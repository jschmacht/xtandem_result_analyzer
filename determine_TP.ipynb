{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1c63756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from handling_acc_files import HelperMethod\n",
    "from create_reference_from_tsv_and_pepxml import ReferenceWriter\n",
    "from collections import defaultdict\n",
    "from create_PSM_df import PSM_FDR\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c99605d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load taxon graph from harddrive.\n"
     ]
    }
   ],
   "source": [
    "taxon_graph = HelperMethod.load_taxa_graph(Path('/home/jules/Documents/databases/databases_tax2proteome/taxdump.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ab345b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_identification_file = Path('/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv')\n",
    "path_to_reference = Path('/home/jules/Documents/Tax2Proteome/benchmarking/reference_files/Run1_U1_2000ng_uniprot_species_nr_reference.tsv')\n",
    "level='species'\n",
    "spectra_file='/home/jules/Documents/Tax2Proteome/benchmarking/spectra/Run1_U1_2000ng.mgf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64664a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced_Run1_U1_2000ng_uniprot_species_nr_reference.tsv\n"
     ]
    }
   ],
   "source": [
    "path_to_all_info_tsv = path_to_identification_file.parent.joinpath(path_to_identification_file.stem + '_' + path_to_reference.stem + '.tsv')\n",
    "print(path_to_all_info_tsv)\n",
    "result_df = ReferenceWriter.read_csv_with_generic_function(path_to_identification_file,\n",
    "                                            ['Protein', 'decoy', 'taxID', f'taxID_{level}'])\n",
    "reference_df = ReferenceWriter.read_csv_with_generic_function(path_to_reference,\n",
    "                                            ['Ref_Peptide', 'Ref_ProteinAcc', 'Ref_Hyperscore', 'Ref_decoy','Ref_taxID_DB', f'Ref_taxID_{level}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ef10470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterminatorSpecificitySensitivity():\n",
    "\n",
    "    def __init__(self, level, fdr_applied_df, reference_df, spectra_file):\n",
    "        \"\"\"\n",
    "        :param fdr_applied_df:\n",
    "        :param refernce_df: column names =\n",
    "        :param spectra_file: 'Run1_U1_2000ng.mgf'\n",
    "        \"\"\"\n",
    "        self.tax_level = ['species', 'genus', 'family', 'order']\n",
    "        self.level = level\n",
    "        self.result_df = fdr_applied_df[['Title', 'Peptide', 'Hyperscore', 'Protein', 'decoy', 'taxID', f'taxID_{level}']]\n",
    "        self.reference_df = reference_df[['SpectraID', 'Ref_Peptide', 'Ref_Hyperscore', 'Ref_ProteinAcc', 'Ref_decoy', 'Ref_taxID_DB', f'Ref_taxID_{level}']]\n",
    "        self.all_spectra_list = self.get_all_spectra_IDs(spectra_file)\n",
    "\n",
    "    def create_df_with_all_spectra_reference_and_result_taxa(self, path_to_out):\n",
    "        df_all_spectra = pd.DataFrame(self.all_spectra_list, columns=['SpectraID'])\n",
    "        print('Number of different spectra: ', len(self.all_spectra_list))\n",
    "        df_with_all_spectra_and_reference_and_results = pd.merge(df_all_spectra, self.result_df, how=\"outer\", left_on='SpectraID', right_on='Title')\n",
    "        df_with_all_spectra_and_reference_and_results = pd.merge(df_with_all_spectra_and_reference_and_results,\n",
    "                                                                 self.reference_df, how=\"outer\", left_on='SpectraID', right_on='SpectraID')\n",
    "        print(f\"write df_with_all_spectra_and_reference_and_results {path_to_out}... \")\n",
    "        df_with_all_spectra_and_reference_and_results.to_csv(str(path_to_out), sep='\\t')\n",
    "        return df_with_all_spectra_and_reference_and_results\n",
    "\n",
    "    def calculate_sensitivity(self, TP, FN):\n",
    "        return TP/(TP+FN)\n",
    "\n",
    "    def calculate_specificity(self, FP, TN):\n",
    "        return TN/(TN + FP)\n",
    "\n",
    "    def calculate_sensitivity_and_specificity(self, path_to_out):\n",
    "        pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "        df_with_all_spectra_and_reference_and_results = self.create_df_with_all_spectra_reference_and_result_taxa(path_to_out)\n",
    "        print('calculate TP, FP, TN, FN')\n",
    "        TP, FP, TN, FN = self.get_true_positive_and_true_negative(df_with_all_spectra_and_reference_and_results)\n",
    "        sensitivity = self.calculate_sensitivity(TP, FN)\n",
    "        specificity = self.calculate_specificity(FP, TN)\n",
    "        print(f'sensitivity: {sensitivity}, specificity: {specificity}')\n",
    "\n",
    "    def load_ref_file(self, ref_file, level):\n",
    "        level_to_column_nb_dict={'species': 4, 'genus': 5, 'family': 6, 'order': 7}\n",
    "        spectraID_to_taxid_dict = defaultdict(list)\n",
    "        with open(ref_file, 'r') as ref:\n",
    "            ref.readline()\n",
    "            for line in ref:\n",
    "                fields = line.split()\n",
    "                level_specific_taxid = fields[level_to_column_nb_dict[level]]\n",
    "                spectraID = fields[0]\n",
    "                spectraID_to_taxid_dict[spectraID].append(level_specific_taxid)\n",
    "        return spectraID_to_taxid_dict\n",
    "\n",
    "    def get_all_spectra_IDs(self, ident_file):\n",
    "        all_spec_IDs = set()\n",
    "        with open(ident_file, 'r') as ident_file:\n",
    "            for line in ident_file:\n",
    "                if line.startswith('TITLE'):\n",
    "                    all_spec_IDs.add(line.split()[0].split('TITLE=')[1])\n",
    "        return all_spec_IDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aeeb7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterminatorSpecificitySensitivity(DeterminatorSpecificitySensitivity):\n",
    "    \n",
    "    def check_for_TP(self, taxid_set, taxid_ref_set):\n",
    "        # ignore Decoy crap entries from result_reduced (not contained in reference)\n",
    "        decoy_set = {'DECOY', 'DECOY/CRAP', 0}\n",
    "        taxid_set = taxid_set.difference(decoy_set)\n",
    "        if len(taxid_set) == 0 and pd.isna(taxid_ref_set): #only decoy entries\n",
    "            return False\n",
    "        return taxid_set.issubset(taxid_ref_set)\n",
    "    \n",
    "    def check_for_FP(self, taxid_set, taxid_ref_set):\n",
    "        for taxid in taxid_set:\n",
    "            # ignore Decoy crap entries from result_reduced (not contained in reference)\n",
    "            if taxid == 'DECOY/CRAP' or taxid == 'DECOY':\n",
    "                continue\n",
    "            else:\n",
    "                if taxid not in taxid_ref_set: \n",
    "                    return True\n",
    "        return False\n",
    "                        \n",
    "    def compare_tax_sets(self, taxid_set, taxid_ref_set, is_FP):\n",
    "        if not pd.isna(taxid_set) and not pd.isna(taxid_ref_set):\n",
    "            if is_FP:\n",
    "                return self.check_for_FP(taxid_set, taxid_ref_set)  \n",
    "            else:\n",
    "                return self.check_for_TP(taxid_set, taxid_ref_set) \n",
    "        return False\n",
    "    \n",
    "    def check_taxid_in_reference(self, taxid_level_column, taxid_level_ref_column, is_FP):\n",
    "        true_false_list = []\n",
    "        for taxid_set, taxid_ref_set in zip(taxid_level_column, taxid_level_ref_column):\n",
    "            true_false_list.append(self.compare_tax_sets(taxid_set, taxid_ref_set, is_FP))\n",
    "        return true_false_list\n",
    "\n",
    "    def get_true_positive_and_true_negative(self, df_with_all_spectra_and_reference_and_results):\n",
    "        pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "        df_taxid = df_with_all_spectra_and_reference_and_results[['SpectraID','taxID','Ref_taxID_DB']]\n",
    "        df_taxid_level = df_with_all_spectra_and_reference_and_results[['SpectraID', f'taxID_{self.level}',f'Ref_taxID_{self.level}']]\n",
    "        \n",
    "        df_TN = df_taxid[df_taxid.taxID != {'DECOY/CRAP'} & df_taxid.Ref_taxID_DB.isna()]\n",
    "        df_TN = df_TN[df_TN.taxID.isna() & df_TN.Ref_taxID_DB.isna()]\n",
    "        TN=len(set(df_TN.SpectraID.tolist()))\n",
    "        df_TP = df_taxid_level[self.check_taxid_in_reference(df_taxid_level[f'taxID_{self.level}'].tolist(), df_taxid_level[f'Ref_taxID_{self.level}'].tolist(), is_FP=False)]\n",
    "        TP = len(set(df_TP.SpectraID.tolist()))\n",
    "        \n",
    "        df_FN = df_taxid[(df_taxid.taxID.notna() ) & df_taxid.Ref_taxID_DB.isna()]\n",
    "        df_FN = df_FN[df_FN.taxID != {'DECOY/CRAP'}]\n",
    "        FN=len(set(df_FN.SpectraID.tolist()))\n",
    "        \n",
    "       \n",
    "        df_FP = df_taxid_level[self.check_taxid_in_reference(df_taxid_level[f'taxID_{self.level}'].tolist(), df_taxid_level[f'Ref_taxID_{self.level}'].tolist(), is_FP=True)]\n",
    "        FP = len(set(df_FP.SpectraID.tolist()))\n",
    "        \n",
    "        print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
    "        return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0f707384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterminatorSpecificitySensitivity(DeterminatorSpecificitySensitivity):\n",
    "    def calculate_sensitivity(self, TP, FN):\n",
    "        return TP/(TP+FN)*100\n",
    "\n",
    "    def calculate_specificity(self, FP, TN):\n",
    "        return TN/(TN + FP)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3145b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv\n",
      "Number of PSMs: 47476\n",
      "Number of decoys: 2498\n",
      "double identified spectra 3322\n",
      "Position FDR border/Number of PSMs: 53296\n"
     ]
    }
   ],
   "source": [
    "psm = PSM_FDR(path_to_identification_file)\n",
    "print(path_to_identification_file)\n",
    "fdr_pos, number_psms, decoys = psm.determine_FDR_position(result_df, 0.05, True)\n",
    "fdr_applied_df = result_df[0:fdr_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "06334070",
   "metadata": {},
   "outputs": [],
   "source": [
    "determinator = DeterminatorSpecificitySensitivity(level, fdr_applied_df, reference_df, spectra_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8c3edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different spectra:  164414\n",
      "write df_with_all_spectra_and_reference_and_results /home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced_Run1_U1_2000ng_uniprot_species_nr_reference.tsv... \n"
     ]
    }
   ],
   "source": [
    "df_with_all_spectra_and_reference_and_results = determinator.create_df_with_all_spectra_reference_and_result_taxa(path_to_all_info_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ef24d9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 47526, FP: 0, TN: 114440, FN: 0\n"
     ]
    }
   ],
   "source": [
    "TP, FP, TN, FN = determinator.get_true_positive_and_true_negative(df_with_all_spectra_and_reference_and_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b3ad1b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161936\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_s = df_with_all_spectra_and_reference_and_results[df_with_all_spectra_and_reference_and_results.taxID != {'DECOY/CRAP'}]\n",
    "number_spectra = (len(set(df_s.SpectraID)))\n",
    "print(number_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0b0a12f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161966\n"
     ]
    }
   ],
   "source": [
    "number_complete = (TP+TN)\n",
    "print(number_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "69fd9520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(number_complete - number_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "570ec710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7ce04e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(determinator.calculate_sensitivity(TP,FN))\n",
    "print(determinator.calculate_specificity(FP,TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3627d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelperMethod():\n",
    "\n",
    "    @staticmethod\n",
    "    def load_taxa_graph(path_to_taxdump):\n",
    "        \"\"\"\n",
    "        # Try load pre-builded taxonomy graph or built taxonomy graph now\n",
    "        :param options: user input options\n",
    "        :return: TaxonGraph object\n",
    "        \"\"\"\n",
    "\n",
    "        if not (path_to_taxdump.parents[0] / 'taxon_graph_results').is_file():\n",
    "            taxon_graph = TaxonGraph()\n",
    "            print(\"Start building taxon graph.\")\n",
    "            taxon_graph.create_graph(str(path_to_taxdump))\n",
    "            print(\"Taxon graph successfully build.\")\n",
    "            # save TaxonGraph to harddrive:\n",
    "            try:\n",
    "                with open(str(path_to_taxdump.parents[0] / 'taxon_graph_results'), 'wb') as handle:\n",
    "                    pickle.dump(taxon_graph, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    print('Safe taxon graph to location: %s' % str(\n",
    "                        path_to_taxdump.parents[0] / 'taxon_graph_results'))\n",
    "            except FileNotFoundError:\n",
    "                print('Error open tax_graph.')\n",
    "                exit(1)\n",
    "        # load Taxon Graph\n",
    "        else:\n",
    "            try:\n",
    "                print('Load taxon graph from harddrive.')\n",
    "                with open(str(path_to_taxdump.parents[0] / 'taxon_graph_results'), 'rb') as handle:\n",
    "                    taxon_graph = pickle.load(handle)\n",
    "            except UnicodeDecodeError or EOFError:\n",
    "                print(\n",
    "                    \"Failed opening path to taxon graph / taxon_graph is corrupted. Delete %s file.\"\n",
    "                    % str(path_to_taxdump.parents[0] / 'taxon_graph'))\n",
    "                exit(1)\n",
    "        return taxon_graph\n",
    "\n",
    "    @staticmethod\n",
    "    def get_taxid_specific_spectra(df, columnname, taxid, level, taxongraph):\n",
    "        taxid_level = taxongraph.find_level_up(taxid, level)\n",
    "        return df[[df[columnname] == taxid_level]]\n",
    "\n",
    "    @staticmethod\n",
    "    def create_df_with_all_spectra_and_dfs_to_compare(all_spectra_list, df1, spectra_column_1, df2, spectra_column_2):\n",
    "        df_all_spectra = pd.DataFrame(all_spectra_list, columns=['SpectraID'])\n",
    "        df_with_all_spectra_and_df1 = pd.merge(df_all_spectra, df1, how=\"outer\", left_on='SpectraID', right_on=spectra_column_1)\n",
    "        df_with_all_spectra_and_df1_df2 = pd.merge(df_with_all_spectra_and_df1, df2, how=\"outer\", left_on='SpectraID', right_on=spectra_column_2)\n",
    "        return df_with_all_spectra_and_df1_df2\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_difference_between_two_df(all_spectra_list, df1, spectra_column_1, column_of_interest_1, df2, spectra_column_2, column_of_interest_2):\n",
    "        df_with_all_spectra_and_df1_df2 = HelperMethod.create_df_with_all_spectra_and_dfs_to_compare(all_spectra_list, df1, spectra_column_1, df2, spectra_column_2)\n",
    "        return df_with_all_spectra_and_df1_df2[df_with_all_spectra_and_df1_df2[column_of_interest_1] !=  df_with_all_spectra_and_df1_df2[column_of_interest_2]]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_spectra_IDs(ident_file):\n",
    "        all_spec_IDs = set()\n",
    "        with open(ident_file, 'r') as ident_file:\n",
    "            for line in ident_file:\n",
    "                if line.startswith('TITLE'):\n",
    "                    all_spec_IDs.add(line.split()[0].split('TITLE=')[1])\n",
    "        return all_spec_IDs\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_rows_with_different_taxa(tax_column_1, tax_column_2, taxon_1, taxon_2):\n",
    "        true_false_list=[]\n",
    "        for tax_set_1, tax_set_2 in zip(tax_column_1, tax_column_2):\n",
    "            if not pd.isna(tax_set_1) and not pd.isna(tax_set_2):\n",
    "                if (taxon_1 in tax_set_1 and taxon_2 not in tax_set_2) or (taxon_1 not in tax_set_1 and taxon_2 in tax_set_2):\n",
    "                    true_false_list.append(True)\n",
    "                else:\n",
    "                    true_false_list.append(False)\n",
    "            elif pd.isna(tax_set_1) and not pd.isna(tax_set_2):\n",
    "                if taxon_2 in tax_set2:\n",
    "                    true_false_list.append(True)\n",
    "                else:\n",
    "                    true_false_list.append(False)                  \n",
    "            elif not pd.isna(tax_set_1) and pd.isna(tax_set_2):\n",
    "                if taxon_1 in tax_set1:\n",
    "                    true_false_list.append(True)\n",
    "                else:\n",
    "                    true_false_list.append(False)\n",
    "            else:\n",
    "                true_false_list.append(False)\n",
    "        return true_false_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_difference_between_two_df_for_one_taxon(all_spectra_list, df1, spectra_column_1, column_of_interest_1, df2,\n",
    "                                      spectra_column_2, column_of_interest_2, taxon, level1, level2, taxon_graph):\n",
    "        df_with_all_spectra_and_df1_df2 = HelperMethod.create_df_with_all_spectra_and_dfs_to_compare(all_spectra_list, df1, spectra_column_1, df2, spectra_column_2)\n",
    "        # remove empty lines\n",
    "        df_with_all_spectra_and_df1_df2 = df_with_all_spectra_and_df1_df2[df_with_all_spectra_and_df1_df2.Hyperscore_x.notna() & df_with_all_spectra_and_df1_df2.Hyperscore_y.notna()]\n",
    "        taxon_1 = taxon_graph.find_level_up(taxon, level1)\n",
    "        taxon_2 = taxon_graph.find_level_up(taxon, level2)\n",
    "        df_difference=df_with_all_spectra_and_df1_df2[HelperMethod.get_rows_with_different_taxa(df_with_all_spectra_and_df1_df2[column_of_interest_1].tolist(), df_with_all_spectra_and_df1_df2[column_of_interest_2].tolist(), taxon_1, taxon_2)]\n",
    "        return df_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ba79aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacillus subtilis = 1423\n",
    "path_to_uniprot_reduced_result_species_nr = '/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv'\n",
    "path_to_uniprot_reduced_result_genus_nr = '/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_genus_nr.t.xml_reduced.tsv'\n",
    "path_to_spectra_file='/home/jules/Documents/Tax2Proteome/benchmarking/spectra/Run1_U1_2000ng.mgf'\n",
    "# load df\n",
    "uniprot_species_nr = ReferenceWriter.read_csv_with_generic_function(path_to_uniprot_reduced_result_species_nr,\n",
    "                                            ['Protein', 'decoy', 'taxID', f'taxID_species'])\n",
    "uniprot_genus_nr = ReferenceWriter.read_csv_with_generic_function(path_to_uniprot_reduced_result_genus_nr,\n",
    "                                            ['Protein', 'decoy', 'taxID', f'taxID_genus'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4b6dd228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PSMs: 47476\n",
      "Number of decoys: 2498\n",
      "double identified spectra 3322\n",
      "Position FDR border/Number of PSMs: 53296\n",
      "Number of PSMs: 35571\n",
      "Number of decoys: 1872\n",
      "double identified spectra 4579\n",
      "Position FDR border/Number of PSMs: 42022\n"
     ]
    }
   ],
   "source": [
    "fdr_pos_species, number_psms, decoys = psm.determine_FDR_position(uniprot_species_nr, 0.05, True)\n",
    "fdr_pos_genus, number_psms, decoys = psm.determine_FDR_position(uniprot_genus_nr, 0.05, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b63d2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_containg_taxon(taxon, tax_set_column):\n",
    "    true_false_list=[]\n",
    "    for tax_set in tax_set_column:\n",
    "        if not pd.isna(tax_set):\n",
    "            true_false_list.append(taxon in tax_set)\n",
    "    return true_false_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "44fb0002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49974\n",
      "37443\n",
      "Spectra identification Bacillus subtilis:  1010\n",
      "Spectra identification Bacillus:  2577\n"
     ]
    }
   ],
   "source": [
    "uniprot_species_nr = uniprot_species_nr[0:fdr_pos_species]\n",
    "uniprot_genus_nr = uniprot_genus_nr[0:fdr_pos_genus]\n",
    "print(len(set(uniprot_species_nr[uniprot_species_nr.taxID != {'CRAP/DECOY'}][\"Title\"].tolist())))\n",
    "print(len(set(uniprot_genus_nr[uniprot_genus_nr.taxID != {'CRAP/DECOY'}][\"Title\"].tolist())))\n",
    "print('Spectra identification Bacillus subtilis: ',len(set(uniprot_species_nr[rows_containg_taxon(1423, uniprot_species_nr.taxID_species.tolist())][\"Title\"].tolist())))\n",
    "print('Spectra identification Bacillus: ',len(set(uniprot_genus_nr[rows_containg_taxon(1386, uniprot_genus_nr.taxID_genus.tolist())][\"Title\"].tolist())))\n",
    "all_spectra_set = HelperMethod.get_all_spectra_IDs(path_to_spectra_file)\n",
    "all_spectra_species_genus_df = HelperMethod.create_df_with_all_spectra_and_dfs_to_compare(all_spectra_set, uniprot_species_nr, 'Title', uniprot_genus_nr, 'Title')\n",
    "all_spectra_species_genus_df = all_spectra_species_genus_df[all_spectra_species_genus_df.Hyperscore_x.notna() & all_spectra_species_genus_df.Hyperscore_y.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "618494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get difference by taxon\n",
    "def rows_one_column_with_taxid_one_without(taxon_level1, taxon_level2, tax_set_column1, tax_set_column2):\n",
    "    true_false_list=[]\n",
    "    for tax_set1, tax_set2 in zip(tax_set_column1, tax_set_column2):\n",
    "        if not pd.isna(tax_set1):\n",
    "            if taxon_level1 in tax_set1 and taxon_level2 not in tax_set2:\n",
    "                true_false_list.append(True)\n",
    "            else:\n",
    "                true_false_list.append(False)\n",
    "        else:\n",
    "            if pd.isna(tax_set2):\n",
    "                true_false_list.append(True)\n",
    "            else:\n",
    "                true_false_list.append(False)\n",
    "    return true_false_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "35e6fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423 1386\n"
     ]
    }
   ],
   "source": [
    "taxid_bacillus_subtilis_species = taxon_graph.find_level_up(1423, 'species')\n",
    "taxid_bacillus_subtilis_genus = taxon_graph.find_level_up(1423, 'genus')\n",
    "print(taxid_bacillus_subtilis_species, taxid_bacillus_subtilis_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e17052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "044efc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spectra with difference for bacillus species, genus:  1858\n",
      "number of spectra identified for bacillus subtilis species, but not bacillus genus:  259\n",
      "number of spectra identified for bacillus genus, but not bacillus subtilis species:  1816\n",
      "spectra with same identified peptide:  1366\n",
      "spectra only identified by bacillus genus and no other species taxa:  0\n",
      "spectra only identified by bacillus species and not genus level db:  0\n",
      "mean number of genus taxa identify spectra, also identified by bacillus genus and not by bacillus subtilis species 3.932239965472594\n",
      "{1822464: 322, 40323: 491, 265: 181, 270: 19, 914: 277, 535: 257, 286: 910, 561: 1084, 497726: 1, 590: 1153, 35798: 153, 106589: 266, 226: 346, 357: 109, 872: 82, 1386: 2317, 3052: 28, 379: 217, 'DECOY/CRAP': 132, 1279: 766}\n"
     ]
    }
   ],
   "source": [
    "bacillus_difference_df = all_spectra_species_genus_df[HelperMethod.get_rows_with_different_taxa(all_spectra_species_genus_df['taxID_species'].tolist(), all_spectra_species_genus_df['taxID_genus'].tolist(), taxid_bacillus_subtilis_species, taxid_bacillus_subtilis_genus)]\n",
    "print('number of spectra with difference for bacillus species, genus: ', len(set(bacillus_difference_df.SpectraID.tolist())))\n",
    "# bacillus_difference_df[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "a = bacillus_difference_df[rows_one_column_with_taxid_one_without(1423, 1386, bacillus_difference_df.taxID_species.tolist(), bacillus_difference_df.taxID_genus.tolist())]\n",
    "# a[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "print('number of spectra identified for bacillus subtilis species, but not bacillus genus: ', len(set(a.SpectraID.tolist())))\n",
    "b = bacillus_difference_df[rows_one_column_with_taxid_one_without(1386, 1423, bacillus_difference_df.taxID_genus.tolist(), bacillus_difference_df.taxID_species.tolist())]\n",
    "# b[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "print('number of spectra identified for bacillus genus, but not bacillus subtilis species: ', len(set(b.SpectraID.tolist())))\n",
    "c = bacillus_difference_df[bacillus_difference_df.Peptide_y == bacillus_difference_df.Peptide_x]\n",
    "# c[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "print('spectra with same identified peptide: ', len(set(c.SpectraID.tolist())))\n",
    "b[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "d = bacillus_difference_df[bacillus_difference_df.Peptide_x.isna() & bacillus_difference_df.Peptide_y.notna()]\n",
    "d[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "e = bacillus_difference_df[bacillus_difference_df.Peptide_y.isna() & bacillus_difference_df.Peptide_x.notna()]\n",
    "print('spectra only identified by bacillus genus and no other species taxa: ', len(set(d.SpectraID.tolist())))\n",
    "print('spectra only identified by bacillus species and not genus level db: ', len(set(e.SpectraID.tolist())))\n",
    "b[['SpectraID', 'Peptide_x', 'Peptide_y', 'Hyperscore_x', 'Hyperscore_y', 'taxID_species', 'taxID_genus']].head(30)\n",
    "from statistics import mean\n",
    "mean_length = mean([len(tax_set) for tax_set in b.taxID_genus])\n",
    "genus_taxa_list = [item for sublist in b.taxID_genus for item in sublist]\n",
    "genus_taxa_2_number_dict = dict((x,genus_taxa_list.count(x)) for x in set(genus_taxa_list))\n",
    "print('mean number of genus taxa identify spectra, also identified by bacillus genus and not by bacillus subtilis species', mean_length)\n",
    "print(genus_taxa_2_number_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c51b93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_spectra_species_genus_df[['SpectraID', 'Peptide_x', 'Hyperscore_x', 'taxID_species', 'Peptide_y', 'Hyperscore_y', 'taxID_genus']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "55617b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxon_identified_in_spectra(taxid_species_list, taxid_genus_list, taxid_species, taxid_genus):\n",
    "    true_false_list = []\n",
    "    for taxa_set_species, taxa_set_genus in zip(taxid_species_list, taxid_genus_list):\n",
    "        if not pd.isna(taxa_set_species):\n",
    "            if taxid_species in taxa_set_species:\n",
    "                true_false_list.append(True)\n",
    "                continue\n",
    "        if not pd.isna(taxa_set_genus):\n",
    "            if taxid_genus in taxa_set_genus:\n",
    "                true_false_list.append(True) \n",
    "                continue\n",
    "        true_false_list.append(False)\n",
    "    return true_false_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7dc1f0a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.9\n",
      "8.1\n",
      "112.9\n",
      "8.7\n"
     ]
    }
   ],
   "source": [
    "df = df[taxon_identified_in_spectra(df.taxID_species.tolist(), df.taxID_genus.tolist(), taxid_bacillus_subtilis_species, taxid_bacillus_subtilis_genus)]\n",
    "df.head(30)\n",
    "print(max(df.Hyperscore_x.tolist()))\n",
    "print(min(df.Hyperscore_x.tolist()))\n",
    "print(max(df.Hyperscore_y.tolist()))\n",
    "print(min(df.Hyperscore_y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b793cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    " def flatten_set( s):\n",
    "        return {item for sublist in s for item in sublist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ae339e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1280, 384, 40324, 36873, 266, 1176649, 28108, 1149133, 1423, 1231, 274, 915, 536, 1034015, 44577, 28901, 294, 3055, 881, 562, 119219, 329852, 1294143}\n",
      "{1822464, 40323, 265, 270, 914, 535, 286, 561, 497726, 590, 35798, 11990, 106589, 226, 357, 872, 1386, 3052, 379, 1279}\n"
     ]
    }
   ],
   "source": [
    "taxids_species_bacillus = set(flatten_set([taxset for taxset in df.taxID_species.tolist() if not pd.isna(taxset)]))\n",
    "taxids_species_bacillus.remove('DECOY/CRAP')\n",
    "print(taxids_species_bacillus)\n",
    "taxids_genus_bacillus = {taxon_graph.find_level_up(taxon, 'genus') for taxon in taxids_species_bacillus}\n",
    "print(taxids_genus_bacillus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5abdda07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3225ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3aa376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_to_uniprot_result_species_nr = '/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml.tsv'\n",
    "path_to_uniprot_result_genus_nr = '/home/jules/Documents/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_genus_nr.t.xml.tsv'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
