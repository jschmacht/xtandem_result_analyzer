{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8a4c91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from create_reference_from_tsv_and_pepxml import ReferenceWriter\n",
    "from create_PSM_df import PSM_FDR\n",
    "from collections import defaultdict\n",
    "from ReadAccTaxon import ReadAccTaxon\n",
    "# load taxon graph\n",
    "import sys  \n",
    "sys.path.insert(0, '/home/jules/tax2proteome_projects/tax2proteome/')\n",
    "from TaxonGraph import TaxonGraph\n",
    "taxon_graph = TaxonGraph()\n",
    "taxon_graph.create_graph(\"/home/jules/Documents/Metaproteomics/databases/databases_tax2proteome/taxdump.tar.gz\")\n",
    "\n",
    "path_to_kleiner_results_bachelor = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/\"\n",
    "path_to_tanca_results_bachelor = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/9MM_FASP/x_tandem_tsv\"\n",
    "\n",
    "uniprot_nr_reduced_tsv = {\n",
    "    'subspecies': path_to_kleiner_results_bachelor + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_subspecies.t.xml_new_reduced.tsv\",\n",
    "    'species': path_to_kleiner_results_bachelor + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_kleiner_results_bachelor + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_genus_nr.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_kleiner_results_bachelor + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_family_nr.t.xml_new_reduced.tsv\",\n",
    "}\n",
    "\n",
    "tanca_uniprot_tsv = {\n",
    "    'species': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_species_nr.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_genus.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_family_nr.t.xml_new_reduced.tsv\",\n",
    "    'order': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_order_nr.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "#species_name, species_taxon, %protein\n",
    "# \"name\", taxa list species, taxa list level %protein\n",
    "Kleiner_species_taxa = [\n",
    "    (\"Escherichia coli\", [562], [562], 5.788), \n",
    "    (\"Salmonella enterica\", [28901], [28901], 33.773), \n",
    "    (\"Bacillus subtilis\", [1423], [1423], 0.788), \n",
    "    (\"Staphylococcus aureus\", [1280], [1280], 2.605), \n",
    "    (\"Desulfovibrio vulgaris\", [881], [881], 0.946), \n",
    "    (\"Thermus thermophilus\", [274], [274], 1.68),  \n",
    "    (\"Chlamydomonas reinhardtii\", [3055], [3055], 3.996), \n",
    "    (\"Paracoccus denitrificans\", [266], [266], 0.922), \n",
    "    (\"Nitrososphaera viennensis\", [1034015], [1034015], 0.819), \n",
    "    (\"Stenotrophomonas maltophilia\", [40324], [40324], 8.021), \n",
    "    (\"Altermonas macleodii\", [28108], [28108], 0.954), \n",
    "    (\"Chromobacterium violaceum\", [536], [536], 1.259), \n",
    "    (\"Paraburkholderia xenovorans\", [36873], [36873], 0.433), \n",
    "    (\"Cupriavidus metallidurans\", [119219], [119219], 15.519),\n",
    "    (\"Nitrosomonas ureae\", [44577], [44577], 0.543), \n",
    "    (\"Nitrosomonas europaea\", [915], [915], 0.082), \n",
    "    (\"Nitrosospira multiformis\", [1231], [1231], 0.209),\n",
    "    (\"Agrobacterium fabrum\", [1176649], [1176649], 5.647), \n",
    "    (\"Rhizobium leguminosarum\", [384], [384], 3.172), \n",
    "    (\"Pseudomonas fluorescens\", [294], [294], 6.696), \n",
    "    (\"Pseudomonas furukawaii\", [1149133], [1149133], 1.165), \n",
    "    (\"Pseudomonas sp. ATCC 13867\", [1294143], [1294143], 2.871) \n",
    "]\n",
    "#genus_name species_taxa, genus_taxa, %protein\n",
    "Kleiner_genus_groups = [ \n",
    "    (\"Nitrosomonas\", [44577, 915],  [914], 0.644), \n",
    "    (\"Pseudomonas\", [294, 1149133, 1294143], [286], 10.733),\n",
    "    (\"viruses\", [10754, 101570, 1985310, 329852, 1977402], [186794, 196894, 1198140, 11990, 10861], 0.513)\n",
    "]\n",
    "\n",
    "#family_name species_taxa, family_taxa, %protein\n",
    "Kleiner_family_groups = [\n",
    "    (\"Enterobacteriaceae\", [28901, 562],  [543], 39.561), \n",
    "    (\"Burkholderiaceae\", [36873, 119219], [119060], 15.519),\n",
    "    (\"Nitrosomonadaceae\", [44577, 915, 1231],  [206379], 0.834), \n",
    "    (\"Rhizobiaceae\", [1176649, 384],  [82115], 8.819), \n",
    "    (\"Pseudomonadaceae\", [294, 1149133, 1294143], [135621], 10.733),\n",
    "    (\"viruses\", [10754, 101570, 1985310, 329852, 1977402], [10744, 10699, 10662, 11989, 10860], 0.513)\n",
    "]\n",
    "\n",
    "Kleiner_groups = {'virus': [10754, 101570, 1985310, 329852, 1977402]}\n",
    "\n",
    "Kleiner_level_groups = {'genus': [[44577, 915], [294, 1149133, 1294143]],\n",
    "                        'family': [[28901, 562], [36873, 119219],  [44577, 915, 1231],  [1176649, 384], \n",
    "                           [294, 1149133, 1294143]]\n",
    "                       }\n",
    "\n",
    "Tanca_species_taxa = [\n",
    "    (\"Pasteurella multocida\", [747], 11.1), (\"Brevibacillus laterosporus\", [1465], 11.1), \n",
    "    (\"Lactobacillus acidophilus\", [1579], 11.1), (\"Lactobacillus casei\", [1582], 11.1),\n",
    "    (\"Pediococcus pentosaceus\", [1255], 11.1), (\"Enterococcus faecalis\", [1351], 11.1), \n",
    "    (\"Rhodotorula glutinis\", [5535], 11.1), (\"Saccharomyces cerevisiae\", [4932], 11.1),\n",
    "    (\"Escherichia coli\", [562], 11.1)\n",
    "]\n",
    "Tanca_level_groups = {'genus': [[1579,1582]], 'family': [[1579,1582,1255]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "190338fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for loading xtandem results into df\n",
    "def get_hit_rows2(decoy_column):\n",
    "    return [True if d_set in  [{True, False}, {False}] else False for d_set in decoy_column]\n",
    "\n",
    "def get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra=False, columns=None):\n",
    "    cs = ['Protein', 'Hyperscore', 'decoy', 'taxID']\n",
    "    if columns:\n",
    "        cs = cs + columns\n",
    "    reduced_df = ReferenceWriter.read_csv_with_generic_function(file, cs, remove_one_charged_spectra)\n",
    "    fdr_pos_result, number_psm_result, number_decoy_result, double_spectra_result, score_last_item_result = PSM_FDR.determine_FDR_position(reduced_df, fdr)\n",
    "    return number_psm_result, reduced_df[0:fdr_pos_result]\n",
    "\n",
    "def get_df_in_fdr_without_decoy(file, fdr, remove_one_charged_spectra=True, columns=None):\n",
    "    df = get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra, columns)[1]\n",
    "    df = df[get_hit_rows2(df.decoy)]\n",
    "    return df\n",
    "\n",
    "def load_dfs(tsv_dict, level_list=None):\n",
    "    fdr=0.05\n",
    "    if not level_list:\n",
    "        level_list = ['species', 'genus', 'family']\n",
    "    result_dfs= {}\n",
    "    for level in level_list:\n",
    "        tsv = tsv_dict[level]\n",
    "        df_in_fdr = get_df_in_fdr_without_decoy(tsv, fdr, columns=[f'taxID_{level}'])\n",
    "        df_in_fdr.Protein = df_in_fdr.Protein.apply(lambda acc_set: {acc.split('|')[1] for acc in acc_set})\n",
    "        result_dfs[level] = df_in_fdr    \n",
    "    return result_dfs['species'], result_dfs['genus'], result_dfs['family']\n",
    "\n",
    "def get_acc2taxid_dict(all_accs):\n",
    "    final_accs = set()\n",
    "    for acc in all_accs:\n",
    "        try:\n",
    "            final_accs.add(acc.split('|')[1])\n",
    "        except:\n",
    "            final_accs.add(acc)\n",
    "    acc2tax_reader=ReadAccTaxon(\"/home/jules/Documents/Metaproteomics/databases/databases_tax2proteome/\", \"uniprot\")\n",
    "    acc_to_taxid_dict = acc2tax_reader.read_acc2tax(final_accs)\n",
    "    acc_to_taxid_dict = {key: int(taxid) for key, taxid in acc_to_taxid_dict.items()}\n",
    "    return acc_to_taxid_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb30fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_exclusive_rows(level_taxa_column):\n",
    "    l=[]\n",
    "    for t_set in level_taxa_column:\n",
    "        if type(t_set) == list:\n",
    "            t_set=set(t_set)\n",
    "        if 'CRAP' in t_set:\n",
    "            t_set.remove('CRAP')\n",
    "        if 'DECOY' in t_set:\n",
    "            t_set.remove('DECOY')\n",
    "        if len(t_set)== 1:\n",
    "            l.append(True)\n",
    "        else:\n",
    "            l.append(False)\n",
    "    return l\n",
    "\n",
    "def get_all_non_exclusive_rows(level_taxa_column):\n",
    "    l=[]\n",
    "    for t_set in level_taxa_column:\n",
    "        if type(t_set) == list:\n",
    "            t_set=set(t_set)\n",
    "        if 'CRAP' in t_set:\n",
    "            t_set.remove('CRAP')\n",
    "        if 'DECOY' in t_set:\n",
    "            t_set.remove('DECOY')\n",
    "        if len(t_set) > 1:\n",
    "            l.append(True)\n",
    "        else:\n",
    "            l.append(False)\n",
    "    return l\n",
    "\n",
    "def get_taxa_rows(column, taxID):\n",
    "    if type(taxID)==int:\n",
    "        return [True if taxID in t_set else False for t_set in column]\n",
    "    elif type(taxID)==list:\n",
    "        return [True if len(set(taxID).intersection(set(taxa_set)))>0 else False for taxa_set in column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f580346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#um PSMs mit weniger als threshold nb PSMs zu entfernen muss acca zu taxid passende listen erstellen\n",
    "def get_taxid_of_acc(acc, level, taxon_graph, acc_to_taxid_dict):\n",
    "    if 'REVERSED' in acc:\n",
    "        return \"DECOY\"\n",
    "    try:\n",
    "        taxid = taxon_graph.find_level_up(acc_to_taxid_dict[acc], level)\n",
    "    except KeyError:\n",
    "        taxid = \"CRAP\"\n",
    "    return taxid\n",
    "\n",
    "def get_taxids_of_accs(acc_list, level, taxon_graph, acc_to_taxid_dict):\n",
    "    taxid_list = []\n",
    "    for acc in acc_list:\n",
    "        taxid_list.append(get_taxid_of_acc(acc, level, taxon_graph, acc_to_taxid_dict))\n",
    "    return taxid_list\n",
    "\n",
    "def sort_taxid_and_acc_in_df(df, level, acc_to_taxid_dict):\n",
    "    df.Protein = df.Protein.apply(lambda acc_set: sorted(list(acc_set)))\n",
    "    df[f\"taxID_{level}\"] = df.Protein.apply(lambda acc_list: get_taxids_of_accs(acc_list, level, taxon_graph, acc_to_taxid_dict))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ae889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_fdr_uniprot_species, df_in_fdr_uniprot_genus, df_in_fdr_uniprot_family = load_dfs(uniprot_nr_reduced_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "419ba942",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_accs_set = {item for sublist in df_in_fdr_uniprot_species.Protein for item in sublist}\n",
    "uniprot_accs_set = uniprot_accs_set.union({item for sublist in df_in_fdr_uniprot_genus.Protein for item in sublist})\n",
    "uniprot_accs_set = uniprot_accs_set.union({item for sublist in df_in_fdr_uniprot_family.Protein for item in sublist})\n",
    "acc_to_taxid_dict = get_acc2taxid_dict(uniprot_accs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e59ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading accession2prot database file with 8 threads.\n",
      "10% read.\n",
      "20% read.\n",
      "30% read.\n",
      "40% read.\n",
      "50% read.\n",
      "60% read.\n",
      "70% read.\n",
      "80% read.\n",
      "90% read.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44298c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_fdr_uniprot_species_sorted = sort_taxid_and_acc_in_df(df_in_fdr_uniprot_species.copy(deep=True), 'species', acc_to_taxid_dict)\n",
    "df_in_fdr_uniprot_genus_sorted = sort_taxid_and_acc_in_df(df_in_fdr_uniprot_genus.copy(deep=True), 'genus', acc_to_taxid_dict)\n",
    "df_in_fdr_uniprot_family_sorted = sort_taxid_and_acc_in_df(df_in_fdr_uniprot_family.copy(deep=True), 'family', acc_to_taxid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775fe704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number all Spectra genus:  35639\n",
      "number exclusive Spectra genus:  21755\n",
      "number non-exclusive Spectra genus:  15653\n",
      "sum:  37408\n",
      "all taxon 379 Spectra genus unsorted:  3619\n",
      "1092 2691 3619\n",
      "sorted spectra\n",
      "number all Spectra genus:  35639\n",
      "number exclusive Spectra genus:  21755\n",
      "number non-exclusive Spectra genus:  15653\n",
      "3619\n",
      "sorted spectra taxon 379\n",
      "1092 2691 3619\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# gibt Überschneidungen zwischen unique und multiple identifizierten spectra, wenn verschiedene \n",
    "# Peptide durch dasselbe spectrum identifiziert wurden, Summe ist also etwas höher\n",
    "uniprot_genus_exclusive = df_in_fdr_uniprot_genus[get_all_exclusive_rows(df_in_fdr_uniprot_genus[f\"taxID_genus\"])]\n",
    "uniprot_genus_non_exclusive = df_in_fdr_uniprot_genus[get_all_non_exclusive_rows(df_in_fdr_uniprot_genus[f\"taxID_genus\"])]\n",
    "print(\"number all Spectra genus: \",len(set(df_in_fdr_uniprot_genus.Title)))\n",
    "print(\"number exclusive Spectra genus: \", len(set(uniprot_genus_exclusive.Title)))\n",
    "print(\"number non-exclusive Spectra genus: \",len(set(uniprot_genus_non_exclusive.Title)))\n",
    "print(\"sum: \",len(set(uniprot_genus_exclusive.Title)) + len(set(uniprot_genus_non_exclusive.Title)))\n",
    "\n",
    "print(\"all taxon 379 Spectra genus unsorted: \",len(set(df_in_fdr_uniprot_genus[get_taxa_rows(df_in_fdr_uniprot_genus[f\"taxID_genus\"], 379)].Title)))\n",
    "set_exclusive = (set(uniprot_genus_exclusive[get_taxa_rows(uniprot_genus_exclusive[f\"taxID_genus\"], 379)].Title))\n",
    "set_unique = (set(uniprot_genus_non_exclusive[get_taxa_rows(uniprot_genus_non_exclusive[f\"taxID_genus\"], 379)].Title))\n",
    "set_intersection = (set_exclusive.intersection(set_unique))\n",
    "print(len(set_exclusive), len(set_unique), len(set_exclusive)+len(set_unique)-len(set_intersection))\n",
    "\n",
    "# sorted --> beide Zahlen gleich, kein Fehler mehr\n",
    "uniprot_genus_exclusive_sorted = df_in_fdr_uniprot_genus_sorted[get_all_exclusive_rows(df_in_fdr_uniprot_genus_sorted[f\"taxID_genus\"])]\n",
    "uniprot_genus_non_exclusive_sorted = df_in_fdr_uniprot_genus_sorted[get_all_non_exclusive_rows(df_in_fdr_uniprot_genus_sorted[f\"taxID_genus\"])]\n",
    "print(\"sorted spectra\")\n",
    "print(\"number all Spectra genus: \",len(set(df_in_fdr_uniprot_genus_sorted.Title)))\n",
    "print(\"number exclusive Spectra genus: \", len(set(uniprot_genus_exclusive_sorted.Title)))\n",
    "print(\"number non-exclusive Spectra genus: \",len(set(uniprot_genus_non_exclusive_sorted.Title)))\n",
    "print(len(set(df_in_fdr_uniprot_genus_sorted[get_taxa_rows(df_in_fdr_uniprot_genus_sorted[f\"taxID_genus\"], 379)].Title)))\n",
    "print(\"sorted spectra taxon 379\")\n",
    "set_exclusive_sorted = (set(uniprot_genus_exclusive_sorted[get_taxa_rows(uniprot_genus_exclusive_sorted[f\"taxID_genus\"], 379)].Title))\n",
    "set_unique_sorted = (set(uniprot_genus_non_exclusive_sorted[get_taxa_rows(uniprot_genus_non_exclusive_sorted[f\"taxID_genus\"], 379)].Title))\n",
    "set_intersection_sorted = (set_exclusive_sorted.intersection(set_unique_sorted))\n",
    "print(len(set_exclusive_sorted), len(set_unique_sorted), len(set_exclusive_sorted)+len(set_unique_sorted)-len(set_intersection_sorted))\n",
    "\n",
    "print(set_unique.difference(set_unique_sorted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_in_fdr_uniprot_genus[df_in_fdr_uniprot_genus.Title =='Run1_U1_2000ng.60899.60899.2'])\n",
    "print(df_in_fdr_uniprot_genus_sorted[df_in_fdr_uniprot_genus_sorted.Title =='Run1_U1_2000ng.60899.60899.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "31164b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for reducing df to PSMs wit at least x numbers of matching PSMs\n",
    "#nb_peptides 1 - 4 \n",
    "def remove_acc_row(column, acc_to_remove_set):\n",
    "    return [False if len(set(accs).difference(acc_to_remove_set))==0 else True for accs in column]\n",
    "\n",
    "def remove_empty_rows(column):\n",
    "    return [False if len(accs)==0 else True for accs in column]\n",
    "\n",
    "def add_tax_information(acc_list, acc2tax_dict, level):\n",
    "    tax_list=[]\n",
    "    for acc in acc_list:\n",
    "        if 'REVERSED' in acc:\n",
    "            tax_list.append('DECOY')\n",
    "        else:\n",
    "            try:\n",
    "                tax_list.append(taxon_graph.find_level_up(acc2tax_dict[acc], level))\n",
    "            except KeyError:\n",
    "                tax_list.append('CRAP')\n",
    "    return tax_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7c1aaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxon_rows(column, taxon):\n",
    "    return [True if taxon in t_list else False for t_list in column]\n",
    "\n",
    "def count_all_identified_spectra_per_taxa(df, level, taxa_list):\n",
    "    taxon_to_spectra_count_dict={}\n",
    "    for taxon in taxa_list:\n",
    "        taxon_to_spectra_count_dict[taxon] = len(set(df[get_taxon_rows(df[f\"taxID_{level}\"], taxon)].Title))\n",
    "    return taxon_to_spectra_count_dict\n",
    "\n",
    "def remove_acc_row(column, acc_to_remove_set):\n",
    "    return [False if len(set(accs).difference(acc_to_remove_set))==0 else True for accs in column]\n",
    "\n",
    "def remove_empty_rows(column):\n",
    "    return [False if len(accs)==0 else True for accs in column]\n",
    "\n",
    "def remove_all_accs_with_less_then_x_peptides(df, level, nb_peptides, acc2tax_dict):\n",
    "    acc_to_peptide_dict=defaultdict(set)\n",
    "    accs_to_remove= set()\n",
    "    accs_to_keep = set()\n",
    "    for index, row in df.iterrows():\n",
    "        for acc in row['Protein']:\n",
    "            if acc!=\"DECOY\" and acc!=\"CRAP\":\n",
    "                acc_to_peptide_dict[acc].add(row[\"Peptide\"])\n",
    "    for acc, pep_set in acc_to_peptide_dict.items():\n",
    "        if len(pep_set) < nb_peptides:\n",
    "            accs_to_remove.add(acc)\n",
    "        else:\n",
    "            accs_to_keep.add(acc)\n",
    "    df_no_x_hits=df[remove_acc_row(df.Protein, accs_to_remove)]\n",
    "    df_no_x_hits.Protein = df_no_x_hits.Protein.apply(lambda acc_list: set(acc_list).intersection(accs_to_keep))\n",
    "    df_no_x_hits.Protein = df_no_x_hits.Protein.apply(lambda acc_set: sorted(list(acc_set)))\n",
    "    df_no_x_hits = df_no_x_hits[remove_empty_rows(df_no_x_hits.Protein)]\n",
    "    df_no_x_hits[f\"taxID_{level}\"] = df_no_x_hits.Protein.apply(lambda acc_list: add_tax_information(acc_list, acc2tax_dict, level))\n",
    "    return df_no_x_hits\n",
    "\n",
    "def write_header(dataset, levels):\n",
    "    fields = []\n",
    "    for level in levels:\n",
    "        fields.append(f\"name {level}\")\n",
    "    for level in levels:\n",
    "        fields.append(f\"spectra count {level}\")\n",
    "        if level == \"species\":\n",
    "            fields.extend([f\"spectra count {level}\"]*(len(levels)-1))\n",
    "    for level in levels:\n",
    "        fields.append(f\"unique spectra count {level}\")\n",
    "\n",
    "    with open(f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_analysis/{dataset}_all_spectra_more_than_x_hits.tsv\", \"w\") as out:\n",
    "        out.write(\"\\t\".join(fields)) \n",
    "        out.write(\"\\n\")                   \n",
    "    \n",
    "    \n",
    "def write_results(all_spectra_dict, unique_spectra_dict, species_taxa_list, level_groups, groups, dataset, levels):\n",
    "    \"\"\"\n",
    "    param all_spectra_dict: {min_nb_psms:{taxon_str:{level:spectra_set}}}, spectra set includes all spectra identified for taxon\n",
    "    param unique_spectra_dict: {min_nb_psms:{taxon_str:{level:spectra_set}}}, spectra set includes only spectra unique identified for taxon\n",
    "        \"\"\"\n",
    "    with open(f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_analysis/{dataset}_all_spectra_more_than_x_hits.tsv\", \"a\") as out:\n",
    "        for min_nb_of_psms in all_spectra_dict.keys():\n",
    "            out.write(f\"Minimum number of PSMS per Protein to be counted: {min_nb_of_psms}\\n\")\n",
    "            # row: name species, name genus, name family, spectra count species, ..., unique spectra count species, ...\n",
    "            for species_taxon in species_taxa_list:\n",
    "                row = [taxon_graph.get_scientific_name(species_taxon)]\n",
    "                # names --> corect\n",
    "                for level in levels[1:]:\n",
    "                    level_taxon = taxon_graph.find_level_up(species_taxon, level)\n",
    "                    row.append(taxon_graph.get_scientific_name(level_taxon))\n",
    "                #spectral count   \n",
    "                for level in levels:\n",
    "                    row.append(str(len(all_spectra_dict[min_nb_of_psms][species_taxon][level])))\n",
    "                    #add spectra count multiple related species for interesting level together\n",
    "                    if level == \"species\":                        \n",
    "                        for lev in levels[1:]:   \n",
    "                            if any(species_taxon in x for x in level_groups[lev]):\n",
    "                                taxa_list = [tax_list for tax_list in level_groups[lev] if species_taxon in tax_list][0]\n",
    "                                spectra_set = set()\n",
    "                                for tax in taxa_list:\n",
    "                                    spectra_set = spectra_set.union(all_spectra_dict[min_nb_of_psms][tax]['species'])\n",
    "                                row.append(str(len(spectra_set)))\n",
    "                            else:\n",
    "                                row.append(\"\")\n",
    "                #unique spectral count\n",
    "                for level in levels: \n",
    "                    row.append(str(len(unique_spectra_dict[min_nb_of_psms][species_taxon][level])))\n",
    "                out.write(\"\\t\".join(row)) \n",
    "                out.write(\"\\n\")\n",
    "            # taxa groups\n",
    "            if groups:\n",
    "                for name, taxa_list in groups.items():\n",
    "                    row = [name]*len(levels)\n",
    "                    for level in levels:\n",
    "                        row.append(str(len(all_spectra_dict[min_nb_of_psms][name][level])))\n",
    "                        #add spectra count multiple related species for interesting level together\n",
    "                        if level == \"species\":                        \n",
    "                            for lev in levels[1:]:   \n",
    "                                    row.append(\"\")\n",
    "                    for level in levels: \n",
    "                        row.append(str(len(unique_spectra_dict[min_nb_of_psms][name][level])))\n",
    "                    out.write(\"\\t\".join(row)) \n",
    "                    out.write(\"\\n\")\n",
    "            #last line\n",
    "            out.write(f\"all spectra\\t\")\n",
    "            for i in range(len(levels)-1):\n",
    "                        out.write(\"\\t\")\n",
    "            for level in levels:\n",
    "                out.write(f\"{all_spectra_dict[min_nb_of_psms]['all'][level]}\\t\")\n",
    "                if level == 'species':\n",
    "                    for i in range(len(levels)-1):\n",
    "                        out.write(\"\\t\")\n",
    "            out.write(\"\\n\\n\")\n",
    "            \n",
    "\n",
    "    \n",
    "def extract_infomation_from_df(df_list, species_taxa_list, acc_to_taxid_dict, levels, groups):\n",
    "    \"\"\"\n",
    "    param group: {name:[taxa list]}\n",
    "    return all_spectra_dict: {min_nb_psms:{taxon_str:{level:spectra_set}}}, spectra set includes all spectra identified for taxon\n",
    "    e.g. {2: {'562': {'species': {'Run1_U1_2000ng.41650.41650.2','Run1_U1_2000ng.76581.76581.3',...)\n",
    "    return unique_spectra_dict: {min_nb_psms:{taxon_str:{level:spectra_set}}}, spectra set includes only spectra unique identified for taxon\n",
    "    \"\"\"\n",
    "    # df_list have to be in correct order species, genus ...\n",
    "    # min_nb_of_psms : {level: {taxon: spectra_count}}\n",
    "    # level_to_taxa_tuple_list_dict : {level: (name, taxa list species, taxa list level, % protein)}\n",
    "    all_spectra_dict = {}\n",
    "    unique_spectra_dict = {}\n",
    "    for min_nb_of_psms in [1,2,3,4]:\n",
    "        print(f\"Processing results for minimum {min_nb_of_psms} PSMS per Protein to be counted.\")\n",
    "        all_spectra_dict[min_nb_of_psms] = defaultdict(dict)\n",
    "        unique_spectra_dict[min_nb_of_psms] = defaultdict(dict)\n",
    "        #create df with all accs removed with less than min_nb_of_psms spectra hits per protein\n",
    "        for n, level in enumerate(levels):\n",
    "            df_no_x_hits=remove_all_accs_with_less_then_x_peptides(df_list[n].copy(deep=True),\n",
    "                                                                    level, min_nb_of_psms, acc_to_taxid_dict)\n",
    "            df_no_x_hits_unique=df_no_x_hits[get_all_exclusive_rows(df_no_x_hits[f\"taxID_{level}\"])]\n",
    "            print(f\"dfs cleaned from unique hits for level {level}\")\n",
    "            for taxon in species_taxa_list:\n",
    "                # all species taxa, determine genus ans family taxa\n",
    "                taxon_level = taxon_graph.find_level_up(taxon, level)\n",
    "                all_spectra_dict[min_nb_of_psms][taxon][level] = \\\n",
    "                 set(df_no_x_hits[get_taxa_rows(df_no_x_hits[f\"taxID_{level}\"], taxon_level)].Title)\n",
    "                unique_spectra_dict[min_nb_of_psms][taxon][level] = \\\n",
    "                 set(df_no_x_hits_unique[get_taxa_rows(df_no_x_hits_unique[f\"taxID_{level}\"], taxon_level)].Title) \n",
    "                                               \n",
    "            # virus all taxa counted together \n",
    "            if groups:\n",
    "                for group_name, taxa_group in groups.items():\n",
    "                    taxa_level = [taxon_graph.find_level_up(taxon, level) for taxon in taxa_group]\n",
    "                all_spectra_dict[min_nb_of_psms][group_name][level] = \\\n",
    "                 set(df_no_x_hits[get_taxa_rows(df_no_x_hits[f\"taxID_{level}\"], taxa_level)].Title)\n",
    "                unique_spectra_dict[min_nb_of_psms][group_name][level] = \\\n",
    "                 set(df_no_x_hits_unique[get_taxa_rows(df_no_x_hits_unique[f\"taxID_{level}\"], taxa_level)].Title)\n",
    "            # all spectra\n",
    "            all_spectra_dict[min_nb_of_psms]['all'][level] = len(set(df_no_x_hits.Title))\n",
    "    return all_spectra_dict, unique_spectra_dict\n",
    "    \n",
    "def extract_information_from_df_and_write(df_list, species_taxa_list, acc_to_taxid_dict, levels=None, level_groups=None, groups=None, dataset=\"Kleiner\"):\n",
    "    if levels==None:\n",
    "        levels=[\"species\", \"genus\", \"family\"]\n",
    "    all_spectra_dict, unique_spectra_dict = extract_infomation_from_df(df_list, species_taxa_list, \n",
    "                                                                       acc_to_taxid_dict, levels, groups)\n",
    "    write_header(dataset, levels)\n",
    "    write_results(all_spectra_dict, unique_spectra_dict, species_taxa_list, level_groups, groups, dataset, levels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6bcb65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing results for minimum 1 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 2 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 3 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 4 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n"
     ]
    }
   ],
   "source": [
    "#Kleiner set, uniprot\n",
    "levels=[\"species\", \"genus\", \"family\"]\n",
    "species_taxa_list = [tax_tuple[1][0] for tax_tuple in Kleiner_species_taxa]\n",
    "df_list = [df_in_fdr_uniprot_species_sorted, df_in_fdr_uniprot_genus_sorted, df_in_fdr_uniprot_family_sorted]\n",
    "extract_information_from_df_and_write(df_list, species_taxa_list, acc_to_taxid_dict, levels, Kleiner_level_groups, Kleiner_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "da5bf804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading accession2prot database file with 8 threads.\n",
      "10% read.\n",
      "20% read.\n",
      "30% read.\n",
      "40% read.\n",
      "50% read.\n",
      "60% read.\n",
      "70% read.\n",
      "80% read.\n",
      "90% read.\n"
     ]
    }
   ],
   "source": [
    "#load Tanca dfs and accs\n",
    "tanca_df_in_fdr_uniprot_species, tanca_df_in_fdr_uniprot_genus, tanca_df_in_fdr_uniprot_family = load_dfs(tanca_uniprot_tsv)\n",
    "tanca_accs_set = {item for sublist in tanca_df_in_fdr_uniprot_species.Protein for item in sublist}\n",
    "tanca_accs_set = tanca_accs_set.union({item for sublist in tanca_df_in_fdr_uniprot_genus.Protein for item in sublist})\n",
    "tanca_accs_set = tanca_accs_set.union({item for sublist in tanca_df_in_fdr_uniprot_family.Protein for item in sublist})\n",
    "acc_to_taxid_dict_tanca = get_acc2taxid_dict(tanca_accs_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "95fd7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanca_df_in_fdr_uniprot_species = sort_taxid_and_acc_in_df(tanca_df_in_fdr_uniprot_species, 'species', acc_to_taxid_dict_tanca)\n",
    "tanca_df_in_fdr_uniprot_genus = sort_taxid_and_acc_in_df(tanca_df_in_fdr_uniprot_genus, 'genus', acc_to_taxid_dict_tanca)\n",
    "tanca_df_in_fdr_uniprot_family = sort_taxid_and_acc_in_df(tanca_df_in_fdr_uniprot_family, 'family', acc_to_taxid_dict_tanca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b45f1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing results for minimum 1 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n",
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 2 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n",
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 3 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n",
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 4 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n",
      "dfs cleaned from unique hits for level family\n"
     ]
    }
   ],
   "source": [
    "# count Tanca spectra\n",
    "levels=[\"species\", \"genus\", \"family\"]\n",
    "species_taxa_list_tanca = [tax_tuple[1][0] for tax_tuple in Tanca_species_taxa]\n",
    "df_list_tanca = [tanca_df_in_fdr_uniprot_species, tanca_df_in_fdr_uniprot_genus, tanca_df_in_fdr_uniprot_family]\n",
    "extract_information_from_df_and_write(df_list_tanca, species_taxa_list_tanca, acc_to_taxid_dict_tanca, levels, Tanca_level_groups, None, \"Tanca\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0a04aa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[747, 1465, 1579, 1582, 1255, 1351, 5535, 4932, 562]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_taxa_list_tanca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "09c85313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing results for minimum 1 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 2 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 3 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n",
      "Processing results for minimum 4 PSMS per Protein to be counted.\n",
      "dfs cleaned from unique hits for level species\n",
      "dfs cleaned from unique hits for level genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No ancestor with level genus of taxID 101570 exists. TaxID 101570 of level species is returned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs cleaned from unique hits for level family\n"
     ]
    }
   ],
   "source": [
    "#seperated functions for testing\n",
    "levels=[\"species\", \"genus\", \"family\"]\n",
    "species_taxa_list = [tax_tuple[1][0] for tax_tuple in Kleiner_species_taxa]\n",
    "df_list = [tanca_df_in_fdr_uniprot_species, tanca_df_in_fdr_uniprot_genus, df_in_fdr_uniprot_family_sorted]\n",
    "\n",
    "all_spectra_dict, unique_spectra_dict = extract_infomation_from_df(df_list, species_taxa_list, acc_to_taxid_dict,\n",
    "                                                                   levels, Kleiner_groups, None, dataset=\"Tanca\")       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5da53cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_header('Kleiner', levels)\n",
    "write_results(all_spectra_dict, unique_spectra_dict, species_taxa_list, Kleiner_level_groups, Kleiner_groups, 'Kleiner', levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d5e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
