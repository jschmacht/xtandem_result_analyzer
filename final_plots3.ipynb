{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6cf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import argparse\n",
    "from create_reference_from_tsv_and_pepxml import ReferenceWriter\n",
    "from sensitivity_calculator import SensitivityAndSpecificity\n",
    "from create_PSM_df import PSM_FDR\n",
    "from Bio import SeqIO\n",
    "from collections import defaultdict\n",
    "from Bio import pairwise2 as pw2\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b330a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load taxon graph\n",
    "import sys  \n",
    "sys.path.insert(0, '/home/jules/tax2proteome_projects/tax2proteome/')\n",
    "from TaxonGraph import TaxonGraph\n",
    "taxon_graph = TaxonGraph()\n",
    "taxon_graph.create_graph(\"/home/jules/Documents/Metaproteomics/databases/databases_tax2proteome/taxdump.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6963ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "#new_reduced: ohne +1 charge specta\n",
    "uniprot_nr_species_tsv_with_wrong_error = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_new_reduced.tsv\"\n",
    "\n",
    "\n",
    "reference_tsv_with_kleiner_db = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_kleiner_db/Run1_U1_2000ng.t.xml_reduced.tsv\"\n",
    "reference_tsv_with_aradiopsis = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_kleiner_reference_aradiopsis/Run1_U1_2000ng_kleiner_aradiopsis.t.xml_reduced.tsv\"\n",
    "reference_tsv_with_ara_yeast_human = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_kleiner_ara_yeast_human/Run1_U1_2000ng.t.xml_new_reduced.tsv\"\n",
    "path_to_bachelor_results = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/\"\n",
    "path_to_uniprot_reanalysis = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_reanalysis_uniprot\"\n",
    "path_to_tanca_results_bachelor = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/9MM_FASP/x_tandem_tsv\"\n",
    "path_to_kleiner_species_nr_0_9_identity = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/uniprot_species_sequences_0_9_identity/Run1_U1_2000ng_uniprot_species_0_9_identity.t.xml.tsv\"\n",
    "path_to_kleiner_species_nr_0_9_identity_reduced = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/uniprot_species_sequences_0_9_identity/Run1_U1_2000ng_uniprot_species_0_9_identity.t.xml_new_reduced.tsv\"\n",
    "def get_path_to_refernce_analysis_results(fdr):\n",
    "    return f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_kleiner_db/Run1_U1_2000ng.t.xml_reduced.tsv_{fdr}_sensitivity_new\"\n",
    "\n",
    "def get_path_to_refernce_analysis_results_with_aradiopsis(fdr):\n",
    "    return f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_kleiner_reference_aradiopsis/Run1_U1_2000ng_kleiner_aradiopsis.t.xml_reduced.tsv_{fdr}_sensitivity_new\"\n",
    "\n",
    "\n",
    "\n",
    "uniprot_reanalysis = {'species': path_to_uniprot_reanalysis + \"/species/Run1_U1_2000ng_uniprot_species.t.xml_new_reduced.tsv\",\n",
    "                      'species_nr': path_to_uniprot_reanalysis + \"/species_nr/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv\",\n",
    "                      \"species_species\": path_to_uniprot_reanalysis + \"/species_species/Run1_U1_2000ng_uniprot_species_species.t.xml_reduced.tsv\",\n",
    "                      'genus_nr': path_to_uniprot_reanalysis + \"/genus_nr/Run1_U1_2000ng_uniprot_genus_nr.t.xml_reduced.tsv\"\n",
    "                     }\n",
    "    \n",
    "uniprot_nr_reduced_tsv = {\n",
    "    'subspecies': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_subspecies.t.xml_new_reduced.tsv\",\n",
    "    'species': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_genus_nr.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_family_nr.t.xml_new_reduced.tsv\",\n",
    "}\n",
    "    \n",
    "uniprot_reduced_tsv = {\n",
    "    'subspecies': path_to_bachelor_results + \"/ncbi_kleiner/x_tandem_tsv/Run1_U1_2000ng_ncbi_kleiner_subspecies.t.xml_new_reduced.tsv\",\n",
    "    'species': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_species.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_genus.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "\n",
    "uniprot_species_reduced_tsv =  {\n",
    "    'subspecies': path_to_uniprot_reanalysis + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_subspecies.t.xml_new_reduced.tsv\",\n",
    "    'species': path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_species.t.xml_new_reduced.tsv\",\n",
    "    'genus':  path_to_bachelor_results + \"/uniprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_uniprot_genus_species.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "\n",
    "ncbi_reduced_tsv= {\n",
    "    'subspecies': path_to_bachelor_results + \"/ncbi_kleiner/x_tandem_tsv/Run1_U1_2000ng_ncbi_kleiner_subspecies.t.xml_new_reduced.tsv\",\n",
    "    'species': path_to_bachelor_results + \"/ncbi_kleiner/x_tandem_tsv/Run1_U1_2000ng_ncbi_kleiner_species.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_bachelor_results + \"/ncbi_kleiner/x_tandem_tsv/Run1_U1_2000ng_ncbi_kleiner_genus.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "\n",
    "ncbi_species_reduced_tsv = {\n",
    "    'species': path_to_bachelor_results + \"/ncbi_kleiner/x_tandem_tsv/Run1_U1_2000ng_ncbi_kleiner_species_species.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_bachelor_results + \"/ncbi_kleiner/x_tandem_tsv/Run1_U1_2000ng_ncbi_kleiner_genus_species.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "swissprot_reduced_tsv = {\n",
    "    'species': path_to_bachelor_results + \"/swissprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_swissprot_species.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_bachelor_results + \"/swissprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_swissprot_genus.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_bachelor_results + \"/swissprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_swissprot_family.t.xml_new_reduced.tsv\",\n",
    "    'order': path_to_bachelor_results + \"/swissprot_kleiner/x_tandem_tsv/Run1_U1_2000ng_swissprot_order.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "\n",
    "tanca_ncbi_tsv = {\n",
    "    'species': path_to_tanca_results_bachelor + \"/9MM_FASP_ncbi_Tanca_species.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_tanca_results_bachelor + \"/9MM_FASP_ncbi_tanca_genus.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_tanca_results_bachelor + \"/9MM_FASP_ncbi_tanca_family.t.xml_new_reduced.tsv\",\n",
    "}\n",
    "\n",
    "tanca_uniprot_tsv = {\n",
    "    'species': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_species_nr.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_genus.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_family_nr.t.xml_new_reduced.tsv\",\n",
    "    'order': path_to_tanca_results_bachelor + \"/9MM_FASP_uniprot_Tanca_order_nr.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "\n",
    "tanca_swissprot_tsv = {\n",
    "    'species': path_to_tanca_results_bachelor + \"/9MM_FASP_swissprot_tanca_species.t.xml_new_reduced.tsv\",\n",
    "    'genus': path_to_tanca_results_bachelor + \"/9MM_FASP_swissprot_tanca_genus.t.xml_new_reduced.tsv\",\n",
    "    'family': path_to_tanca_results_bachelor + \"/9MM_FASP_swissprot_tanca_family.t.xml_new_reduced.tsv\",\n",
    "    'order': path_to_tanca_results_bachelor + \"/9MM_FASP_swissprot_tanca_order.t.xml_new_reduced.tsv\"\n",
    "}\n",
    "\n",
    "def get_dict_databases_to_size_and_result_file(fdr):\n",
    "    dict_databases_to_size_and_result_file={'reference': (123088, f\"{reference_tsv_with_kleiner_db}_{fdr}_sensitivity_new\"),\n",
    "                                        \"reference_with_aradiopsis\": (138980, f\"{reference_tsv_with_aradiopsis}_{fdr}_sensitivity_new\"),\n",
    "                                        \n",
    "                                        'ncbi_subspecies': (300000, f\"{ncbi_reduced_tsv['subspecies']}_{fdr}_sensitivity_new\"),\n",
    "                                        'ncbi_species': (8702135, f\"{ncbi_reduced_tsv['species']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"ncbi_genus\":(27804893, f\"{ncbi_reduced_tsv['genus']}_{fdr}_sensitivity_new\"),\n",
    "                                        \n",
    "                                        \"uniprot_subspecies\": (4683371, f\"{uniprot_reduced_tsv['subspecies']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_species\": (4683371, f\"{uniprot_reduced_tsv['species']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_species_species\": (2093157, f\"{uniprot_species_reduced_tsv['species']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_subspecies_nr\": (200000, f\"{uniprot_nr_reduced_tsv['subspecies']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_species_nr\": (2991727, f\"{uniprot_nr_reduced_tsv['species']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_genus\": (18352148,  f\"{uniprot_reduced_tsv['genus']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_genus_species\": (13068285,  f\"{uniprot_species_reduced_tsv['genus']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_genus_nr\": (13210287,  f\"{uniprot_nr_reduced_tsv['genus']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"uniprot_family_nr\": (22509624, f\"{uniprot_nr_reduced_tsv['family']}_{fdr}_sensitivity_new\"),\n",
    "                                        \n",
    "                                        \"swissprot_species\": (58505, f\"{swissprot_reduced_tsv['species']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"swissprot_genus\": (88164, f\"{swissprot_reduced_tsv['genus']}_{fdr}_sensitivity_new\" ),\n",
    "                                        \"swissprot_family\": (124044, f\"{swissprot_reduced_tsv['family']}_{fdr}_sensitivity_new\"),\n",
    "                                        \"swissprot_order\": (181725, f\"{swissprot_reduced_tsv['order']}_{fdr}_sensitivity_new\")\n",
    "                                       }\n",
    "    return dict_databases_to_size_and_result_file\n",
    "\n",
    "dict_databases_to_size_and_result_file = get_dict_databases_to_size_and_result_file(0.05)\n",
    "uniprot_dict =dict(filter(lambda item: item[0] in ['uniprot_subspecies', 'uniprot_species', 'uniprot_genus'], dict_databases_to_size_and_result_file.items()))\n",
    "uniprot_nr_dict =dict(filter(lambda item: '_nr' in item[0], dict_databases_to_size_and_result_file.items()))\n",
    "uniprot_species_dict=dict(filter(lambda item: item[0] in ['uniprot_species_species', 'uniprot_genus_species'], dict_databases_to_size_and_result_file.items()))\n",
    "ncbi_dict =dict(filter(lambda item: 'ncbi' in item[0], dict_databases_to_size_and_result_file.items()))\n",
    "swissprot_dict=dict(filter(lambda item: 'swiss' in item[0], dict_databases_to_size_and_result_file.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef65324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_rows_without_charge1(title_col):\n",
    "    return [title.split('.')[-1] != '' for title in title_col]\n",
    "\n",
    "def remove_spectra_of_charge_one_from_reduced_tsv(reduced_tsv):\n",
    "    return reduced_tsv[get_all_rows_without_charge1(reduced_tsv.Title)]\n",
    "\n",
    "def read_all_results_into_dict(file):\n",
    "    result_dict= {}\n",
    "    with open(file, 'r') as inp:\n",
    "        firstline=inp.readline()\n",
    "        db_names = [name.strip() for name in firstline.strip().split('\\t')[1:]]\n",
    "        for db in db_names:\n",
    "            result_dict[db] = {}\n",
    "        for line in inp.readlines():\n",
    "            result_name = line.split('\\t')[0]\n",
    "            result_fields = [name.strip() for name in line.split('\\t')[1:]]\n",
    "            for i, db in enumerate(db_names):\n",
    "                result_dict[db][result_name]=result_fields[i]\n",
    "    return result_dict\n",
    "\n",
    "def read_analysis_results_into_dict(file):\n",
    "    result_dict= {}\n",
    "    with open(file, 'r') as inp:\n",
    "        for line in inp.readlines():\n",
    "            result_dict[line.split('\\t')[0]] = line.split('\\t')[1].strip()\n",
    "   #print(result_dict)\n",
    "    return result_dict\n",
    "\n",
    "def read_TP(file):\n",
    "    TP = int(read_analysis_results_into_dict(file)['TP:'])\n",
    "    return TP\n",
    "\n",
    "def read_TN(file):\n",
    "    TN = int(read_analysis_results_into_dict(file)['TN:'])\n",
    "    return TN\n",
    "\n",
    "def read_FP(file):\n",
    "    TP = int(read_analysis_results_into_dict(file)['FP:'])\n",
    "    return TP\n",
    "\n",
    "def read_FN(file):\n",
    "    TN = int(read_analysis_results_into_dict(file)['FN:'])\n",
    "    return TN\n",
    "\n",
    "def read_sensitivity(file):\n",
    "    sen = float(read_analysis_results_into_dict(file)['sensitivity:'])\n",
    "    return sen\n",
    " \n",
    "def read_specificity(file):\n",
    "    spe = float(read_analysis_results_into_dict(file)['specificity:'])\n",
    "    return spe\n",
    "\n",
    "\n",
    "def read_value_from_result_file(file, database, level, column_of_interest):\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    value = df.loc[(df['level'] == level) & (df['database'] == database)][column_of_interest]\n",
    "    return value.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d193f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_results(filtered_dict):   \n",
    "    db_size = []\n",
    "    score_border = []\n",
    "    result_dict = {}\n",
    "    for file_name, db_size_file_tuple in filtered_dict.items():\n",
    "        result_dict[file_name] = {'db_size': db_size_file_tuple[0]/100000, 'score_border': read_last_score(db_size_file_tuple[1])}\n",
    "\n",
    "    for k, v in result_dict.items():\n",
    "        db_size.append(v['db_size'])\n",
    "        score_border.append(v['score_border'])\n",
    "    return result_dict, db_size, score_border\n",
    "\n",
    "def get_specificity_results(filtered_dict):   \n",
    "    db_size = []\n",
    "    score_border = []\n",
    "    result_dict = {}\n",
    "    for file_name, db_size_file_tuple in filtered_dict.items():\n",
    "        result_dict[file_name] = {'db_size': db_size_file_tuple[0]/100000, 'specificity': read_specificity(db_size_file_tuple[1])}\n",
    "    for k, v in result_dict.items():\n",
    "        db_size.append(v['db_size'])\n",
    "        score_border.append(v['specificity'])\n",
    "    return result_dict, db_size, score_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb30ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoy_rows_from_decoy_column(decoy_column):\n",
    "    return [True if d=={True} else False for d in decoy_column]\n",
    "\n",
    "def get_tax_rows(tax_column, taxid):\n",
    "    return [True if tax_set == {taxid} else False for tax_set in tax_column]\n",
    "\n",
    "def get_decoy_rows_from_protein_column(protein_column):\n",
    "    return [True if 'REVERSED' in p else False for p in protein_column]\n",
    "\n",
    "\n",
    "def get_hit_rows(protein_column):\n",
    "    return [False if 'REVERSED' in p else True for p in protein_column]\n",
    "\n",
    "def get_decoy_rows2(decoy_column):\n",
    "    return [True if d_set in [{True, False}, {True}] else False for d_set in decoy_column]\n",
    "\n",
    "def get_hit_rows2(decoy_column):\n",
    "    return [True if d_set in  [{True, False}, {False}] else False for d_set in decoy_column]\n",
    "\n",
    "def get_not_crap_rows(column_name):\n",
    "    return [True if t_set != {\"CRAP\"} else False for t_set in column_name]\n",
    "\n",
    "def get_taxa_rows(column_name, taxID):\n",
    "    return [True if taxID in t_set else False for t_set in column_name]\n",
    "\n",
    "def get_spectra_rows(spectra_column, spectra_set):\n",
    "    return [True if spectrum in spectra_set else False for spectrum in spectra_column]\n",
    "def get_not_spectra_rows(spectra_column, spectra_set):\n",
    "    return [True if spectrum not in spectra_set else False for spectrum in spectra_column]\n",
    "\n",
    "def get_acc_rows(acc_column, acc_set1, all_acc_contained=True):\n",
    "    \"\"\"\n",
    "    returns rows, where ALL acc in row also in acc_set1\n",
    "    \"\"\"\n",
    "    if all_acc_contained:\n",
    "        return [True if len(acc_set2.difference(acc_set1)) == 0 else False for acc_set2 in acc_column]\n",
    "    else:\n",
    "        return [True if len(acc_set2.intersection(acc_set1)) > 0 else False for acc_set2 in acc_column]\n",
    "\n",
    "def get_not_acc_rows(acc_column, acc_set1, all_acc_contained=True):\n",
    "    if all_acc_contained:\n",
    "        return [False if len(acc_set2.difference(acc_set1)) == 0  else True for acc_set2 in acc_column]\n",
    "    else:\n",
    "        return [False if len(acc_set2.intersection(acc_set1)) > 0  else True for acc_set2 in acc_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20aca416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result_df(f):\n",
    "    df =  ReferenceWriter.read_csv_with_generic_function(f,['Hyperscore', 'taxID', 'decoy'])\n",
    "    return df[['Title', 'Peptide', 'Hyperscore', 'taxID', 'decoy']]\n",
    "    \n",
    "def get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra=False, columns=None):\n",
    "    cs = ['Protein', 'Hyperscore', 'decoy', 'taxID']\n",
    "    if columns:\n",
    "        cs = cs + columns\n",
    "    reduced_df = ReferenceWriter.read_csv_with_generic_function(file, cs, remove_one_charged_spectra)\n",
    "    fdr_pos_result, number_psm_result, number_decoy_result, double_spectra_result, score_last_item_result = PSM_FDR.determine_FDR_position(reduced_df, fdr)\n",
    "    return number_psm_result, reduced_df[0:fdr_pos_result]\n",
    "\n",
    "def get_df_in_fdr_without_decoy(file, fdr, remove_one_charged_spectra=True, columns=None):\n",
    "    df = get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra, columns)[1]\n",
    "    df = df[get_hit_rows2(df.decoy)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f08d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm\n",
    "def create_df_for_df_with_sep_decoy(df_reduced_tsv):\n",
    "    \"\"\"\n",
    "    decoy column values of reduced_tsv file changed to 'PSM' for  {False} and 'DECOY' for {TRUE}\n",
    "    {True, False} values doubled, one as 'PSM' one as 'DECOY'\n",
    "    :return:  Title(=spectrum ID) | Protein set {acc1, acc2} | Hyperscore (float) | decoy (PSM or DECOY)\n",
    "    \"\"\"\n",
    "    def get_true_false(decoy_column):\n",
    "        l = [True if decoy == {True, False} else False for decoy in decoy_column]\n",
    "        return l\n",
    "    # reduce df to columns 'Title', 'Protein', 'Hyperscore', 'decoy'\n",
    "   # df_reduced_tsv = df_reduced_tsv[['Title', 'Protein', 'Hyperscore', 'decoy']]\n",
    "    # df only with rows with value {True, False} in column \"decoy\"\n",
    "    df_true_false = df_reduced_tsv[get_true_false(df_reduced_tsv.decoy)]\n",
    "    # df only with rows with value {True, False} in column \"decoy\"  copyied\n",
    "    df_true = df_true_false.copy(deep=True)\n",
    "    # df value {True, False} in column \"decoy\" changed to {True}\n",
    "    df_true.decoy=[{True} for v in df_true.decoy]\n",
    "    # copied original df with columns 'Title', 'Protein', 'Hyperscore', 'decoy'\n",
    "    df_with_sep_decoy= df_reduced_tsv.copy(deep=True)\n",
    "    # decoy column value {False, True} changed to False\n",
    "    df_with_sep_decoy.decoy = [{False} if v == {False, True} else v for v in df_with_sep_decoy.decoy ]\n",
    "    # df_true rows appended, so decoy entries with {False True} doubled, one with {true}, once with {False}}\n",
    "    df_with_sep_decoy = df_with_sep_decoy.append(df_true, ignore_index=True)\n",
    "    # replace decoy value {True} by DECOY {False} by 'PSM'\n",
    "    df_with_sep_decoy.decoy=['DECOY' if v == {True} else 'PSM' for v in df_with_sep_decoy.decoy]\n",
    "    return df_with_sep_decoy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f86f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_all_level_df_for_histogram_per_db(database_reduced_tsv, db_levels):\n",
    "    \"\"\"\n",
    "    database_reduced_tsv e.g. uniprot_nr_reduced_tsv (dict) or list of paths to reduced tsvs\n",
    "    db_levels: e.g.[species, genus...] or [db_1, db_2]\n",
    "    \"\"\"\n",
    "    \n",
    "    df_reduced_tsv_list = []\n",
    "    result_df_list = []\n",
    "    \n",
    "    if type(database_reduced_tsv)==list:\n",
    "        for reduced_tsv in database_reduced_tsv:\n",
    "            df_reduced_tsv_list.append(ReferenceWriter.read_csv_with_generic_function(reduced_tsv,['Hyperscore',  'decoy'])[['Title', 'Hyperscore',  'decoy']])\n",
    "        for i, df_reduced_tsv in enumerate(df_reduced_tsv_list):\n",
    "            df_level = create_df_for_df_with_sep_decoy(df_reduced_tsv)\n",
    "            df_level['database'] = db_levels[i]\n",
    "            result_df_list.append(df_level)            \n",
    "    else:   \n",
    "        for level in db_levels:\n",
    "            df_reduced_tsv_list.append(ReferenceWriter.read_csv_with_generic_function(database_reduced_tsv[level],['Hyperscore',  'decoy'])[['Title', 'Hyperscore',  'decoy']])\n",
    "        for i, df_reduced_tsv in enumerate(df_reduced_tsv_list):\n",
    "            df_level = create_df_for_df_with_sep_decoy(df_reduced_tsv)\n",
    "            # change subspecies to strain\n",
    "            if db_levels[i] == 'subspecies':\n",
    "                level = 'strain'\n",
    "            else:\n",
    "                level = db_levels[i]\n",
    "            df_level['level'] = level\n",
    "            result_df_list.append(df_level)      \n",
    "    df_all_level = pd.concat(result_df_list)\n",
    "    return df_all_level\n",
    "\n",
    "def get_all_fdr_borders_per_db(db_dict, db_names):\n",
    "    border_list = []\n",
    "    for name in (db_names):\n",
    "        fdr_border_level = float(read_last_score(db_dict[name][1]))\n",
    "        border_list.append(fdr_border_level)\n",
    "    return border_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a1f3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df sensitivity analysis and save\n",
    "def create_sens_dict(file, db, level):\n",
    "    d = read_analysis_results_into_dict(file)\n",
    "    d['database'] = db\n",
    "    d['level'] = level\n",
    "    return d\n",
    "\n",
    "def create_all_analysis_result_df(fdr, tanca=False):\n",
    "    dict_databases_to_size_and_result_file = get_dict_databases_to_size_and_result_file(fdr)\n",
    "    d_list = []\n",
    "    for level in ['subspecies', 'species', 'genus', 'family', 'order']:\n",
    "        try:\n",
    "            d = create_sens_dict(dict_databases_to_size_and_result_file[f'uniprot_{level}_nr'][1], 'uniprot_nr', level)\n",
    "            d_list.append(d)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            d = create_sens_dict(dict_databases_to_size_and_result_file[f'uniprot_{level}'][1], 'uniprot', level)\n",
    "            d_list.append(d)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            d = create_sens_dict(dict_databases_to_size_and_result_file[f'ncbi_{level}'][1], 'ncbi', level)\n",
    "            d_list.append(d)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            d = create_sens_dict(dict_databases_to_size_and_result_file[f'swissprot_{level}'][1], 'swissprot', level)\n",
    "            d_list.append(d)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "    ref_list= []\n",
    "    ref_d =create_sens_dict(get_path_to_refernce_analysis_results(fdr), 'reference', '-')\n",
    "    ref_list.insert(0, ref_d)\n",
    "    ref_d =create_sens_dict(get_path_to_refernce_analysis_results_with_aradiopsis(fdr), 'reference with aradiopsis seq', '-')\n",
    "    ref_list.append(ref_d)\n",
    "\n",
    "    full_df = pd.DataFrame(d_list)\n",
    "    full_df = full_df.sort_values(by=['database'], ignore_index=True)\n",
    "    full_df = pd.concat([pd.DataFrame(ref_list), full_df],  ignore_index=True)\n",
    "    full_df.columns = [head[0:-1] if head.endswith(':') else head for head in list(full_df.columns) ]\n",
    "    full_df = full_df.rename(columns={'Number of spectra identified in result but not in reference': \"nb additional identified spectra\", \n",
    "                            \"Number of spectra identified in result\": \"nb identified spectra\",\n",
    "                           \"Number of PSMs in result\": \"nb PSMs\",\n",
    "                           \"Hyperscore of last item in FDR boundaries\": \"lowest score in FDR\"})\n",
    "    df = full_df[['database', 'level', 'specificity', 'sensitivity', 'TP', 'FP', 'TN', 'FN', \"nb additional identified spectra\",\n",
    "                 \"nb identified spectra\", \"nb PSMs\", \"lowest score in FDR\"]]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa57d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database-size vs. PSMs\n",
    "def get_psm_per_db_from_sens_analysis(df, db):\n",
    "    PSM_identified = []\n",
    "    if db == 'uniprot':\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'uniprot' ].loc[df['level'] == 'subspecies']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'uniprot_nr' ].loc[df['level'] == 'species']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'uniprot_nr' ].loc[df['level'] == 'genus']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'uniprot_nr' ].loc[df['level'] == 'family']['nb PSMs']))\n",
    "        \n",
    "    if db == 'ncbi':\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'ncbi' ].loc[df['level'] == 'subspecies']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'ncbi' ].loc[df['level'] == 'species']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'ncbi' ].loc[df['level'] == 'genus']['nb PSMs']))\n",
    "        \n",
    "    if db == 'swissprot':        \n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'swissprot' ].loc[df['level'] == 'species']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'swissprot' ].loc[df['level'] == 'genus']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'swissprot' ].loc[df['level'] == 'family']['nb PSMs']))\n",
    "        PSM_identified.append(int(df.loc[df['database'] == 'swissprot' ].loc[df['level'] == 'order']['nb PSMs']))\n",
    "    return PSM_identified\n",
    "\n",
    "def create_pd_df_for_psm_plot(PSM_identified_uniprot_percentage, PSM_identified_ncbi_percentage, uniprot_database_sizes, ncbi_database_sizes, PSM_identified_swissprot_percentage=None, swissprot_database_sizes=None):\n",
    "    database = ['UniProtKB' for e in PSM_identified_uniprot_percentage]\n",
    "    database.extend(['NCBI' for e in PSM_identified_ncbi_percentage])\n",
    "    if PSM_identified_swissprot_percentage:\n",
    "        database.extend(['Swissprot' for e in PSM_identified_swissprot_percentage])\n",
    "    psms = PSM_identified_uniprot_percentage + PSM_identified_ncbi_percentage \n",
    "    if PSM_identified_swissprot_percentage:\n",
    "        psms = psms + PSM_identified_swissprot_percentage\n",
    "    dataset = ['kleiner' for e in  database]\n",
    "    level = ['strain', 'species', 'genus', 'family', 'strain', 'species', 'genus']\n",
    "    if PSM_identified_swissprot_percentage:\n",
    "        level = level + ['species', 'genus', 'family', 'order']\n",
    "\n",
    "    database_size = uniprot_database_sizes + ncbi_database_sizes\n",
    "    if swissprot_database_sizes:\n",
    "        database_size = database_size + swissprot_database_sizes\n",
    "    DatabaseSize = pd.DataFrame(list(zip(database_size, level, psms, database, dataset)), columns =['# fasta (M)', 'level', '% PSMs identified', 'database', 'dataset'])\n",
    "    return DatabaseSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d164d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identified spectra in all levels together: 36,84%, deutlich abweichender Wert von Bachelorarbeit 26%:\n",
    "def get_decoy_rows_from_decoy_column_from_merged_df(decoy_column):\n",
    "    result=[]\n",
    "    for d in decoy_column:\n",
    "        # nan \n",
    "        if type(d) != set:\n",
    "            result.append(True)\n",
    "        elif  d=={True}:\n",
    "            result.append(True)\n",
    "        elif  d=={False}:\n",
    "            result.append(False)\n",
    "        elif  d=={True, False}:\n",
    "            result.append(False)\n",
    "        else:\n",
    "            print(d)\n",
    "    return result\n",
    "\n",
    "def get_merged_df_of_all_levels(reduced_tsv_file_dict, fdr, levels):\n",
    "    dfs_in_fdr = []\n",
    "    decoy_columns = []\n",
    "    for level in levels:\n",
    "        number_psm_result, reduced_df_in_fdr = get_psm_and_df_in_fdr(reduced_tsv_file_dict[level], fdr)[1]\n",
    "        reduced_df_in_fdr = reduced_df_in_fdr.rename(columns={'decoy': f'decoy_{level}'})\n",
    "        decoy_columns.append(f'decoy_{level}')\n",
    "        dfs_in_fdr.append(reduced_df_in_fdr)\n",
    "    \n",
    "    merged_df = pd.DataFrame(columns=[\"Title\"])\n",
    "    for reduced_df_in_fdr in dfs_in_fdr:\n",
    "        merged_df = pd.merge(merged_df, reduced_df_in_fdr, how=\"outer\", on='Title')\n",
    "\n",
    "    decoy_lists_per_level = []\n",
    "    for decoy_column_name in decoy_columns:\n",
    "        decoy_list_per_level = get_decoy_rows_from_decoy_column_from_merged_df(merged_df[decoy_column_name])\n",
    "        decoy_lists_per_level.append(decoy_list_per_level)\n",
    "    \n",
    "    final_decoy_list= []\n",
    "    for decoy_tuple in zip(*decoy_lists_per_level):\n",
    "        if False in decoy_tuple:\n",
    "            final_decoy_list.append(True)\n",
    "        else:\n",
    "            final_decoy_list.append(False)\n",
    "            \n",
    "    identified_spectra_of_all_levels_together = len(set(merged_df[final_decoy_list]['Title']))\n",
    "    return merged_df, final_decoy_list, identified_spectra_of_all_levels_together\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbde4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spectra_per_taxon(reduced_df_in_fdr, level, taxon=None, taxa_list=None):\n",
    "    spectra = set()\n",
    "    for spectrum_ID, taxa_set in zip(list(reduced_df_in_fdr['Title']), list(reduced_df_in_fdr[f'taxID_{level}'])):\n",
    "        if taxon:\n",
    "            if taxon in taxa_set:\n",
    "                spectra.add(spectrum_ID)\n",
    "        elif taxa_list:\n",
    "            for taxon in taxa_list:\n",
    "                if taxon in taxa_set:\n",
    "                    spectra.add(spectrum_ID)\n",
    "    return (spectra)\n",
    "\n",
    "def get_percentage_psm_per_taxon(obj, taxID_to_spectra_dict, taxon_str, level):\n",
    "    final_taxa_set= set()\n",
    "    psm_percentage = {}\n",
    "    for taxon in taxon_str.split(', '):\n",
    "        taxon = int(taxon) if taxon not in ['viruses', 'CRAP','DECOY'] else taxon\n",
    "        taxon_of_level = obj.taxon_graph.find_level_up(taxon, level) if level != 'subspecies' else taxon\n",
    "        final_taxa_set=final_taxa_set.union(taxID_to_spectra_dict[taxon_of_level])\n",
    "    psm_percentage = len(final_taxa_set)/obj.psm_count*100\n",
    "    return psm_percentage\n",
    "\n",
    "def get_sized_down_to_100_percentage(percent, sum_percent):\n",
    "    return percent/sum_percent*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b4819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_deviation(path_to_reduced_df, path_to_bachelor_result, level, fdr):\n",
    "    # Mean deviation between percentage identified PSMs per species and protein composition.\n",
    "    # Mean deviation = 1/n  ∗ ∑ |% PSMspecies i − % protein species i |\n",
    "    perc_per_taxa_df = get_perc_per_taxa_df(path_to_reduced_df, path_to_bachelor_result, level, fdr)\n",
    "    sum_mean = 0\n",
    "    for row in perc_per_taxa_df.values.tolist():\n",
    "        sum_mean += abs(row[1]-row[2])\n",
    "    result = sum_mean/len(perc_per_taxa_df)\n",
    "    return result\n",
    "\n",
    "def create_mean_deviation_df(input_files):\n",
    "    # level    database dataset  mean deviation\n",
    "    fdr = 0.1\n",
    "    dict_list = []\n",
    "    for files in input_files['swissprot']:       \n",
    "        mean_deviation = calculate_mean_deviation(files[0], files[1], files[2], fdr)\n",
    "        mean_dict = {'level': files[2], 'database': 'SwissProt', 'dataset': '29MM', 'mean deviation': mean_deviation}\n",
    "        dict_list.append(mean_dict)\n",
    "    for files in input_files['ncbi']:       \n",
    "        mean_deviation = calculate_mean_deviation(files[0], files[1], files[2], fdr)\n",
    "        mean_dict = {'level': files[2], 'database': 'NCBI', 'dataset': '29MM', 'mean deviation': mean_deviation}\n",
    "        dict_list.append(mean_dict)\n",
    "    for files in input_files['uniprot']:       \n",
    "        mean_deviation = calculate_mean_deviation(files[0], files[1], files[2], fdr)\n",
    "        mean_dict = {'level': files[2], 'database': 'UniProtKB', 'dataset': '29MM', 'mean deviation': mean_deviation}\n",
    "        dict_list.append(mean_dict)\n",
    "    mean_deviation_df = pd.DataFrame(dict_list)\n",
    "    return mean_deviation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d256a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import number_of_psm_per_species \n",
    "from number_of_psm_per_species import PsmNumberPerTaxIDs\n",
    "importlib.reload(number_of_psm_per_species)\n",
    "def get_perc_per_taxa_df(path_to_reduced_df, path_to_bachelor_result, level, fdr):\n",
    "    obj = PsmNumberPerTaxIDs('kleiner', path_to_reduced_df, level, fdr)    \n",
    "    taxID_to_spectra_dict = obj.count_row_by_row()\n",
    "    df = pd.read_csv(path_to_bachelor_result, sep='\\t')\n",
    "   # taxon_to_db_percentage = {t:db for t, db in zip(list(df['taxon(s)']), list(df['% database']))}\n",
    "    df['% PSM_not_adapted'] = df.apply(lambda row: get_percentage_psm_per_taxon(obj, taxID_to_spectra_dict, row['taxon(s)'], level), axis=1)\n",
    "    sum_percent = df[~df['% PSM_not_adapted'].isin(['CRAP','DECOY', 'virus'])]['% PSM_not_adapted'].sum()\n",
    "    df['% PSM'] = df.apply(lambda row: get_sized_down_to_100_percentage(row['% PSM_not_adapted'], sum_percent), axis=1)\n",
    "    # print(df)\n",
    "    df = df[[\"taxon(s)\", \"% PSM\", \"% protein\", \"% database\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea16e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_identified_spectra(db, level, fdr):\n",
    "    if 'uniprot' in db.lower():\n",
    "        db= 'uniprot'\n",
    "    if 'ncbi' in db.lower():\n",
    "        db='ncbi'\n",
    "    if 'swiss' in db.lower():\n",
    "        db='swissprot'\n",
    "    nb_all_spectra = 88279\n",
    "    if db == 'uniprot':\n",
    "        if level == 'united':\n",
    "            return get_merged_df_of_all_levels(uniprot_nr_reduced_tsv, fdr, ['subspecies', 'species', 'genus', 'family'])[2]/nb_all_spectra * 100\n",
    "        else:\n",
    "            psm, df_in_fdr = get_psm_and_df_in_fdr(uniprot_nr_reduced_tsv[level], fdr)\n",
    "    if db == 'ncbi':\n",
    "        if level == 'united':\n",
    "            return get_merged_df_of_all_levels(ncbi_reduced_tsv, fdr, ['subspecies', 'species', 'genus'])[2]/nb_all_spectra * 100\n",
    "        else:\n",
    "             psm, df_in_fdr = get_psm_and_df_in_fdr(ncbi_reduced_tsv[level], fdr)\n",
    "    if db == 'swissprot':\n",
    "        if level == 'united':\n",
    "            return get_merged_df_of_all_levels(swissprot_reduced_tsv, fdr, ['species', 'genus', 'family', \"order\"])[2]/nb_all_spectra * 100\n",
    "        else:\n",
    "            psm, df_in_fdr = get_psm_and_df_in_fdr(swissprot_reduced_tsv[level], fdr)\n",
    "    if db == 'reference':\n",
    "        psm, df_in_fdr = get_psm_and_df_in_fdr(reference_tsv_with_kleiner_db, fdr)   \n",
    "    df_no_decoys = df_in_fdr[get_hit_rows2(df_in_fdr.decoy)]\n",
    "    return len(set(df_no_decoys['Title']))/nb_all_spectra * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20b61003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTS FUNCTIONS\n",
    "def create_histograms_in_columns_per_db(df_all_level, border_list, output, title, fdr, c='level'):\n",
    "    \"\"\"\n",
    "    multiple histogramms in one row\n",
    "    \"\"\"\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    g1 = sns.displot(data=df_all_level, \n",
    "                     col=c, \n",
    "                     x=\"Hyperscore\", \n",
    "                     hue=\"decoy\", \n",
    "                     binwidth=1.5, \n",
    "                     palette=['lightblue', 'red'], \n",
    "                     legend=False)\n",
    "    #kde=True : curve insert above hist\n",
    "    axes_subplots = g1.fig.axes\n",
    "    for i, fdr_border in enumerate(border_list):\n",
    "        subplot_axe = axes_subplots[i]\n",
    "        subplot_axe.axvline(fdr_border, linewidth=2, color='black', label='FDR')\n",
    "        y_min, y_max = subplot_axe.get_ylim()\n",
    "        subplot_axe.text(fdr_border+1, y_max-(y_max/10), str(fdr_border), va='bottom')\n",
    "    plt.legend(title='', loc='upper right', labels=[f'{fdr} FDR','DECOY', 'PSM'])\n",
    "    # p.fig.suptitle\n",
    "    plt.suptitle(title,y=1.05)\n",
    "    plt.savefig(output, format='svg')\n",
    "\n",
    "def create_histogramm(df_with_sep_decoy, output, fdr_border, fdr):\n",
    "    \"\"\"\n",
    "    single histogramm\n",
    "    \"\"\"\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    plt.figure(figsize=(20,6))\n",
    "    sns.displot(df_with_sep_decoy, \n",
    "                x=\"Hyperscore\", \n",
    "                hue=\"decoy\", \n",
    "                binwidth=1.5, \n",
    "                palette=['lightblue', 'red'], \n",
    "                legend=False,)    \n",
    "    plt.axvline(fdr_border, linewidth=2, color='black', label='FDR')\n",
    "    axes = plt.gca()\n",
    "    y_min, y_max = axes.get_ylim()\n",
    "    plt.text(fdr_border+1, y_max-(y_max/10), str(fdr_border), va='bottom')\n",
    "    plt.legend(title='', loc='upper right', labels=[f'{fdr} FDR','DECOY', 'PSM'])\n",
    "    plt.suptitle('Reference Database')\n",
    "    plt.savefig(output, format='svg')\n",
    "    return plt\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062104c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_specificity_and_sensitivity_side_by_side_plot(df_spe, df_sen, output):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    p=[sns.color_palette(\"colorblind\")[1], sns.color_palette(\"colorblind\")[0], sns.color_palette(\"colorblind\")[2]]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "    sns.lineplot(ax=axes[0], data=df_spe, x=\"level\", y=\"specificity\", hue='database', palette=p, legend=False)\n",
    "    axes[0].set_title('Specificity')\n",
    "    axes[0].set(ylim=(50, 100))\n",
    "    sns.lineplot(ax=axes[1], data=df_sen, x=\"level\", y=\"sensitivity\", hue='database',  palette=p, legend=False)\n",
    "    axes[1].set_title('Sensitivity')\n",
    "\n",
    "    plt.legend(title='database', bbox_to_anchor=(1, 1), loc=2, labels=['NCBI-nr', 'UniProtKB-nr', 'Swiss-Prot'])\n",
    "    plt.savefig(output, format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fef8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or whitegrid?\n",
    "#xlabels = ['axes.axisbelow':False]\n",
    "def create_db_size_lineplot(DatabaseSize_df, file, output):\n",
    "    uni_color=sns.color_palette(\"colorblind\")[0]\n",
    "    uni_nr_color=sns.color_palette()[9]\n",
    "    ncbi_color=sns.color_palette(\"colorblind\")[1]\n",
    "    ncbi_rh_color = 'orange'\n",
    "    swiss_color=sns.color_palette(\"colorblind\")[2]\n",
    "    palette1=[ncbi_color, uni_color, uni_nr_color, swiss_color]\n",
    "    palette2=[ncbi_color, ncbi_rh_color,  uni_color, uni_nr_color, swiss_color]\n",
    "    if 'kleiner' in file:\n",
    "        title = '29MM'\n",
    "    elif 'tanca' in file:\n",
    "        title = '9MM'\n",
    "    if 'noRH' in file:\n",
    "        g = sns.catplot(x='level', y='# fasta', hue='database', linestyles=[\"-\", \"-\", \"-\", \"-\"],\n",
    "            kind=\"point\", palette=palette1, data=DatabaseSize_df)  \n",
    "        plt.ylim([0,(50000000)])\n",
    "    else:    \n",
    "        g = sns.catplot(x='level', y='size (GB)', hue='database', linestyles=[\"-\", \"-\", \"-\",\"-\", \"-\"],\n",
    "            kind=\"point\", palette=palette2, data=DatabaseSize_df)\n",
    "        plt.ylim([0,43])\n",
    "    g.fig.suptitle(title)\n",
    "    g.savefig(f\"{output}{Path(file +'.txt').stem}.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bfbee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\") \n",
    "def create_fasta_size_vs_identifed_psms_plot(df, output):\n",
    "    plt.clf()\n",
    "    if set(df['dataset']) == {'kleiner'}:\n",
    "        title = '29MM'\n",
    "        p=sns.color_palette(\"colorblind\")[0:4]\n",
    "        palette=[p[1], p[0], p[2], p[3]]\n",
    "        #plt.ylim([0,30])\n",
    "    elif set(df['dataset']) == {'Tanca'}:\n",
    "        title = '9MM'\n",
    "        p=sns.color_palette(\"colorblind\")[0:3]\n",
    "        palette=[p[1], p[0], p[2]]\n",
    "        #plt.ylim([50,100])\n",
    "    g = sns.scatterplot(x='# fasta (M)', y='% PSMs identified', style ='level', hue='database', palette=palette, linestyles=[\"-\", \"-\"], data=df) \n",
    "    sns.lineplot(x='# fasta (M)', y='% PSMs identified', hue='database', legend=False,palette=palette, data=df) \n",
    "    g.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output, format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9833390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_level_vs_identified_barplot(df_for_plot, dataset, output, fdr=0.1):    \n",
    "    title=''\n",
    "    plt.clf()\n",
    "    p=sns.color_palette(\"colorblind\")[0:5]\n",
    "    if fdr == 0.05:\n",
    "        plt.ylim([0,50])\n",
    "    elif fdr == 0.1:\n",
    "        plt.ylim([0,60])\n",
    "    if dataset == 'tanca':\n",
    "        title= '9MM'\n",
    "        plt.ylim([0,100])\n",
    "        palette=[p[1], p[0], p[2]]\n",
    "    elif dataset == 'kleiner':\n",
    "        title= '29MM'\n",
    "        palette=[p[1], p[0], p[2]]\n",
    "    elif dataset =='reference':\n",
    "        title= '29MM'      \n",
    "        palette=[p[4]]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #number = len(set(list(PSM['Database level'])))\n",
    "    #g = sns.barplot(x=\"database level\", y=\"% identified spectra\", hue='database', palette=sns.color_palette(\"hls\", 1), data=df_for_plot\n",
    "    g = sns.barplot(x=\"database level\", y=\"% identified spectra\", hue='database', palette=palette, data=df_for_plot)\n",
    "    handles, labels = g.get_legend_handles_labels()\n",
    "    g.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    g.get_legend().set_visible(True)\n",
    "    for tick in g.get_xticklabels():\n",
    "        tick.set_rotation(0)       \n",
    "    g.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output, format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "074ebf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_identified_spectra_barplot(input_file_list):\n",
    "    for i, file in enumerate(input_file_list):\n",
    "        title=''\n",
    "        plt.clf()   \n",
    "        if 'tanca' in file:\n",
    "            title= '9MM'\n",
    "            plt.ylim([0,100])\n",
    "        elif 'kleiner' in file:\n",
    "            title= '29MM'\n",
    "            plt.ylim([0,30])\n",
    "        PSM_df = pd.read_csv(file+\".txt\", sep='\\t')\n",
    "        print(PSM_df)\n",
    "        PSM_df[\"% PSM identified\"]=get_percentage_identified_spectra_for_uniprot_ncbi_swissprot_all_level(0.05)\n",
    "        number = len(set(list(PSM_df['Database level'])))\n",
    "        g = sns.barplot(x=\"Database level\", y=\"% PSM identified\", hue='Database', palette=sns.color_palette(\"GnBu\", 3), data=PSM)\n",
    "        g.ylabel = '% identified spectra'\n",
    "        handles, labels = g.get_legend_handles_labels()\n",
    "        g.legend(loc='lower center', bbox_to_anchor=(1.2, 0.3))\n",
    "        #g.get_legend().set_visible(False)\n",
    "        for tick in g.get_xticklabels():\n",
    "            tick.set_rotation(0)       \n",
    "        g.set_title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(input_file_list[i]+\".svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d4f6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nb_of_psms_per_species_barplot_and_csv(df, column_name, output, taxon_graph):\n",
    "    new_column_name = f\"{column_name.split('_')[1]}\"\n",
    "    df[new_column_name] = df[column_name].apply(lambda taxid: taxon_graph.get_scientific_name(taxid) if taxid not in ['CRAP', 'DECOY'] else taxid)\n",
    "    plt = df.groupby([new_column_name]).size().plot(kind=\"bar\", ylim=(0,18000), ylabel='# PSMs')\n",
    "    \n",
    "    plt.figure.savefig(output +\".svg\", format='svg', bbox_inches='tight')\n",
    "    df.groupby([new_column_name]).size().to_csv(output +\".csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dedb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psms_per_taxID_plot(path_to_reduced_df, path_to_bachelor_result, level, fdr, outputpath):\n",
    "    # take old df and calculate '% PSM' new for all taxids\n",
    "    sns.set_style(\"white\")\n",
    "    kleiner_palette_strain = [ 'red', 'lightcoral', 'grey', 'darkgrey', 'chocolate', 'mediumpurple','darkorchid','rebeccapurple',   'chocolate', 'limegreen', 'forestgreen', 'grey', 'sienna', 'chocolate', 'firebrick',  'dodgerblue', 'royalblue', 'gold', 'darkorange', 'orange', 'yellow', 'khaki', 'lemonchiffon', 'lightcoral', 'chocolate']\n",
    "    kleiner_palette_species = [ 'red', 'lightcoral', 'grey', 'darkgrey', 'chocolate', 'mediumpurple','darkorchid','rebeccapurple', 'chocolate', 'limegreen', 'forestgreen', 'grey', 'sienna', 'firebrick',  'dodgerblue', 'royalblue', 'gold', 'darkorange', 'orange', 'yellow', 'lemonchiffon', 'lightcoral', 'chocolate']\n",
    "    kleiner_palette_genus = [ 'red', 'lightcoral', 'grey', 'darkgrey', 'chocolate', 'rebeccapurple', 'chocolate', 'limegreen', 'forestgreen', 'grey', 'sienna', 'firebrick',  'dodgerblue', 'royalblue', 'gold', 'darkorange', 'orange', 'yellow', 'lemonchiffon', 'lightcoral', 'chocolate']\n",
    "    kleiner_palette_family = [ 'red', 'lightcoral', 'grey','darkgrey', 'chocolate', 'rebeccapurple', 'chocolate',  'forestgreen', 'grey', 'firebrick',  'royalblue', 'gold', 'darkorange',  'lemonchiffon', 'lightcoral', 'chocolate']\n",
    "    kleiner_palette_order = [ 'red', 'lightcoral', 'grey', 'darkgrey', 'chocolate', 'rebeccapurple', 'chocolate',  'forestgreen', 'grey', 'firebrick',  'royalblue', 'darkorange', 'lemonchiffon', 'lightcoral', 'chocolate']\n",
    "    df = get_perc_per_taxa_df(path_to_reduced_df, path_to_bachelor_result, level, fdr)\n",
    "    print(df)\n",
    "    if level == 'subspecies':\n",
    "        palette=kleiner_palette_strain\n",
    "    elif level == 'species':\n",
    "        palette=kleiner_palette_species\n",
    "    elif level == 'genus':\n",
    "        palette=kleiner_palette_genus\n",
    "    elif level == 'family':\n",
    "        palette=kleiner_palette_family\n",
    "    elif level == 'order':\n",
    "        palette=kleiner_palette_order\n",
    "    if 'ncbi' in path_to_reduced_df:\n",
    "        db = 'NCBI'\n",
    "    elif 'uniprot' in path_to_reduced_df:\n",
    "        db = 'Uniprot'\n",
    "    elif 'swissprot' in path_to_reduced_df:\n",
    "        db = 'Swissprot'\n",
    "           \n",
    "    sns.set_palette(sns.color_palette(palette))\n",
    "    ax = df.set_index('taxon(s)').reindex(df.set_index('taxon(s)').sum().index, axis=1).T.plot(kind='bar', stacked=True, width=0.6,\n",
    "          figsize=(18,9), fontsize=30)\n",
    "    # ,title=(\"Species:Kleiner\\ndatabase: %s   level: %s\" %(db, level))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), loc='lower center', bbox_to_anchor=(1.3, 0.1))\n",
    "    ax.get_legend().set_visible(False)\n",
    "    #ax.set_xticklabels(\"\")\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(0)\n",
    "    plt.tight_layout()\n",
    "    plt.ylim([0,100])\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(Path(outputpath)/(str(Path(path_to_reduced_df).stem)+f\"_{fdr}_taxon_specific_identifications.svg\"), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e754746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lineplot_sens_spec(df_spe_sens, output):\n",
    "    p=sns.color_palette(\"colorblind\")[0:5]\n",
    "    palette=[p[1], p[0], p[2]]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.lineplot(x='level', y='value', data=df_spe_sens, palette=palette, hue='database', style='sens/spe')\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0)\n",
    "    plt.ylabel(\"specificity/sensitivity\")\n",
    "    plt.savefig(output,  bbox_inches='tight')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "383b30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psm_identified_vs_db_size_with_ref(fdr, file):\n",
    "    sns.set_style(\"white\") \n",
    "    plt.clf()\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    # df[\"% PSMs identified\"] = df.apply(lambda row: get_percentage_identified_spectra(row.database, row.level, fdr), axis=1)\n",
    "    # neu berechnet für fdr 0.05\n",
    "    df[\"% PSMs identified\"] = [35.384406, 44.396742, 40.370870, 39.526954, 36.972553, 43.847348, 40.353878]\n",
    "    print(df)\n",
    "    if 'kleiner' in file:\n",
    "        title = '29MM'\n",
    "        #plt.ylim([0,30])\n",
    "    elif 'tanca' in file:\n",
    "        title = '9MM'\n",
    "        #plt.ylim([50,100])\n",
    "    g = sns.scatterplot(x='# fasta (M)', y='% PSMs identified', style ='level', hue='database', palette=['red','blue'],legend=False, linestyles=[\"-\", \"-\"], data=df) \n",
    "    sns.lineplot(x='# fasta (M)', y='% PSMs identified', hue='database', legend=False, palette=['red','blue'], data=df) \n",
    "    \n",
    "    # Reference DB point\n",
    "    ident_ref = get_percentage_identified_spectra('reference', '', 0.05)\n",
    "    plt.scatter(123088/1000000, ident_ref, marker='o', color='black', label='reference DB', s=30)\n",
    "    g.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.legend(title='', loc='upper right', labels=['UniProtKB', 'NCBI', 'reference DB'])\n",
    "    plt.savefig(input[i]+\".svg\", format='svg')\n",
    "    \n",
    "    #g.fig.suptitle(title)\n",
    "    #g.savefig(output[i]+\".svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65b0f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_plot(df_from_analysis, output):\n",
    "    taxa_arabidopsis = 3702\n",
    "    df_from_analysis['mock community'] = df_from_analysis.apply(lambda x : True\n",
    "            if x['taxID_species'] != taxa_arabidopsis and x['taxID_species'] != 'DECOY' else False, axis = 1)  \n",
    "    # Count number of True in the series\n",
    "   # num_ara= len(df_from_analysis['taxID_species'][df_from_analysis['taxID_species'] == {3702}].index)\n",
    "    num_human = len(df_from_analysis['taxID_species'][df_from_analysis['taxID_species'] == {9606}].index)\n",
    "    num_sacc = len(df_from_analysis['taxID_species'][df_from_analysis['taxID_species'] == {4932}].index)\n",
    "    num_taxa = len(df_from_analysis['mock community'][df_from_analysis['mock community'] == True].index)\n",
    "    num_decoy= len(df_from_analysis['decoy'][df_from_analysis['decoy'] == {True}].index)\n",
    "    \n",
    "    # Hyperscore values arabidopsis\n",
    "   # df_from_analysis['ara'] = df_from_analysis.apply(lambda x : True\n",
    "    #        if x['taxID_species'] == {3702} else False, axis = 1)  \n",
    "    #score_ara = df_from_analysis['Hyperscore'][df_from_analysis['ara'] == True]\n",
    "    #df_without_ara = df_from_analysis[['Hyperscore', 'decoy']][df_from_analysis['ara'] == False]\n",
    "    #score_without_ara = df_from_analysis['Hyperscore'][df_from_analysis['decoy']=={False}]\n",
    "    #print(score_ara)\n",
    "    #print(score_without_ara.mean())\n",
    "    # highest 47, lowest 21.1, mean 23.48, all mean = 40.11\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['PSMs'] = [num_taxa, num_decoy, num_human, num_sacc]\n",
    "    print(df)\n",
    "    \n",
    "    #columns=[\"mock community\", 'Decoy', 'Arabidopsis thaliana']\n",
    "    ax = df.T.plot(kind='bar', stacked=True, ylabel='# PSM', title='29MM DB with junk sequences')\n",
    "   # ax.legend(title='', loc='lower center', bbox_to_anchor=(1.3, 0.1), labels=['mock community', 'Decoy', 'Arabidopsis thaliana'])\n",
    "    ax.legend(title='', loc='lower center', bbox_to_anchor=(1.3, 0.1), labels=['mock community', 'Decoy', 'Homo sapiens', 'Saccharomyces cerevisiae'])\n",
    "    ax.figure.savefig(output, format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b723cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_psm_result, df_from_analysis = get_psm_and_df_in_fdr(reference_tsv_with_aradiopsis, 0.05, remove_one_charged_spectra=True, columns=['taxID_species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddcd4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_psm_result, df_from_analysis_0_9 = get_psm_and_df_in_fdr(path_to_kleiner_species_nr_0_9_identity_reduced, 0.05, remove_one_charged_spectra=True, columns=['taxID_species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbad99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_plot(df_from_analysis, \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/arabiopsis_stacked_plot.svg\")\n",
    "print('number of sequences with arabiopsis: 139096, number of sequences without arabiopsis: 123204 , more seq: ', 100 - 123204/139096*100, '%')\n",
    "print(f\"{359/44176*100}% hits are arbiopsis PSMs, assumed false positives: {(359+44176)*0.05}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0437ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_plot(df_more_junk_seq_from_analysis, \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/more_junk_stacked_plot.svg\")\n",
    "(519+182)/42596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50560e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "46620128 / 220000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df sensitivity analysis and save\n",
    "# create_all_analysis_result_df(0.05).to_csv('/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_05_fdr.tsv', sep = '\\t')\n",
    "create_all_analysis_result_df(0.1).to_csv('/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_1_fdr.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ref file\n",
    "kleiner_pep_xml_result = pd.read_csv('/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/spectra/Run1_U1_2000ng.pep.xml.tsv', sep='\\t')\n",
    "kleiner_pep_xml_result = kleiner_pep_xml_result.rename(columns={'Peptide': 'Peptide_ref'})\n",
    "kleiner_pep_xml_result_reduced_df = kleiner_pep_xml_result.groupby([\"Title\", \"Ref_Score\"], as_index=False).agg(\n",
    "            {'ProteinAcc': lambda acc: set(acc), 'Peptide_ref': lambda seq: set(seq)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single histogramm for uniprot species db with 90% sequence identity\n",
    "# 1. read df\n",
    "identity_uni_species_df = ReferenceWriter.read_csv_with_generic_function(path_to_kleiner_species_nr_0_9_identity_reduced,['Protein', 'Hyperscore', 'decoy', 'taxID'])\n",
    "# create df of right format\n",
    "df_with_sep_decoy_ref = create_df_for_df_with_sep_decoy(identity_uni_species_df)\n",
    "# get fdr_border\n",
    "fdr = 0.05\n",
    "result_file = f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/uniprot_species_sequences_0_9_identity/Run1_U1_2000ng_uniprot_species_0_9_identity.t.xml_new_reduced.tsv_0.05_sensitivity_new\"\n",
    "fdr_border = 23.9\n",
    "# plot histogramm\n",
    "create_histogramm(df_with_sep_decoy_ref, f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_reference_{fdr}.svg', fdr_border, fdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441befc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8aae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single histogramm for reference db\n",
    "# 1. read df\n",
    "kleiner_ref_db_df = ReferenceWriter.read_csv_with_generic_function(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_kleiner_db/Run1_U1_2000ng.t.xml_reduced.tsv\",['Protein', 'Hyperscore', 'decoy', 'taxID'])\n",
    "# create df of right format\n",
    "df_with_sep_decoy_ref = create_df_for_df_with_sep_decoy(kleiner_ref_db_df)\n",
    "# get fdr_border\n",
    "fdr = 0.1\n",
    "result_file = f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_1_fdr.tsv\"\n",
    "fdr_border = read_value_from_result_file(result_file, 'reference', '-', 'lowest score in FDR')\n",
    "# plot histogramm\n",
    "create_histogramm(df_with_sep_decoy_ref, f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_reference_{fdr}.svg', fdr_border, fdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e98aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram reference and referece aradiopsis\n",
    "# create df for histogramm, get fdr_borders\n",
    "levels = ['-']\n",
    "dbs = ['reference', 'reference with aradiopsis seq', 'reference with ara yeast human seq']\n",
    "reduced_tsv_dicts = [reference_tsv_with_kleiner_db, reference_tsv_with_aradiopsis, reference_tsv_with_ara_yeast_human]\n",
    "df_for_hist = create_all_level_df_for_histogram_per_db(reduced_tsv_dicts, ['reference', 'reference + 11% false seq', 'reference + 200% false seq'])\n",
    "# get fdr_border\n",
    "for fdr in [0.1, 0.05]:\n",
    "    result_file = f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_{str(fdr).split('.')[-1]}_fdr.tsv\"\n",
    "    border_list = []\n",
    "    for db in dbs:\n",
    "        border_list.append(read_value_from_result_file(result_file, db, levels[0], 'lowest score in FDR'))\n",
    "\n",
    "    # plot and save histogramm\n",
    "    output = f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_reference_with_ara_{fdr}.svg'\n",
    "    create_histograms_in_columns_per_db(df_for_hist, border_list, output, 'Reference', fdr, c=\"database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4752dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramms with subspecies\n",
    "levels = ['subspecies', 'species', 'genus', 'family']\n",
    "db = 'uniprot_nr'\n",
    "reduced_tsv_dict = uniprot_nr_reduced_tsv\n",
    "df_for_hist = create_all_level_df_for_histogram_per_db(reduced_tsv_dict, levels)\n",
    "# get fdr_border\n",
    "for fdr in [0.1, 0.05]:\n",
    "    result_file = f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_{str(fdr).split('.')[-1]}_fdr.tsv\"\n",
    "    border_list = []\n",
    "    for level in levels:\n",
    "        border_list.append(read_value_from_result_file(result_file, db, level, 'lowest score in FDR'))\n",
    "    # plot and save histogramm\n",
    "    output = f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_{db}_with_subspecies_{fdr}.svg'\n",
    "    create_histograms_in_columns_per_db(df_for_hist, border_list, output, 'UniProtKB', fdr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5720ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for histogramm, get fdr_borders\n",
    "levels = ['subspecies', 'species', 'genus']\n",
    "db = 'ncbi'\n",
    "reduced_tsv_dict = ncbi_reduced_tsv\n",
    "df_for_hist = create_all_level_df_for_histogram_per_db(reduced_tsv_dict, levels)\n",
    "# get fdr_border\n",
    "for fdr in [0.1, 0.05]:\n",
    "    result_file = f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_{str(fdr).split('.')[-1]}_fdr.tsv\"\n",
    "    border_list = []\n",
    "    for level in levels:\n",
    "        border_list.append(read_value_from_result_file(result_file, db, level, 'lowest score in FDR'))\n",
    "\n",
    "    # plot and save histogramm\n",
    "    output = f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_{db}_with_subspecies_{fdr}.svg'\n",
    "    create_histograms_in_columns_per_db(df_for_hist, border_list, output, 'NCBI', fdr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b65cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for histogramm, get fdr_borders\n",
    "levels = ['species', 'genus', 'family', 'order']\n",
    "db = 'swissprot'\n",
    "reduced_tsv_dict = swissprot_reduced_tsv\n",
    "df_for_hist = create_all_level_df_for_histogram_per_db(reduced_tsv_dict, levels)\n",
    "# get fdr_border\n",
    "for fdr in [0.1, 0.05]:\n",
    "    result_file = f\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/sensitivity_analysis_0_{str(fdr).split('.')[-1]}_fdr.tsv\"\n",
    "    border_list = []\n",
    "    for level in levels:\n",
    "        border_list.append(read_value_from_result_file(result_file, db, level, 'lowest score in FDR'))\n",
    "\n",
    "    # plot and save histogramm\n",
    "    output = f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_{db}_{fdr}.svg'\n",
    "    create_histograms_in_columns_per_db(df_for_hist, border_list, output, 'SwissProt', fdr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_ncbi_with_subspecies.svg'\n",
    "create_histograms_in_columns_per_db(df_ncbi, border_list_ncbi, output, 'NCBI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/histogramms/histogramm_psm_decoy_swissprot.svg'\n",
    "create_histograms_in_columns_per_db(df_swissprot, border_list_swissprot, output, 'SwissProt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825788e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "fdrs = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "files = [f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv_{fdr}_sensitivity'\n",
    "        for fdr in fdrs]\n",
    "\n",
    "files_ignore_unclassified = [f'/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv_ignore_unclassified_{fdr}_sensitivity' \n",
    "                            for fdr in fdrs]\n",
    "used_files=files_ignore_unclassified\n",
    "TP_values = [read_TP(file) for file in used_files]\n",
    "FN_values = [read_FN(file) for file in used_files]\n",
    "FP_values = [read_FP(file) for file in used_files]\n",
    "TN_values = [read_TN(file) for file in used_files]\n",
    "#fpr = fp/(fp+tn)\n",
    "fpr_values = [FP_values[i]/(FP_values[i]+TN_values[i]) for i in range(len(used_files))]\n",
    "#tpr = tp/(tp+fn) = sensitivity\n",
    "tpr_values =  [TP_values[i]/(TP_values[i]+FN_values[i]) for i in range(len(used_files))]\n",
    "m = max(tpr_values)\n",
    "maxes = [i for i, j in enumerate(tpr_values) if j == m]\n",
    "print('tpr max:', [fdrs[i] for i in maxes])\n",
    "#print(tpr_values)\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "ax.plot(fpr_values, tpr_values)\n",
    "#ax.plot(np.linspace(0, 1, 100),\n",
    " #        np.linspace(0, 1, 100),\n",
    "  #       label='baseline',\n",
    "   #      linestyle='--')\n",
    "plt.title('Receiver Operating Characteristic Curve', fontsize=18)\n",
    "plt.ylabel('TPR', fontsize=16)\n",
    "plt.xlabel('FPR', fontsize=16)\n",
    "#plt.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afe707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity and specificity plot\n",
    "fdr=0.1\n",
    "dict_databases_to_size_and_result_file = get_dict_databases_to_size_and_result_file(fdr)\n",
    "column_names = ['database', 'level', 'specificity', 'sensitivity']\n",
    "rows =[['UniProtKB-nr', 'strain', read_specificity(dict_databases_to_size_and_result_file['uniprot_subspecies'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['uniprot_subspecies'][1])], \n",
    "    ['UniProtKB-nr', 'species', read_specificity(dict_databases_to_size_and_result_file['uniprot_species_nr'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['uniprot_species_nr'][1])], \n",
    "       ['UniProtKB-nr', 'genus', read_specificity(dict_databases_to_size_and_result_file['uniprot_genus_nr'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['uniprot_genus_nr'][1])], \n",
    "       ['UniProtKB-nr', 'family', read_specificity(dict_databases_to_size_and_result_file['uniprot_family_nr'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['uniprot_family_nr'][1])],\n",
    "       ['NCBI-nr', 'strain', read_specificity(dict_databases_to_size_and_result_file['ncbi_subspecies'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['ncbi_subspecies'][1])],\n",
    "      ['NCBI-nr', 'species', read_specificity(dict_databases_to_size_and_result_file['ncbi_species'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['ncbi_species'][1])],\n",
    "       ['NCBI-nr', 'genus', read_specificity(dict_databases_to_size_and_result_file['ncbi_genus'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['ncbi_genus'][1])],\n",
    "      ['Swiss-Prot', 'species', read_specificity(dict_databases_to_size_and_result_file['swissprot_species'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['swissprot_species'][1]) ], \n",
    "       ['Swiss-Prot', 'genus', read_specificity(dict_databases_to_size_and_result_file['swissprot_genus'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['swissprot_genus'][1]) ], \n",
    "       ['Swiss-Prot', 'family', read_specificity(dict_databases_to_size_and_result_file['swissprot_family'][1]), \n",
    "        read_sensitivity(dict_databases_to_size_and_result_file['swissprot_family'][1]) ]]\n",
    "df_spe_sens = pd.DataFrame(rows,columns=column_names)\n",
    "df_spe = df_spe_sens[['database', 'level', 'specificity']]\n",
    "df_sen = df_spe_sens[['database', 'level', 'sensitivity']]\n",
    "df_spe.database=pd.Categorical(df_spe.database,categories=['NCBI-nr', 'UniProtKB-nr', 'Swiss-Prot'])\n",
    "df_spe=df_spe.sort_values('database')\n",
    "df_sen.database=pd.Categorical(df_sen.database,categories=['NCBI-nr', 'UniProtKB-nr', 'Swiss-Prot'])\n",
    "df_sen=df_sen.sort_values('database')\n",
    "create_specificity_and_sensitivity_side_by_side_plot(df_spe, df_sen, \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/sens_spec_0_05.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity and sensitivity with unidentified spectra\n",
    "def create_df_for_lineplot_from_rows_df2(column_names, rows):\n",
    "    df_spe_sens = pd.DataFrame(rows,columns=column_names)\n",
    "    return df_spe_sens\n",
    "\n",
    "fdr = 0.05\n",
    "dict_databases_to_size_and_result_file = get_dict_databases_to_size_and_result_file(fdr)\n",
    "column_names = ['database', 'level', 'value', 'sens/spe']\n",
    "rows =[\n",
    "    ['NCBI-nr', 'strain', read_specificity(dict_databases_to_size_and_result_file['ncbi_subspecies'][1]), 'specificity'], \n",
    "    ['NCBI-nr', 'strain', read_sensitivity(dict_databases_to_size_and_result_file['ncbi_subspecies'][1]), 'sensitivity'],\n",
    "    ['NCBI-nr', 'species', read_specificity(dict_databases_to_size_and_result_file['ncbi_species'][1]), 'specificity'], \n",
    "    ['NCBI-nr', 'species', read_sensitivity(dict_databases_to_size_and_result_file['ncbi_species'][1]), 'sensitivity'],\n",
    "    ['NCBI-nr', 'genus', read_specificity(dict_databases_to_size_and_result_file['ncbi_genus'][1]), 'specificity'], \n",
    "    ['NCBI-nr', 'genus',read_sensitivity(dict_databases_to_size_and_result_file['ncbi_genus'][1]), 'sensitivity'],\n",
    "    ['UniProtKB-nr', 'strain', read_specificity(dict_databases_to_size_and_result_file['uniprot_subspecies'][1]), 'specificity'],\n",
    "    ['UniProtKB-nr', 'strain', read_sensitivity(dict_databases_to_size_and_result_file['uniprot_subspecies'][1]), 'sensitivity'], \n",
    "    ['UniProtKB-nr', 'species', read_specificity(dict_databases_to_size_and_result_file['uniprot_species_nr'][1]), 'specificity'], \n",
    "    ['UniProtKB-nr', 'species', read_sensitivity(dict_databases_to_size_and_result_file['uniprot_species_nr'][1]), 'sensitivity'], \n",
    "    ['UniProtKB-nr', 'genus', read_specificity(dict_databases_to_size_and_result_file['uniprot_genus_nr'][1]), 'specificity'], \n",
    "    ['UniProtKB-nr', 'genus',read_sensitivity(dict_databases_to_size_and_result_file['uniprot_genus_nr'][1]), 'sensitivity'], \n",
    "    ['UniProtKB-nr', 'family', read_specificity(dict_databases_to_size_and_result_file['uniprot_family_nr'][1]), 'specificity'], \n",
    "    ['UniProtKB-nr', 'family', read_sensitivity(dict_databases_to_size_and_result_file['uniprot_family_nr'][1]), 'sensitivity'],\n",
    "    ['Swiss-Prot', 'species', read_specificity(dict_databases_to_size_and_result_file['swissprot_species'][1]), 'specificity'], \n",
    "    ['Swiss-Prot', 'species', read_sensitivity(dict_databases_to_size_and_result_file['swissprot_species'][1]) , 'sensitivity'],\n",
    "    ['Swiss-Prot', 'genus', read_specificity(dict_databases_to_size_and_result_file['swissprot_genus'][1]), 'specificity'], \n",
    "    ['Swiss-Prot', 'genus', read_sensitivity(dict_databases_to_size_and_result_file['swissprot_genus'][1]), 'sensitivity' ], \n",
    "    ['Swiss-Prot', 'family', read_specificity(dict_databases_to_size_and_result_file['swissprot_family'][1]), 'specificity'], \n",
    "    ['Swiss-Prot', 'family',read_sensitivity(dict_databases_to_size_and_result_file['swissprot_family'][1]), 'sensitivity' ]\n",
    "]\n",
    "df_spe_sens = pd.DataFrame(rows,columns=column_names)\n",
    "\n",
    "plt = plot_lineplot_sens_spec(df_spe_sens, '/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/specificity_sensitivity_0_05.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database size\n",
    "db_size_files = [\"/home/jules/Documents/Bachelorarbeit/Graphiken/db_size/database_size_kleiner_noRH\",\n",
    "       \"/home/jules/Documents/Bachelorarbeit/Graphiken/db_size/database_size_kleiner\",\n",
    "       \"/home/jules/Documents/Bachelorarbeit/Graphiken/db_size/database_size_tanca\",\n",
    "       \"/home/jules/Documents/Bachelorarbeit/Graphiken/db_size/database_size_tanca_noRH\"]\n",
    "sns.set_style(\"white\") \n",
    "output = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/database_size/\"\n",
    "for i, file in enumerate(db_size_files):\n",
    "        DatabaseSize_df = pd.read_csv(file+\".txt\", sep='\\t')\n",
    "        DatabaseSize_df['database'] = DatabaseSize_df['database'].replace(['UniProt_NR'],'UniProtKB-nr')\n",
    "        DatabaseSize_df['database'] = DatabaseSize_df['database'].replace(['UniProt'],'UniProtKB')\n",
    "        DatabaseSize_df['database'] = DatabaseSize_df['database'].replace(['NCBI-nr'],'NCBI-nr')\n",
    "        create_db_size_lineplot(DatabaseSize_df, file, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_tanca_spectra = 8471\n",
    "tanca_nb_identified_spectra_0_05 = {}\n",
    "for (db_dict, db) in zip([tanca_swissprot_tsv, tanca_uniprot_tsv, tanca_ncbi_tsv], ['swissprot', 'uniprot', 'ncbi']):\n",
    "    tanca_nb_identified_spectra_0_05[db] = {}\n",
    "    for k, v in db_dict.items():\n",
    "        number_psm_result, df = get_psm_and_df_in_fdr(v, 0.05, remove_one_charged_spectra=True, columns=[f'taxid_{k}'])\n",
    "        df_without_decoy = df[get_hit_rows2(df.decoy)]\n",
    "        number_spectra = len(set(df_without_decoy.Title))\n",
    "        tanca_nb_identified_spectra_0_05[db][k] = (number_spectra, number_spectra/number_tanca_spectra*100)\n",
    "print(tanca_nb_identified_spectra_0_05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tanca_nb_identified_spectra_0_1 = tanca_nb_identified_spectra\n",
    "df_for_plot_tanca = pd.read_csv(\"/home/jules/Documents/Bachelorarbeit/Graphiken/db_size/db_size_psm_tanca.txt\", sep=\"\\t\")\n",
    "df_for_plot_tanca.database=pd.Categorical(df_for_plot_tanca.database,categories=['NCBI', 'UniProtKB_NR', 'SwissProt'])\n",
    "df_for_plot_tanca=df_for_plot_tanca.sort_values('database')\n",
    "psm_identified = [tanca_nb_identified_spectra_0_05['ncbi']['species'][1],tanca_nb_identified_spectra_0_05['ncbi']['genus'][1],\n",
    "                 tanca_nb_identified_spectra_0_05['ncbi']['family'][1],\n",
    "                  tanca_nb_identified_spectra_0_05['uniprot']['species'][1],tanca_nb_identified_spectra_0_05['uniprot']['genus'][1],\n",
    "                 tanca_nb_identified_spectra_0_05['uniprot']['family'][1], tanca_nb_identified_spectra_0_05['uniprot']['order'][1],\n",
    "                 tanca_nb_identified_spectra_0_05['swissprot']['species'][1],tanca_nb_identified_spectra_0_05['swissprot']['genus'][1],\n",
    "                 tanca_nb_identified_spectra_0_05['swissprot']['family'][1], tanca_nb_identified_spectra_0_05['swissprot']['order'][1],]\n",
    "\n",
    "df_for_plot_tanca['% PSMs identified'] = psm_identified\n",
    "print(df_for_plot_tanca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2496653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database-size vs. PSMs\n",
    "full_df = create_all_analysis_result_df(0.1)\n",
    "number_of_spectra = 164414\n",
    "number_of_spectra_passing_quality_control = 88279\n",
    "PSM_identified_uniprot = get_psm_per_db_from_sens_analysis(full_df, 'uniprot')\n",
    "PSM_identified_ncbi = get_psm_per_db_from_sens_analysis(full_df, 'ncbi')\n",
    "PSM_identified_swissprot = get_psm_per_db_from_sens_analysis(full_df, 'swissprot')\n",
    "PSM_identified_ncbi_percentage = [psm/number_of_spectra_passing_quality_control * 100 for psm in PSM_identified_ncbi]\n",
    "PSM_identified_uniprot_percentage= [psm/number_of_spectra_passing_quality_control * 100 for psm in PSM_identified_uniprot]\n",
    "PSM_identified_swissprot_percentage= [psm/number_of_spectra_passing_quality_control * 100 for psm in PSM_identified_swissprot]\n",
    "uniprot_database_sizes = [uniprot_nr_db[0]/1000000 for uniprot_nr_db in uniprot_nr_dict.values()]\n",
    "ncbi_database_sizes = [ncbi_db[0]/1000000 for ncbi_db in ncbi_dict.values()]\n",
    "swissprot_database_sizes = [swissprot_db[0]/1000000 for swissprot_db in swissprot_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42733d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database-size vs. PSMs Plots\n",
    "# identified PSMs deutlich abweichend von Bachelor-Analyse\n",
    "# columns:  # fasta (M)    level  % PSMs identified   database  dataset    \n",
    "df_for_plot_kleiner = create_pd_df_for_psm_plot(PSM_identified_uniprot_percentage, PSM_identified_ncbi_percentage, \n",
    "                                                uniprot_database_sizes, ncbi_database_sizes, PSM_identified_swissprot_percentage, \n",
    "                                                swissprot_database_sizes)\n",
    "all_result_df = create_all_analysis_result_df(0.1)\n",
    "#print(all_result_df)\n",
    "df_reference = pd.DataFrame([[0.1, 'species', 51320/number_of_spectra_passing_quality_control*100, 'Reference', \"kleiner\"]], columns=[\"# fasta (M)\", \"level\", \"% PSMs identified\", \"database\", \"dataset\"])\n",
    "df_for_plot_kleiner = df_for_plot_kleiner.append(df_reference)\n",
    "# kleiner\n",
    "df_for_plot_kleiner['database'] = df_for_plot_kleiner['database'].replace(['UniProtKB'],'UniProtKB-nr')\n",
    "df_for_plot_kleiner['database'] = df_for_plot_kleiner['database'].replace(['Swissprot'],'Swiss-Prot')\n",
    "df_for_plot_kleiner['database'] = df_for_plot_kleiner['database'].replace(['NCBI'],'NCBI-nr')\n",
    "df_for_plot_kleiner.database=pd.Categorical(df_for_plot_kleiner.database,categories=['NCBI-nr', 'UniProtKB-nr', 'Swiss-Prot', 'Reference'])\n",
    "df_for_plot_kleiner=df_for_plot_kleiner.sort_values('database')\n",
    "create_fasta_size_vs_identifed_psms_plot(df_for_plot_kleiner, \n",
    "                                         \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/database_size/kleiner_uni_ncbi_db_psm_vs_db_size_0_1_with_reference.svg\")\n",
    "\n",
    "#tanca\n",
    "df_for_plot_tanca['database'] = df_for_plot_tanca['database'].replace(['SwissProt'],'Swiss-Prot')\n",
    "df_for_plot_tanca['database'] = df_for_plot_tanca['database'].replace(['UniProtKB_NR'],'UniProtKB-nr')\n",
    "df_for_plot_tanca['database'] = df_for_plot_tanca['database'].replace(['NCBI'],'NCBI-nr')\n",
    "# create_fasta_size_vs_identifed_psms_plot(df_for_plot_tanca, \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/database_size/tanca_uni_ncbi_db_psm_vs_db_size_0_05.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f52b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSMs \n",
    "outputfile_kl = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/PSM/kleiner_psm_vs_level_0_05.svg\"\n",
    "# created psm vs dbsize plot\n",
    "#  # fasta (M) database level  % identified spectra   database  dataset\n",
    "df_for_plot_all_db = create_pd_df_for_psm_plot(PSM_identified_uniprot_percentage, PSM_identified_ncbi_percentage, uniprot_database_sizes, ncbi_database_sizes, PSM_identified_swissprot_percentage, swissprot_database_sizes)\n",
    "df_for_plot_all_db = df_for_plot_all_db[df_for_plot_all_db.level != 'order']\n",
    "df_for_plot_all_db = df_for_plot_all_db.rename(columns={'level': 'database level', '% PSMs identified': \"% identified spectra\"})\n",
    "df_for_plot_all_db.database=pd.Categorical(df_for_plot_all_db.database,categories=['NCBI', 'UniProtKB', 'Swissprot'])\n",
    "df_for_plot_all_db=df_for_plot_all_db.sort_values('database')\n",
    "df_for_plot_all_db['database'] = df_for_plot_all_db['database'].replace(['UniProtKB'],'UniProtKB-nr')\n",
    "df_for_plot_all_db['database'] = df_for_plot_all_db['database'].replace(['Swissprot'],'Swiss-Prot')\n",
    "df_for_plot_all_db['database'] = df_for_plot_all_db['database'].replace(['NCBI'],'NCBI-nr')\n",
    "print(df_for_plot_all_db)\n",
    "#create_database_level_vs_identified_barplot(df_for_plot_all_db, 'kleiner', outputfile_kl, 0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a9870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_reference_0_1 = pd.DataFrame([[0.1, 'species', 51320/number_of_spectra_passing_quality_control*100, 'Reference', \"kleiner\"]], columns=[\"# fasta (M)\", \"database level\", \"% PSMs identified\", \"database\", \"dataset\"])\n",
    "df_reference_0_05 = pd.DataFrame([[0.1, 'species', 43482/number_of_spectra_passing_quality_control*100, 'Reference', \"kleiner\"]], columns=[\"# fasta (M)\", \"database level\", \"% PSMs identified\", \"database\", \"dataset\"])\n",
    "df_reference_0_05 = df_reference_0_05.rename(columns={'level': 'database level', '% PSMs identified': \"% identified spectra\"})\n",
    "print(df_reference_0_05)\n",
    "create_database_level_vs_identified_barplot(df_reference_0_05, 'reference', \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/PSM/reference_psm_0_05.svg\", 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot_tanca = pd.read_csv(\"/home/jules/Documents/Bachelorarbeit/Graphiken/db_size/db_size_psm_tanca.txt\", sep=\"\\t\")\n",
    "df_for_plot_tanca['% PSMs identified'] = psm_identified\n",
    "outputfile_tc = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/PSM/tanca_psm_vs_level_0_05.svg\"\n",
    "df_for_plot_all_db_tanca = df_for_plot_tanca.rename(columns={'level': 'database level', '% PSMs identified': \"% identified spectra\"})\n",
    "df_for_plot_all_db_tanca.database=pd.Categorical(df_for_plot_all_db_tanca.database,categories=['NCBI', 'UniProtKB_NR', 'SwissProt'])\n",
    "df_for_plot_all_db_tanca=df_for_plot_all_db_tanca.sort_values('database')\n",
    "df_for_plot_all_db_tanca['database'] = df_for_plot_all_db_tanca['database'].replace(['UniProtKB_NR'],'UniProtKB-nr')\n",
    "df_for_plot_all_db_tanca['database'] = df_for_plot_all_db_tanca['database'].replace(['SwissProt'],'Swiss-Prot')\n",
    "df_for_plot_all_db_tanca['database'] = df_for_plot_all_db_tanca['database'].replace(['NCBI'],'NCBI-nr')\n",
    "print(df_for_plot_all_db_tanca)\n",
    "create_database_level_vs_identified_barplot(df_for_plot_all_db_tanca, 'tanca', outputfile_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cad1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(['A', 'B', 'C', 'D'])\n",
    "set2 = set(['B', 'C', 'D', 'E'])\n",
    "\n",
    "v=venn2([set1, set2], ('Set1', 'Set2'))\n",
    "v.get_patch_by_id('A').set_alpha(1.0)\n",
    "#v.get_patch_by_id('100').set_color('white')\n",
    "v.get_label_by_id('A').set_text('Unknown')\n",
    "v.get_label_by_id('B').set_text('Set \"A\"')\n",
    "plt.title(\"Sample Venn diagram\")\n",
    "plt.annotate('Unknown set', xy=v.get_label_by_id('A').get_position() - np.array([0, 0.05]), xytext=(-70,-70),\n",
    "             ha='center', textcoords='offset points', bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.1),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.5',color='gray'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45447077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spectra set for venn diagramm uniprot\n",
    "fdr = 0.05\n",
    "spectra_in_fdr_uniprot_species =  set(get_df_in_fdr_without_decoy(uniprot_nr_reduced_tsv['species'], fdr)['Title']) \n",
    "spectra_in_fdr_uniprot_species_species = set(get_df_in_fdr_without_decoy(uniprot_species_reduced_tsv['species'], fdr)['Title'])  \n",
    "spectra_in_fdr_uniprot_genus =  set(get_df_in_fdr_without_decoy(uniprot_nr_reduced_tsv['genus'], fdr)['Title'])\n",
    "spectra_in_fdr_uniprot_genus_species =  set(get_df_in_fdr_without_decoy(uniprot_species_reduced_tsv['genus'], fdr)['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bf230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spectra set for venn diagramm ncbi\n",
    "fdr = 0.05\n",
    "spectra_in_fdr_ncbi_species =  set(get_df_in_fdr_without_decoy(ncbi_reduced_tsv['species'], fdr)['Title'])\n",
    "spectra_in_fdr_ncbi_species_species =  set(get_df_in_fdr_without_decoy(ncbi_species_reduced_tsv['species'], fdr)['Title'])\n",
    "spectra_in_fdr_ncbi_genus =  set(get_df_in_fdr_without_decoy(ncbi_reduced_tsv['genus'], fdr)['Title'])\n",
    "spectra_in_fdr_ncbi_genus_species =  set(get_df_in_fdr_without_decoy(ncbi_species_reduced_tsv['genus'], fdr)['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_venn_plot(setA, setB, position):\n",
    "    total = len(setA.union(setB))\n",
    "    v = venn2([setA, setB], set_labels = ('', ''), set_colors=['red', 'yellow'],\n",
    "              subset_label_formatter=lambda x: f\"{(x/total):1.2%}\", ax=axes[position[0]][position[1]])\n",
    "    v.get_patch_by_id('A').set_alpha(1.0)\n",
    "    v.get_patch_by_id('B').set_alpha(1.0)\n",
    "    return v\n",
    "\n",
    "figure, axes = plt.subplots(2, 2)\n",
    "v = get_venn_plot(spectra_in_fdr_uniprot_species, spectra_in_fdr_uniprot_species_species, (0,0))\n",
    "v = get_venn_plot(spectra_in_fdr_uniprot_genus, spectra_in_fdr_uniprot_genus_species, (0,1))\n",
    "v = get_venn_plot(spectra_in_fdr_ncbi_species, spectra_in_fdr_ncbi_species_species, (1,0))\n",
    "v = get_venn_plot(spectra_in_fdr_ncbi_genus, spectra_in_fdr_ncbi_genus_species, (1,1))\n",
    "\n",
    "figure.legend(title='', loc='upper center', labels=['all descandants', 'no sequences below species level'])\n",
    "plt.savefig(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/venn/uniprot_ncbi_venn2.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "total=1000\n",
    "s = lambda x: f\"{(x/total):1.2%}\"\n",
    "s(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ee9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 92470\n",
    "merged_df_u, final_decoy_list_u, identified_spectra_of_all_levels_together_u = get_merged_df_of_all_levels(uniprot_nr_reduced_tsv, 0.1, [\"subspecies\", \"species\", \"genus\", \"family\"])\n",
    "perc_all_u_0_05 = identified_spectra_of_all_levels_together_u/number_of_spectra_passing_quality_control*100\n",
    "print(perc_all_u_0_05)\n",
    "path = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/uniprot_all_level_merged.tsv\"\n",
    "# merged_df_u[final_decoy_list_u][['Title', 'decoy_subspecies', 'decoy_species', 'decoy_genus', 'decoy_family']].to_csv(path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_n, final_decoy_list_n, identified_spectra_of_all_levels_together_n = get_merged_df_of_all_levels(ncbi_reduced_tsv, 0.1, [\"subspecies\", \"species\", \"genus\"])\n",
    "perc_all_n_0_1 = identified_spectra_of_all_levels_together_n/number_of_spectra_passing_quality_control*100\n",
    "print(perc_all_n_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_s, final_decoy_list_s, identified_spectra_of_all_levels_together_s = get_merged_df_of_all_levels(swissprot_reduced_tsv, 0.1, [\"species\", \"genus\", \"family\", \"order\"])\n",
    "perc_all_s_0_1 = identified_spectra_of_all_levels_together_s/number_of_spectra_passing_quality_control*100\n",
    "print(perc_all_s_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_united_values(df, uni_united, ncbi_united, swiss_united=None):\n",
    "    # columns =['# fasta (M)', 'level', '% PSMs identified', 'database', 'dataset']\n",
    "    df.loc[df.index.max() + 1] = ['', 'united', uni_united, 'UniProtKB-nr', 'kleiner']\n",
    "    df.loc[df.index.max() + 1] = ['', 'united', ncbi_united, 'NCBI-nr', 'kleiner']\n",
    "    df.loc[df.index.max() + 1] = ['', 'united', swiss_united, 'Swiss-Prot', 'kleiner']\n",
    "    return df\n",
    "perc_all_u_0_05 = 50.17274776560677\n",
    "perc_all_n_0_05 = 49.22914849511209\n",
    "perc_all_s_0_05 = 29.03861620543957\n",
    "perc_all_u_0_1 = 58.515615265238615\n",
    "perc_all_n_0_1 = 57.611663022915984\n",
    "perc_all_s_0_1 = 33.93219225410347\n",
    "df_for_plot_all_db_with_united = add_united_values(df_for_plot_all_db, perc_all_u_0_1, perc_all_n_0_1, perc_all_s_0_1)\n",
    "#  # fasta (M) database level  % identified spectra   database  dataset\n",
    "df_for_plot_all_db_with_united.columns = ['# fasta (M)', 'database level', '% identified spectra', 'database', 'dataset']\n",
    "\n",
    "print(df_for_plot_all_db_with_united)\n",
    "create_database_level_vs_identified_barplot(df_for_plot_all_db_with_united, 'kleiner', \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/PSM/kleiner_psm_vs_level_united_0_1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28370f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation PSM new calculated\n",
    "path_to_mean_deviation_df = [\"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/mean_deviation_kleiner\",\n",
    "        \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/mean_deviation_tanca\"]\n",
    "sns.set_style(\"white\") \n",
    "\n",
    "for file in path_to_mean_deviation_df:\n",
    "    #deviation_df = create_mean_deviation_df(file)\n",
    "    deviation_df = pd.read_csv(file)\n",
    "    print(deviation_df)\n",
    "    if 'kleiner' in file:\n",
    "        title = '29MM'\n",
    "        g = sns.catplot(x='level', y='mean deviation', hue='database', linestyles=[\"-\", \"-\", \"-\"], kind=\"point\", palette=sns.color_palette(\"colorblind\")[0:4], data=deviation_df)  \n",
    "       # plt.ylim([0,5])\n",
    "    elif 'tanca' in file:\n",
    "        title = '9MM'\n",
    "        g = sns.catplot(x='level', y='mean deviation', hue='database', linestyles=[\"--\", \"--\", \"--\"], kind=\"point\", palette=sns.color_palette(\"colorblind\")[0:4], data=deviation_df)  \n",
    "    plt.ylim([0,13])\n",
    "    plt.ylabel('mean deviation (%)')\n",
    "    #g.fig.suptitle(title)\n",
    "    g.savefig(file+\".svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation PSM bases on bachelor results\n",
    "path_to_mean_deviation_df = [\"/home/jules/Documents/Bachelorarbeit/Graphiken/taxon_specific_identification&db/mean_deviation_kleiner\",\n",
    "        \"/home/jules/Documents/Bachelorarbeit/Graphiken/taxon_specific_identification&db/mean_deviation_tanca\"]\n",
    "sns.set_style(\"white\") \n",
    "\n",
    "for file in path_to_mean_deviation_df:\n",
    "    deviation_df = pd.read_csv(file+\".txt\", sep='\\t')\n",
    "    \n",
    "    deviation_df['database'] = deviation_df['database'].replace(['UniProt'],'UniProtKB-nr')\n",
    "    deviation_df.database=pd.Categorical(deviation_df.database,categories=['NCBI-nr', 'UniProtKB-nr', 'Swiss-Prot'])\n",
    "    deviation_df=deviation_df.sort_values('database')\n",
    "    p = [sns.color_palette('colorblind')[1], sns.color_palette('colorblind')[0], sns.color_palette('colorblind')[2]]\n",
    "    print(deviation_df)\n",
    "    if 'kleiner' in file:\n",
    "        title = '29MM'\n",
    "        g = sns.catplot(x='level', y='mean deviation', hue='database', linestyles=[\"-\", \"-\", \"-\"], kind=\"point\", palette=p, data=deviation_df)  \n",
    "        save_file= \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/mean_deviation/mean_deviation_kleiner.svg\"\n",
    "    # plt.ylim([0,5])\n",
    "    elif 'tanca' in file:\n",
    "        title = '9MM'\n",
    "        g = sns.catplot(x='level', y='mean deviation', hue='database', linestyles=[\"--\", \"--\", \"--\"], kind=\"point\", palette=p, data=deviation_df)  \n",
    "        save_file= \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/mean_deviation/mean_deviation_tanca.svg\"\n",
    "    plt.ylim([0,13])\n",
    "    plt.ylabel('mean deviation (%)')\n",
    "    #g.fig.suptitle(title)\n",
    "    g.savefig(save_file, format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = {\n",
    "    'uniprot':\n",
    "    [(uniprot_nr_reduced_tsv[\"subspecies\"], \n",
    "      \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_unidb_strain.txt\", \"subspecies\"),\n",
    "     (uniprot_nr_reduced_tsv[\"species\"],\n",
    "      \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_unidb_species.txt\", \"species\"),\n",
    "    (uniprot_nr_reduced_tsv[\"genus\"],\n",
    "     \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_unidb_genus.txt\",\"genus\"),\n",
    "    ( uniprot_nr_reduced_tsv[\"family\"],\n",
    "     \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_unidb_family.txt\", \"family\")],\n",
    "    \"ncbi\":\n",
    "    [(ncbi_reduced_tsv[\"subspecies\"],\n",
    "     \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_ncbidb_strain.txt\", \"subspecies\"),\n",
    "     (ncbi_reduced_tsv[\"species\"],\n",
    "      \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_ncbidb_species.txt\", \"species\"),\n",
    "     (ncbi_reduced_tsv[\"genus\"],\n",
    "      \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_ncbidb_genus.txt\", \"genus\")],\n",
    "     \"swissprot\":\n",
    "    [(swissprot_reduced_tsv[\"species\"],\n",
    "      \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_swissprot_species.txt\", 'species'),\n",
    "    (swissprot_reduced_tsv[\"genus\"],\n",
    "     \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_swissprot_genus.txt\", \"genus\"),\n",
    "    (swissprot_reduced_tsv[\"family\"],\n",
    "     \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_swissprot_family.txt\", \"family\"),\n",
    "    (swissprot_reduced_tsv[\"order\"],\n",
    "     \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_swissprot_order.txt\", \"order\")]\n",
    "}\n",
    "\n",
    "other_files = [\"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/taxon_specific_identification&db/Kleiner_ncbidb_genus_species\",\n",
    "              ]\n",
    "outputpath = \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/taxon_specific_identification/\"\n",
    "fdr = 0.1\n",
    "for files in input_files['swissprot']:\n",
    "    create_psms_per_taxID_plot(files[0], files[1], files[2], fdr, outputpath)\n",
    "fdr = 0.1\n",
    "for files in input_files['ncbi']:\n",
    "    create_psms_per_taxID_plot(files[0], files[1], files[2], fdr, outputpath)\n",
    "fdr = 0.1\n",
    "for files in input_files['uniprot']:\n",
    "    create_psms_per_taxID_plot(files[0], files[1], files[2], fdr, outputpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debcc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % PSM identified barplot\n",
    "#PSMs \n",
    "input_files = [\n",
    "    \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/PSM/PSM_kleiner_ncbi_vs_uniprot_vs_swissprot\",\n",
    "    # \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/PSM/PSM_tanca_ncbi_vs_uniprot_vs_swissprot\"\n",
    "]\n",
    "create_identified_spectra_barplot(input_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a68227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database-size vs. PSMs\n",
    "input_files = [\"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/db_size/db_size_psm_tanca.txt\",\n",
    "        \"/home/jules/Documents/Metaproteomics/Bachelorarbeit/Graphiken/db_size/db_size_psm_kleiner.txt\"]\n",
    "create_psm_identified_vs_db_size_with_ref(0.05, input_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from number_of_psm_per_species import PsmNumberPerTaxIDs\n",
    "obj = PsmNumberPerTaxIDs('kleiner', input_files['uniprot'][0][0], input_files['uniprot'][0][2])\n",
    "taxID_to_spectra_dict = obj.count_row_by_row()\n",
    "taxID_to_spectra_dict = obj.get_virus_spectra(taxID_to_spectra_dict)\n",
    "taxID_to_percentage_dict = obj.get_percentage(taxID_to_spectra_dict)\n",
    "print(taxID_to_percentage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_spec_in_fdr = get_df_in_fdr(uniprot_reduced_tsv_species_df, 0.1)\n",
    "# kleiner_pep_xml_result:  Title ProteinAcc  Peptide  Ref_Score\n",
    "# uni_spec_in_fdr: reduced_df of uniprot species matches in FDR-border: Title Peptide  Hyperscore taxID  decoy \n",
    "print('number of identified spectra by Kleiner: ', len(set(kleiner_pep_xml_result['Title'].tolist())))\n",
    "print('number of identified spectra by Uniprot species: ', len(set(uni_spec_in_fdr['Title'].tolist())))\n",
    "# Title  Ref_Score  ProteinAcc Peptide_x (set)  Peptide_y(string)  Hyperscore   taxID    decoy\n",
    "merged_pep_xml_uniprot_df = pd.merge(kleiner_pep_xml_result_reduced_df, uni_spec_in_fdr, how=\"outer\", left_on='Title', right_on=\"Title\")\n",
    "df_identified_in_uniprot = merged_pep_xml_uniprot_df[merged_pep_xml_uniprot_df['Peptide_ref'].isna()]\n",
    "df_identified_in_kleiner_ref = merged_pep_xml_uniprot_df[merged_pep_xml_uniprot_df['Peptide'].isna()]\n",
    "print('number of spectra identified in uniprot species result but not in kleiner: ', len(set(df_identified_in_uniprot['Title'].tolist())))\n",
    "print('number of spectra identified in kleiner but not in uniprot species result: ', len(set(df_identified_in_kleiner_ref['Title'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89392b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of df with one charge spectra and so\n",
    "\n",
    "# now all reduced dataframes without charge one spectra (_new_reduced)\n",
    "uniprot_reduced_tsv_species_nr_new_df = ReferenceWriter.read_csv_with_generic_function(uniprot_nr_reduced_tsv['species'],['Protein', 'Hyperscore', 'decoy', 'taxID'], remove_one_charged_spectra=True)\n",
    "print('number spectra of new reduced df: ',len(uniprot_reduced_tsv_species_nr_new_df))\n",
    "uniprot_reduced_tsv_species_nr_new_df = ReferenceWriter.read_csv_with_generic_function(uniprot_nr_reduced_tsv['species'],['Protein', 'Hyperscore', 'decoy', 'taxID'], remove_one_charged_spectra=False)\n",
    "print('number spectra of new reduced df (removed one charge spectra): ',len(uniprot_reduced_tsv_species_nr_new_df))\n",
    "uniprot_reduced_tsv_species_nr_old_df = ReferenceWriter.read_csv_with_generic_function( \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv\",['Protein', 'Hyperscore', 'decoy', 'taxID'], remove_one_charged_spectra=False)\n",
    "print('number spectra of old reduced df (with one charge spectra): ',len(uniprot_reduced_tsv_species_nr_old_df))\n",
    "uniprot_reduced_tsv_species_nr_old_df = ReferenceWriter.read_csv_with_generic_function( \"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/uniprot/x_tandem_tsv/Run1_U1_2000ng_uniprot_species_nr.t.xml_reduced.tsv\",\n",
    "                                                                                       ['Protein', 'Hyperscore', 'decoy', 'taxID'], remove_one_charged_spectra=True)\n",
    "print('number spectra of old reduced df (removed one charge spectra): ', len(uniprot_reduced_tsv_species_nr_old_df))\n",
    "# check if same df, also new analysis old analysis\n",
    "# a = pd.merge(uniprot_reduced_tsv_species_nr_new_df[['Title', 'Peptide']], uniprot_reduced_tsv_species_nr_old_df[['Title', 'Peptide']], how=\"outer\", on='Title')\n",
    "# Test for differences old and new analysis\n",
    "excluded_spectra = set(a[a.Peptide_x.isna()]['Title']) # 46701\n",
    "print(len(set(a[a.Peptide_y.isna()]['Title']))) # 0\n",
    "excluded_spectra_with_number_at_last_pos = set([spectrum for spectrum in a[a.Peptide_x.isna()]['Title'] if spectrum.split('.')[-1] != '' ])\n",
    "included_spectra = uniprot_reduced_tsv_species_nr_new_df['Title']\n",
    "included_spectra_without_number_at_last_pos = set([spectrum for spectrum in included_spectra if spectrum.split('.')[-1] == '' ])\n",
    "print(included_spectra_without_number_at_last_pos)\n",
    "excluded_spectra_without_number_at_last_pos = set([spectrum for spectrum in excluded_spectra if spectrum.split('.')[-1] == '' ])\n",
    "print(len(excluded_spectra))\n",
    "print(a[a.Peptide_y == 'VGDYTVAIGNPFGLGETVTSGIVSALGR']) # Spectrum Run1_U1_2000ng.151046.151046. und Run1_U1_2000ng.151255.151255. not passed quality control new analysis\n",
    "uniprot_reduced_tsv_genus_nr_new_df = ReferenceWriter.read_csv_with_generic_function(uniprot_nr_reduced_tsv['genus'],['Protein', 'Hyperscore', 'decoy', 'taxID'])\n",
    "intersect = set(uniprot_reduced_tsv_genus_nr_new_df['Title']).intersection(excluded_spectra)\n",
    "print(sorted(list(excluded_spectra_with_number_at_last_pos)))\n",
    "print(sorted(list(intersect)))\n",
    "ncbi_reduced_tsv_subspecies_old_df = ReferenceWriter.read_csv_with_generic_function( ncbi_reduced_tsv['subspecies'], ['Protein', 'Hyperscore', 'decoy', 'taxID'])\n",
    "print(len(ncbi_reduced_tsv_subspecies_old_df))\n",
    "ncbi_reduced_tsv_subspecies_new = remove_spectra_of_charge_one_from_reduced_tsv(ncbi_reduced_tsv_subspecies_old_df)\n",
    "print(len(ncbi_reduced_tsv_subspecies_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20de083",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_spec_in_fdr = uni_spec_in_fdr.rename(columns={'Peptide': 'Peptide_uni'})\n",
    "merged_pep_xml_uniprot_df = pd.merge(kleiner_pep_xml_result_reduced_df, uni_spec_in_fdr, how=\"outer\", on=\"Title\")\n",
    "a = pd.merge(merged_pep_xml_uniprot_df_er, merged_pep_xml_uniprot_df, how=\"outer\", on='Title')\n",
    "b = a[a['Peptide_uni'].isna()][['Title', 'Peptide_ref_x', 'Peptide_ref_y', 'Peptide_uni', 'Peptide_er']]\n",
    "c = b[b['Peptide_er'].notna()]\n",
    "d = c[c['Peptide_ref_x'].notna()]\n",
    "# without quality control: 8 specta more identified (equal to kleiner_ref), all other trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fba7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load taxon graph\n",
    "import sys  \n",
    "sys.path.insert(0, '/home/jules/tax2proteome_projects/tax2proteome/')\n",
    "from TaxonGraph import TaxonGraph\n",
    "taxon_graph = TaxonGraph()\n",
    "taxon_graph.create_graph(\"/home/jules/Documents/Metaproteomics/databases/databases_tax2proteome/taxdump.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50262b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_graph.find_taxIDs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59399b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=uniprot_nr_reduced_tsv['species']\n",
    "fdr=0.1\n",
    "df_uni_species = get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra=True, columns=[\"taxID_species\"])[1]\n",
    "df_uni_species_without_set = df_uni_species.explode('taxID_species').reset_index(drop=True)\n",
    "df_uni_species_without_crap = df_uni_species_without_set[[True if t_set != \"CRAP\" else False for t_set in df_uni_species_without_set.taxID_species]]\n",
    "df_uni_species_without_decoy = df_uni_species_without_crap[[True if t_set != \"DECOY\" else False for t_set in df_uni_species_without_crap.taxID_species]]\n",
    "\n",
    "create_nb_of_psms_per_species_barplot_and_csv(df_uni_species_without_decoy, 'taxID_species', '/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/nb_psm_per_species_barplot_and_csv/nb_psm_per_species_uni_0_1', taxon_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=uniprot_nr_reduced_tsv['genus']\n",
    "fdr=0.1\n",
    "df_uni_genus = get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra=True, columns=[\"taxID_genus\"])[1]\n",
    "df_uni_genus_without_set = df_uni_genus.explode('taxID_genus').reset_index(drop=True)\n",
    "df_uni_genus_without_crap = df_uni_genus_without_set[[True if t_set != \"CRAP\" else False for t_set in df_uni_genus_without_set.taxID_genus]]\n",
    "df_uni_genus_without_decoy = df_uni_genus_without_crap[[True if t_set != \"DECOY\" else False for t_set in df_uni_genus_without_crap.taxID_genus]]\n",
    "\n",
    "create_nb_of_psms_per_species_barplot_and_csv(df_uni_genus_without_decoy, 'taxID_genus', '/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/nb_psm_per_species_barplot_and_csv/nb_psm_per_genus_uni_0_1', taxon_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c096d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file=uniprot_nr_reduced_tsv['family']\n",
    "fdr=0.1\n",
    "df_uni_family = get_psm_and_df_in_fdr(file, fdr, remove_one_charged_spectra=True, columns=[\"taxID_family\"])[1]\n",
    "df_uni_family_without_set = df_uni_family.explode('taxID_family').reset_index(drop=True)\n",
    "df_uni_family_without_crap = df_uni_family_without_set[[True if t_set != \"CRAP\" else False for t_set in df_uni_family_without_set.taxID_family]]\n",
    "df_uni_family_without_decoy = df_uni_family_without_crap[[True if t_set != \"DECOY\" else False for t_set in df_uni_family_without_crap.taxID_family]]\n",
    "\n",
    "create_nb_of_psms_per_species_barplot_and_csv(df_uni_family_without_decoy, 'taxID_family', '/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/nb_psm_per_species_barplot_and_csv/nb_psm_per_family_uni_0_1', taxon_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_uni_family_without_set))\n",
    "len(df_uni_family_without_decoy)\n",
    "create_nb_of_psms_per_species_barplot_and_csv(df_uni_family_without_decoy, 'taxID_family', '/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/plots/nb_psm_per_species_barplot_and_csv/nb_psm_per_family_uni_0_05', taxon_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b21412b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich bacillus.. species vs. family\n",
    "# bacillus species taxon ID: 1423, family taxon ID: 186817\n",
    "# staphylococcus: 1280, 90964\n",
    "# Paracoccus denitrificans 266, 31989\n",
    "# species_df mean score: 41.4, median: 38.5; family_df mean score: 44.1, median: 41.1\n",
    "fdr=0.05\n",
    "df_in_fdr_uniprot_species = get_df_in_fdr_without_decoy(uniprot_nr_reduced_tsv['species'], fdr, columns=['taxID_species']) \n",
    "df_in_fdr_uniprot_family =  get_df_in_fdr_without_decoy(uniprot_nr_reduced_tsv['family'], fdr, columns=['taxID_family'])\n",
    "print(df_in_fdr_uniprot_family.mean())\n",
    "print(df_in_fdr_uniprot_family.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca31bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_fdr_uniprot_species.head()\n",
    "df_species_1423 = df_in_fdr_uniprot_species[get_taxa_rows(df_in_fdr_uniprot_species.taxID_species, 1423)]\n",
    "df_family_186817 = df_in_fdr_uniprot_family[get_taxa_rows(df_in_fdr_uniprot_family.taxID_family, 186817)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e54e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_set_1423 = set(df_species_1423['Title'])\n",
    "spectra_set_186817 = set(df_family_186817['Title'])\n",
    "print(str(len(spectra_set_1423)) + ' ' + str(len(spectra_set_186817)))\n",
    "# waren alle spectra in family schon vorher identifiziert? von (2352-855) neu hinzugekommen, 221 komplett neu\n",
    "spectra_set_new_in_186817=spectra_set_186817.difference(set(df_in_fdr_uniprot_species['Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bda2b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_taxa(df_column):\n",
    "    taxa_count_dict = {}\n",
    "    for tax_set in df_column:\n",
    "        for taxon in tax_set:\n",
    "            if taxon in taxa_count_dict:\n",
    "                taxa_count_dict[taxon]+= 1\n",
    "            else:\n",
    "                taxa_count_dict[taxon]=1\n",
    "    return taxa_count_dict\n",
    "\n",
    "def get_taxon_specific_accs(tax, db):\n",
    "    taxon_accs = set()\n",
    "    len_db=len(db)\n",
    "    all_descending_taxa = taxon_graph.find_taxIDs(tax)\n",
    "    search_strs = [f'OX={taxon}' for taxon in all_descending_taxa]\n",
    "    print(len(all_descending_taxa))\n",
    "    for i, entry in enumerate(db):\n",
    "        if (len_db/(i+1))%10==0:\n",
    "            print(f\"{(i+1)/len_db *100} % db searched\")\n",
    "        if any(taxon in entry.description for taxon in search_strs):\n",
    "            taxon_accs.add(entry.id)\n",
    "    return taxon_accs\n",
    "\n",
    "def get_taxon_specific_accs2(tax, df_acc_taxon):\n",
    "    taxon_accs = set()\n",
    "    all_descending_taxa = taxon_graph.find_taxIDs(tax)\n",
    "    print(len(all_descending_taxa))\n",
    "    for taxon in all_descending_taxa:\n",
    "        taxon_accs.add(entry.id)\n",
    "    return taxon_accs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_db = list(SeqIO.parse(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/Kleiner_ref_db/Kleiner_ref_crap.fasta\", \"fasta\"))\n",
    "uni_s_db = list(SeqIO.parse(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/Tax2Proteome_DB/kleiner_species_nr_crap.fasta\", \"fasta\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4244c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accs(tax):\n",
    "    all_descending_taxa = taxon_graph.find_taxIDs(tax)\n",
    "    acc_set = set()\n",
    "    with open(\"/home/jules/Documents/Metaproteomics/databases/databases_tax2proteome/acc2tax_uniprot\", 'r') as infile:\n",
    "        for line in infile:\n",
    "            fields = line.split('\\t')\n",
    "            try: \n",
    "                taxon = int(fields[1].strip())\n",
    "                if taxon in all_descending_taxa:\n",
    "                    acc_set.add(fields[0].strip())      \n",
    "            except:\n",
    "                continue\n",
    "    return acc_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c57b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_seq(acc1, acc2):\n",
    "    seq1 = wget(f\"https://www.uniprot.org/uniref/{acc1}.fasta\")\n",
    "    seq2 = wget(f\"https://www.uniprot.org/uniref/{acc2}.fasta\")\n",
    "    global_align = pw2.align.globalxx(first_seq, second_seq)\n",
    "    number_matching_AS = global_align[0][2]\n",
    "    percent_matcing = number_matching_seq/len(seq1)*100\n",
    "    return percent_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b3d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87041\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# welche spectra neu dazu für bacillus auf family level\n",
    "df_family_186817_not_in_species_df = df_family_186817[get_not_spectra_rows(df_family_186817.Title, spectra_set_1423)]\n",
    "df_family_186817_not_in_species_df.head()\n",
    "new_identified_peptides = set(df_family_186817_not_in_species_df.Peptide)\n",
    "\n",
    "df_family_186817_not_in_species_df = df_family_186817[~df_family_186817.Title.isin(spectra_set_1423)]\n",
    "df_only_one_taxa = df_family_186817_not_in_species_df[df_family_186817_not_in_species_df.taxID_family == {186817}]\n",
    "print(len(df_only_one_taxa.Title))\n",
    "#print((df_family_186817_not_in_species_df.taxID_family))\n",
    "taxa_count_dict_186815 = count_taxa(df_family_186817_not_in_species_df.taxID_family)\n",
    "print(taxa_count_dict_186815)    \n",
    "new_identified_accs = [acc for acc_set in list(df_family_186817_not_in_species_df.Protein) for acc in acc_set]\n",
    "# print(*list(set([acc.split('|')[1] for acc in flat_list])), sep = \" OR \") \n",
    "\n",
    "#welche spectra schon vorher bekannt #2370, mean=42.6, median=39.8, 172576 different accs\n",
    "df_family_186817_in_species_df = df_family_186817[get_not_spectra_rows(df_family_186817.Title, spectra_set_new_in_186817)]\n",
    "print(len(df_family_186817_not_in_species_df))\n",
    "flat_set = set([acc for acc_set in list(df_family_186817_in_species_df.Protein) for acc in acc_set])\n",
    "print(len(new_identified_accs)) \n",
    "print(len(new_identified_peptides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60d93831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bacillus subtilis \n",
      "identified spectra species: 855 identified spectra family: 2352\n",
      "new identified spectra family: 1712\n",
      "identified only for taxon: 429\n",
      " all spectra counts per taxa: {186817: 1816, 72275: 405, 90964: 452, 543: 904, 32033: 545, 31989: 434, 135621: 617, 119060: 440, 1499392: 232, 206379: 199, 82115: 189, 3051: 11, 188786: 21, 194924: 48, 10662: 4, 10699: 6, 1033997: 1, 'DECOY': 6}\n",
      "davon wurde bereits vorher für andere spezien identifiziert: 1491 spektren.\n"
     ]
    }
   ],
   "source": [
    "# bacillus subtilis spec:1423 fam: 186817\n",
    "# welche spectra komplett neu, Score Werte von 101.1 - 28.3, mean=33.8, median=30.5, davon 8 ribosomale Proteine,\n",
    "# 100 enzyme, 29 uncharacterized, 3 Flagellar (von 285), ATP: 48\n",
    "# anzahl unterschiedlicher Peptide von 1816 spectra, 846 unterschiediche Peptide und 466753 neue accs\n",
    "# davon 450 speziell nur für bacillus, 904 auch in 543, 617 in 125621, 453 un 90964\n",
    "print(\"bacillus subtilis \")\n",
    "df_species_1423 = df_in_fdr_uniprot_species[get_taxa_rows(df_in_fdr_uniprot_species.taxID_species, 1423)]\n",
    "df_family_186817 = df_in_fdr_uniprot_family[get_taxa_rows(df_in_fdr_uniprot_family.taxID_family, 186817)]\n",
    "print(f\"identified spectra species: {len(set(df_species_1423.Title))} identified spectra family: {len(set(df_family_186817.Title))}\")\n",
    "df_family_186817_not_in_species_df=df_family_186817[~df_family_186817.Title.isin(df_species_1423.Title)]\n",
    "print(f\"new identified spectra family: {len(set(df_family_186817_not_in_species_df.Title))}\")\n",
    "df_only_one_taxa_186817 = df_family_186817_not_in_species_df[df_family_186817_not_in_species_df.taxID_family == {186817}]\n",
    "taxa_count_dict_186817 = count_taxa(df_family_186817_not_in_species_df.taxID_family)\n",
    "print(f\"identified only for taxon: {len(set(df_only_one_taxa_186817.Title))}\\n all spectra counts per taxa: {taxa_count_dict_186817}\")\n",
    "df_family_186817_in_species_df = df_family_186817_not_in_species_df[df_family_186817_not_in_species_df.Title.isin(df_in_fdr_uniprot_species.Title)]\n",
    "print(f\"davon wurde bereits vorher für andere spezien identifiziert: {len(set(df_family_186817_in_species_df.Title))} spektren.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a4360fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wie oft neu identifizierte in allen spektren\n",
    "def get_spectra_to_accs(df, accs, name, df_species):\n",
    "    spectra_set =set()\n",
    "    for row in df.values.tolist():\n",
    "        if any(acc in row[1] for acc in accs):\n",
    "            spectra_set.add(row[0])\n",
    "    print(f'In species df identified PSM with {name}: {len(df_species[df_species.Title.isin(spectra_set)])}')\n",
    "\n",
    "def get_new_spectra_characteristics(fam_taxon, df_family_taxon_not_in_species_df, df_family, df_species):\n",
    "    taxa_spec_accs = get_accs(186817)\n",
    "    new_identified_accs = [acc.split('|')[1] for acc_set in list(df_family_taxon_not_in_species_df.Protein) for acc in acc_set]\n",
    "    #new_identified_accs = [acc.split('|')[1] for acc in new_identified_accs]\n",
    "    new_identified_accs_186817 = taxa_spec_accs.intersection(set(new_identified_accs))\n",
    "    print(f\"Number of new identified accs: {len(new_identified_accs_186817)}\")\n",
    "    \n",
    "    acc_to_count_dict = {}\n",
    "    for acc in new_identified_accs_186817:\n",
    "        count = sum([acc in acc_long for acc_long_set in df_family_taxon_not_in_species_df.Protein for acc_long in acc_long_set])\n",
    "        acc_to_count_dict[acc]=count\n",
    "    \n",
    "    acc_count_2_dict={}\n",
    "    acc_count_1_dict={}\n",
    "    acc_count_3_dict={}\n",
    "    acc_count_4_dict={}\n",
    "    acc_count_5_dict={}\n",
    "    for acc, count in acc_to_count_dict.items():\n",
    "        if count ==1 :\n",
    "            acc_count_1_dict[acc]=count\n",
    "        elif count==2:\n",
    "            acc_count_2_dict[acc]=count\n",
    "        elif count==3:\n",
    "            acc_count_3_dict[acc]=count\n",
    "        elif count==4:\n",
    "            acc_count_4_dict[acc]=count\n",
    "        elif count>4:\n",
    "            acc_count_5_dict[acc]=count\n",
    "    print(f\"mit 1 identifikation: {len(acc_count_1_dict)}, mit 2 identifikationen: {len(acc_count_2_dict)},\\n\\\n",
    "    mit 3 identifikationen: {len(acc_count_3_dict)}, mit 4 identifikationen: {len(acc_count_4_dict)}, \\n\\\n",
    "    mit mehr als 4 identifikationen: {len(acc_count_5_dict)}\") \n",
    "    # davon schon im species df identifiziere spektren\n",
    "    df = df_family[['Title','Protein']]\n",
    "    df = df.astype({'Protein': 'string'})\n",
    "\n",
    "\n",
    "    get_spectra_to_accs(df, acc_count_1_dict.keys(), 'count_1', df_species)\n",
    "    get_spectra_to_accs(df, acc_count_2_dict.keys(), 'count_2', df_species)\n",
    "    get_spectra_to_accs(df, acc_count_3_dict.keys(), 'count_3', df_species)\n",
    "    get_spectra_to_accs(df, acc_count_4_dict.keys(), 'count_4', df_species)\n",
    "    get_spectra_to_accs(df, acc_count_5_dict.keys(), 'count_5', df_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c69721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new identified accs: 4459\n",
      "mit 1 identifikation: 2793, mit 2 identifikationen: 543,\n",
      "    mit 3 identifikationen: 496, mit 4 identifikationen: 97, \n",
      "    mit mehr als 4 identifikationen: 530\n",
      "In species df identified PSM with count_1: 412\n",
      "In species df identified PSM with count_2: 322\n",
      "In species df identified PSM with count_3: 168\n",
      "In species df identified PSM with count_4: 105\n",
      "In species df identified PSM with count_5: 1381\n"
     ]
    }
   ],
   "source": [
    "get_new_spectra_characteristics(186817, df_family_186817_not_in_species_df, df_in_fdr_uniprot_family, df_in_fdr_uniprot_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8871e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromobacterium violaceum \n",
      "identified spectra species: 1129 identified spectra family: 1534\n",
      "new identified spectra family: 677\n",
      "identified only for taxon: 95\n",
      " all spectra counts per taxa: {1499392: 715, 32033: 271, 186817: 165, 135621: 372, 72275: 193, 119060: 459, 31989: 186, 543: 246, 206379: 165, 90964: 83, 82115: 99, 194924: 46, 188786: 48, 3051: 4, 10699: 1, 'DECOY': 4, 10744: 1, 1033997: 1}\n",
      "davon wurde bereits vorher für andere spezien identifiziert: 649 spektren\n"
     ]
    }
   ],
   "source": [
    "# chromobacterium violaceum spec: 536 fam: 1499392\n",
    "print(\"chromobacterium violaceum \")\n",
    "df_species_536 = df_in_fdr_uniprot_species[get_taxa_rows(df_in_fdr_uniprot_species.taxID_species, 536)]\n",
    "df_family_1499392 = df_in_fdr_uniprot_family[get_taxa_rows(df_in_fdr_uniprot_family.taxID_family, 1499392)]\n",
    "print(f\"identified spectra species: {len(set(df_species_536.Title))} identified spectra family: {len(set(df_family_1499392.Title))}\")\n",
    "df_family_1499392_not_in_species_df=df_family_1499392[~df_family_1499392.Title.isin(df_species_536.Title)]\n",
    "print(f\"new identified spectra family: {len(set(df_family_1499392_not_in_species_df.Title))}\")\n",
    "df_only_one_taxa_1499392 = df_family_1499392_not_in_species_df[df_family_1499392_not_in_species_df.taxID_family == {1499392}]\n",
    "taxa_count_dict_1499392 = count_taxa(df_family_1499392_not_in_species_df.taxID_family)\n",
    "print(f\"identified only for taxon: {len(set(df_only_one_taxa_1499392.Title))}\\n all spectra counts per taxa: {taxa_count_dict_1499392}\")\n",
    "df_family_1499392_in_species_df = df_family_1499392_not_in_species_df[df_family_1499392_not_in_species_df.Title.isin(df_in_fdr_uniprot_species.Title)]\n",
    "print(f\"davon wurde bereits vorher für andere spezien identifiziert: {len(set(df_family_1499392_in_species_df.Title))} spektren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42a785a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new identified accs: 1708\n",
      "mit 1 identifikation: 531, mit 2 identifikationen: 465,\n",
      "    mit 3 identifikationen: 405, mit 4 identifikationen: 278, \n",
      "    mit mehr als 4 identifikationen: 29\n",
      "In species df identified PSM with count_1: 41\n",
      "In species df identified PSM with count_2: 70\n",
      "In species df identified PSM with count_3: 50\n",
      "In species df identified PSM with count_4: 23\n",
      "In species df identified PSM with count_5: 680\n"
     ]
    }
   ],
   "source": [
    "get_new_spectra_characteristics(1499392, df_family_1499392_not_in_species_df, df_in_fdr_uniprot_family, df_in_fdr_uniprot_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c49f9dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paracoccus dentrificans\n",
      "identified spectra species: 614 identified spectra family: 3026\n",
      "new identified spectra family: 2583\n",
      "identified only for taxon: 975\n",
      " all spectra counts per taxa: {82115: 734, 31989: 2895, 1499392: 469, 186817: 451, 135621: 1042, 90964: 387, 119060: 746, 543: 776, 32033: 603, 72275: 523, 194924: 141, 206379: 255, 10744: 4, 3051: 26, 10662: 6, 188786: 19, 10699: 10, 1033997: 3, 'DECOY': 11}\n",
      "davon wurde bereits vorher für andere spezien identifiziert: 1963 spektren\n"
     ]
    }
   ],
   "source": [
    "# paracoccus dentrificans: spec: 266 fam: 31989\n",
    "print(\"paracoccus dentrificans\")\n",
    "df_species_266 = df_in_fdr_uniprot_species[get_taxa_rows(df_in_fdr_uniprot_species.taxID_species, 266)]\n",
    "df_family_31989 = df_in_fdr_uniprot_family[get_taxa_rows(df_in_fdr_uniprot_family.taxID_family, 31989)]\n",
    "print(f\"identified spectra species: {len(set(df_species_266.Title))} identified spectra family: {len(set(df_family_31989.Title))}\")\n",
    "df_family_31989_not_in_species_df=df_family_31989[~df_family_31989.Title.isin(df_species_266.Title)]\n",
    "print(f\"new identified spectra family: {len(set(df_family_31989_not_in_species_df.Title))}\")\n",
    "df_only_one_taxa_31989 = df_family_31989_not_in_species_df[df_family_31989_not_in_species_df.taxID_family == {31989}]\n",
    "taxa_count_dict_31989 = count_taxa(df_family_31989_not_in_species_df.taxID_family)\n",
    "print(f\"identified only for taxon: {len(set(df_only_one_taxa_31989.Title))}\\n all spectra counts per taxa: {taxa_count_dict_31989}\")\n",
    "df_family_31989_in_species_df = df_family_31989_not_in_species_df[df_family_31989_not_in_species_df.Title.isin(df_in_fdr_uniprot_species.Title)]\n",
    "print(f\"davon wurde bereits vorher für andere spezien identifiziert: {len(set(df_family_31989_in_species_df.Title))} spektren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fef4a46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new identified accs: 11958\n",
      "mit 1 identifikation: 7454, mit 2 identifikationen: 1968,\n",
      "    mit 3 identifikationen: 824, mit 4 identifikationen: 438, \n",
      "    mit mehr als 4 identifikationen: 1274\n",
      "In species df identified PSM with count_1: 477\n",
      "In species df identified PSM with count_2: 186\n",
      "In species df identified PSM with count_3: 143\n",
      "In species df identified PSM with count_4: 114\n",
      "In species df identified PSM with count_5: 898\n"
     ]
    }
   ],
   "source": [
    "get_new_spectra_characteristics(31989, df_family_31989_not_in_species_df, df_in_fdr_uniprot_family, df_in_fdr_uniprot_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "507edde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staphylococcus aureus\n",
      "identified spectra species: 928 identified spectra family: 2850\n",
      "new identified spectra family: 2203\n",
      "identified only for taxon: 46\n",
      " all spectra counts per taxa: {90964: 2217, 543: 2114, 186817: 560, 72275: 423, 32033: 314, 82115: 117, 31989: 182, 135621: 465, 1499392: 198, 194924: 26, 119060: 161, 10744: 13, 3051: 16, 206379: 89, 10662: 9, 10699: 20, 188786: 34, 'DECOY': 3}\n",
      "davon wurde bereits vorher für andere spezien identifiziert: 2162 spektren\n"
     ]
    }
   ],
   "source": [
    "# staphylococcus aureus: spec: 1280 fam: 90964\n",
    "print(\"staphylococcus aureus\")\n",
    "df_species_1280 = df_in_fdr_uniprot_species[get_taxa_rows(df_in_fdr_uniprot_species.taxID_species, 1280)]\n",
    "df_family_90964 = df_in_fdr_uniprot_family[get_taxa_rows(df_in_fdr_uniprot_family.taxID_family, 90964)]\n",
    "print(f\"identified spectra species: {len(set(df_species_1280.Title))} identified spectra family: {len(set(df_family_90964.Title))}\")\n",
    "df_family_90964_not_in_species_df=df_family_90964[~df_family_90964.Title.isin(df_species_1280.Title)]\n",
    "print(f\"new identified spectra family: {len(set(df_family_90964_not_in_species_df.Title))}\")\n",
    "df_only_one_taxa_90964 = df_family_90964_not_in_species_df[df_family_90964_not_in_species_df.taxID_family == {90964}]\n",
    "taxa_count_dict_90964 = count_taxa(df_family_90964_not_in_species_df.taxID_family)\n",
    "print(f\"identified only for taxon: {len(set(df_only_one_taxa_90964.Title))}\\n all spectra counts per taxa: {taxa_count_dict_90964}\")\n",
    "df_family_90964_in_species_df = df_family_90964_not_in_species_df[df_family_90964_not_in_species_df.Title.isin(df_in_fdr_uniprot_species.Title)]\n",
    "print(f\"davon wurde bereits vorher für andere spezien identifiziert: {len(set(df_family_90964_in_species_df.Title))} spektren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57166f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new identified accs: 2564\n",
      "mit 1 identifikation: 1338, mit 2 identifikationen: 689,\n",
      "    mit 3 identifikationen: 274, mit 4 identifikationen: 7, \n",
      "    mit mehr als 4 identifikationen: 256\n",
      "In species df identified PSM with count_1: 72\n",
      "In species df identified PSM with count_2: 62\n",
      "In species df identified PSM with count_3: 94\n",
      "In species df identified PSM with count_4: 68\n",
      "In species df identified PSM with count_5: 837\n"
     ]
    }
   ],
   "source": [
    "get_new_spectra_characteristics(90964, df_family_90964_not_in_species_df, df_in_fdr_uniprot_family, df_in_fdr_uniprot_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60959f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altermonas macleodii\n",
      "identified spectra species: 895 identified spectra family: 2224\n",
      "new identified spectra family: 1562\n",
      "identified only for taxon: 293\n",
      " all spectra counts per taxa: {186817: 279, 72275: 1785, 90964: 361, 543: 1008, 135621: 785, 1499392: 213, 32033: 545, 206379: 188, 119060: 501, 31989: 363, 82115: 175, 3051: 25, 188786: 44, 10744: 11, 194924: 82, 10699: 6, 10662: 4, 'DECOY': 5, 1033997: 1}\n",
      "davon wurde bereits vorher für andere spezien identifiziert: 1432 spektren\n"
     ]
    }
   ],
   "source": [
    "# altermonas macleodii spec: 28108, fam: 72275\n",
    "print(\"altermonas macleodii\")\n",
    "df_species_28108 = df_in_fdr_uniprot_species[get_taxa_rows(df_in_fdr_uniprot_species.taxID_species, 28108)]\n",
    "df_family_72275 = df_in_fdr_uniprot_family[get_taxa_rows(df_in_fdr_uniprot_family.taxID_family, 72275)]\n",
    "print(f\"identified spectra species: {len(set(df_species_28108.Title))} identified spectra family: {len(set(df_family_72275.Title))}\")\n",
    "df_family_72275_not_in_species_df=df_family_72275[~df_family_72275.Title.isin(df_species_28108.Title)]\n",
    "print(f\"new identified spectra family: {len(set(df_family_72275_not_in_species_df.Title))}\")\n",
    "df_only_one_taxa_72275 = df_family_72275_not_in_species_df[df_family_72275_not_in_species_df.taxID_family == {72275}]\n",
    "taxa_count_dict_72275 = count_taxa(df_family_72275_not_in_species_df.taxID_family)\n",
    "print(f\"identified only for taxon: {len(set(df_only_one_taxa_72275.Title))}\\n all spectra counts per taxa: {taxa_count_dict_72275}\")\n",
    "df_family_72275_in_species_df = df_family_72275_not_in_species_df[df_family_72275_not_in_species_df.Title.isin(df_in_fdr_uniprot_species.Title)]\n",
    "print(f\"davon wurde bereits vorher für andere spezien identifiziert: {len(set(df_family_72275_in_species_df.Title))} spektren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb818385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new identified accs: 5149\n",
      "mit 1 identifikation: 2137, mit 2 identifikationen: 320,\n",
      "    mit 3 identifikationen: 1153, mit 4 identifikationen: 82, \n",
      "    mit mehr als 4 identifikationen: 1457\n",
      "In species df identified PSM with count_1: 133\n",
      "In species df identified PSM with count_2: 58\n",
      "In species df identified PSM with count_3: 112\n",
      "In species df identified PSM with count_4: 20\n",
      "In species df identified PSM with count_5: 833\n"
     ]
    }
   ],
   "source": [
    "get_new_spectra_characteristics(72275, df_family_72275_not_in_species_df, df_in_fdr_uniprot_family, df_in_fdr_uniprot_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db085e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading 9MM species and family:\n",
    "fdr=0.05\n",
    "tanca_species_df = get_df_in_fdr_without_decoy(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/9MM_FASP/x_tandem_tsv/9MM_FASP_uniprot_Tanca_species_nr.t.xml_new_reduced.tsv\", fdr, columns=['taxID_species'])\n",
    "tanca_genus_df = get_df_in_fdr_without_decoy(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/results_searchgui_xtandem_analyzer_bachelor_thesis/9MM_FASP/x_tandem_tsv/9MM_FASP_uniprot_Tanca_family_nr.t.xml_new_reduced.tsv\", fdr, columns=['taxID_family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c259bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rhodotorula glutinis spec: 5535, genus: 5533\n",
    "print(\"rhodotorula glutinis\")\n",
    "df_species_5535 = tanca_species_df[get_taxa_rows(tanca_species_df.taxID_species, 5535)]\n",
    "df_genus_5533 = tanca_genus_df[get_taxa_rows(tanca_genus_df.taxID_genus, 5533)]\n",
    "print(f\"identified spectra species: {len(set(df_species_5535.Title))} identified spectra genu: {len(set(df_genus_5533.Title))}\")\n",
    "df_genus_5533_not_in_species_df=df_genus_5533[~df_genus_5533.Title.isin(df_species_5535.Title)]\n",
    "print(f\"new identified spectra family: {len(set(df_family_72275_not_in_species_df.Title))}\")\n",
    "df_only_one_taxa_72275 = df_family_72275_not_in_species_df[df_family_72275_not_in_species_df.taxID_family == {72275}]\n",
    "taxa_count_dict_72275 = count_taxa(df_family_72275_not_in_species_df.taxID_family)\n",
    "print(f\"identified only for taxon: {len(set(df_only_one_taxa_72275.Title))}\\n all spectra counts per taxa: {taxa_count_dict_72275}\")\n",
    "df_family_72275_in_species_df = df_family_72275_not_in_species_df[df_family_72275_not_in_species_df.Title.isin(df_in_fdr_uniprot_species.Title)]\n",
    "print(f\"davon wurde bereits vorher für andere spezien identifiziert: {len(set(df_family_72275_in_species_df.Title))} spektren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_family_186817_not_in_species_df.Peptide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_fdr_uniprot_species[df_in_fdr_uniprot_species.Title == 'Run1_U1_2000ng.153630.153630.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare additional identified reference to uniprot species\n",
    "fdr=0.05\n",
    "df_in_fdr_ref = get_df_in_fdr_without_decoy(reference_tsv_with_kleiner_db, fdr, columns=['taxID_species']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(df_in_fdr_ref.Title)))\n",
    "print(len(set(df_in_fdr_ref[df_in_fdr_ref.decoy != {True}].Title)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c736150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_fdr_uniprot_species = get_df_in_fdr_without_decoy(uniprot_nr_reduced_tsv['species'], fdr, columns=['taxID_species']) \n",
    "cs = ['Protein', 'Hyperscore', 'decoy', 'taxID', 'taxID_species']\n",
    "df_full_uniprot_species = ReferenceWriter.read_csv_with_generic_function(uniprot_nr_reduced_tsv['species'], cs, remove_one_charged_spectra=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5166738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(set(df_in_fdr_uniprot_species.Title)))\n",
    "print(len(set(df_in_fdr_uniprot_species[df_in_fdr_uniprot_species.decoy != {True}].Title)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_db = list(SeqIO.parse(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/Kleiner_ref_db/Kleiner_ref_crap.fasta\", \"fasta\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_accs_with_no_diamond_result(ref_db, set_to_compare):\n",
    "    missing_accs = set()\n",
    "    for entry in ref_db:\n",
    "        if entry.id not in set_to_compare:\n",
    "            missing_accs.add(entry.id)\n",
    "    return missing_accs\n",
    "    \n",
    "# file enthält alle kleiner accs die auch in der uniprot_species_nr DB drin waren\n",
    "# nur 84 Identifikationen, 100% match: 3943 PSMs, #all matchs: 84 PSMs\n",
    "acc_score_df = pd.read_csv('/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/number_ref_seq_in_db/matches_tax2proteome_kleiner_ref_one_accs.tsv', header=None, names=[\"acc\", \"score\"], sep=\"\\t\")\n",
    "acc_set_in_both = set(acc_score_df[acc_score_df.score == 100].acc)\n",
    "# have to add sequences with no match\n",
    "acc_set_only_in_ref = set(acc_score_df[acc_score_df.score != 100].acc)\n",
    "all_acc_in_ref_df = {item for sublist in df_in_fdr_ref.Protein for item in sublist if 'REVERSED' not in item}\n",
    "acc_no_blast_match = all_acc_in_ref_df.difference(set(acc_score_df.acc))\n",
    "#print(acc_no_blast_match)\n",
    "missing_acc_set = add_accs_with_no_diamond_result(ref_db, set(acc_score_df.acc))\n",
    "print(len(missing_acc_set))\n",
    "acc_set_only_in_ref = acc_set_only_in_ref.union(missing_acc_set)\n",
    "print(len(acc_set_only_in_ref))\n",
    "print(f\"number sequences in tax2proteome uniprot species db (100% match): {len(acc_set_in_both)}\\n\\\n",
    "number sequences only in reference: (<100 % match) {len(acc_set_only_in_ref)}\\n\\\n",
    "number accs in ref DB: {len(acc_score_df)}\")\n",
    "ref_df_acc_not_in_t2p_df = df_in_fdr_ref[get_not_acc_rows(df_in_fdr_ref.Protein, acc_set_in_both, False)]\n",
    "ref_df_acc_not_in_t2p_df_2 = df_in_fdr_ref[get_acc_rows(df_in_fdr_ref.Protein, acc_set_only_in_ref, True)]\n",
    "ref_df_acc_in_t2p_df = df_in_fdr_ref[get_acc_rows(df_in_fdr_ref.Protein, acc_set_in_both, False)]\n",
    "#print(ref_df_acc_not_in_t2p_df[['Title', 'Protein', 'Hyperscore']].head())\n",
    "#print(ref_df_acc_not_in_t2p_df_2[['Title', 'Protein', 'Hyperscore']].head())\n",
    "print(f\"number identified spectra in ref in fdr: {len(set(df_in_fdr_ref.Title))}\")\n",
    "print(f\"number identified spectra in ref in fdr with all acc in Protein set not 100% match to t2p DB: {len(set(ref_df_acc_not_in_t2p_df.Title))} \\\n",
    "together: {len(set(ref_df_acc_not_in_t2p_df.Title))+ len(set(ref_df_acc_in_t2p_df.Title))}\")\n",
    "print(f\"number identified spectra in ref in fdr with all acc in Protein set not 100% match to t2p DB: {len(set(ref_df_acc_not_in_t2p_df_2.Title))} \\\n",
    "together: {len(set(ref_df_acc_not_in_t2p_df_2.Title))+ len(set(ref_df_acc_not_in_t2p_df_2.Title))}\")\n",
    "print(f\"number identified spectra in T2P in fdr with acc also contained in ref: {len(set(ref_df_acc_in_t2p_df.Title))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% match: 3943 PSMs, #all matchs: 84 PSMs #unique spectra identified in Kleiner (>24): 564\n",
    "# missing spectra with higher fdr:\n",
    "df_uni_spec_in_missing_th = df_full_uniprot_species[(df_full_uniprot_species.Hyperscore >= 20.8)  & (df_full_uniprot_species.Hyperscore<23.7) & (df_full_uniprot_species.decoy!={True})].sort_values(by=['Hyperscore'])\n",
    "spectra_in_this_range = set(df_uni_spec_in_missing_th.Title)\n",
    "peptides_in_this_range = set(df_uni_spec_in_missing_th.Peptide)\n",
    "df_spectra_in_this_range =df_in_fdr_uniprot_species[df_in_fdr_uniprot_species.Title.isin(spectra_in_this_range)]\n",
    "df_peptides_in_this_range = df_in_fdr_uniprot_species[df_in_fdr_uniprot_species.Peptide.isin(peptides_in_this_range)]\n",
    "\n",
    "print(\"number spectra in Hyperscore range betwenn 20.8 -23.7: \", len(spectra_in_this_range))\n",
    "print(\"number peptides in Hyperscore range betwenn 20.8 -23.7: \", len(peptides_in_this_range))\n",
    "print(\"len DF gefiltert nach Spektren, die in Hyperscore range betwenn 20.8 -23.7 liegen: \"\", len(df_spectra_in_this_range))\n",
    "print(\"len DF gefiltert nach Peptiden, die in Hyperscore range betwenn 20.8 -23.7 liegen: \", len(df_peptides_in_this_range))\n",
    "#print(peptides_in_this_range)\n",
    "#print(df_uni_spec_in_missing_th.head())\n",
    "#df_uni_spec_in_missing_th.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df93935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#proteins_ = {item for sublist in df_acc_not_in_this_range.Protein for item in sublist}\n",
    "#print(len(proteins_.intersection(proteins_in_this_range)))\n",
    "print('reference df: ', len(set(df_in_fdr_ref.Title)))\n",
    "print('uniprot species df: ', len(set(df_in_fdr_uniprot_species.Title)))\n",
    "print('uniprot species df acc: ', len(set(df_acc_not_in_this_range.Title)))\n",
    "print('uniprot species df spectra: ',len(set(df_spectra_in_this_range.Title)))\n",
    "print('uniprot species df peptides: ',len(set(df_peptides_not_in_this_range.Title)))\n",
    "df_spectra_in_this_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search peptides not in uniprot_nr species in DB\n",
    "df_uni_spec_ref_th = df_full_uniprot_species[(df_full_uniprot_species.Hyperscore >= 20.8) & (df_full_uniprot_species.decoy!={True})]\n",
    "#uniprot_identified_peptides_not_ref = set(df_uni_spec_ref_th.Peptide).difference(set(df_in_fdr_ref.Peptide))\n",
    "ref_identified_peptides_not_in_t2p_uni_spec = set(df_in_fdr_ref.Peptide).difference(set(df_uni_spec_ref_th.Peptide))\n",
    "print(len(ref_identified_peptides_not_in_t2p_uni_spec))\n",
    "#print(len(uniprot_identified_peptides_not_ref))\n",
    "#ref_identified_peptides_not_uniprot_species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416e0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectra_in_uni_set=set(df_in_fdr_uniprot_species.Title)\n",
    "ref_df_spectra_not_in_t2p = df_in_fdr_ref[~df_in_fdr_ref.Title.isin(spectra_in_uni_set)].sort_values(by=['Hyperscore'])\n",
    "acc_of_unidentified_spectra = {item for sublist in df_in_fdr_ref[~df_in_fdr_ref.Title.isin(spectra_in_uni_set)].Protein for item in sublist}\n",
    "df_acc_not_in_species_df = df_in_fdr_ref[get_not_spectra_rows(df_in_fdr_ref.Title, spectra_in_uni_set)]\n",
    "print(f\"number spectra not identified with t2p DB: {len(set(ref_df_spectra_not_in_t2p.Title))}\")\n",
    "print(f\"davon unter Hyperscore von 23.7 : {len(set((ref_df_spectra_not_in_t2p[ref_df_spectra_not_in_t2p.Hyperscore<23.7])))}\")\n",
    "print(f\"number accs associate to these spectra: {len(acc_of_unidentified_spectra)}\")\n",
    "print(f\"number of unidentified spectra with match < 100% with blast: {len(acc_of_unidentified_spectra.intersection(acc_set_only_in_ref))}\")\n",
    "print('Run1_U1_2000ng.74833.74833.2' in df_in_fdr_uniprot_species.Title)\n",
    "print(\"VVALIEVADGEAAQPAAAAAPAPAK\" in df_in_fdr_uniprot_species.Protein)\n",
    "#print(df_in_fdr_ref[df_in_fdr_ref.Title == \"Run1_U1_2000ng.74833.74833.2\"][['Title','Hyperscore', 'Protein']])\n",
    "#print(df_in_fdr_uniprot_species[df_in_fdr_uniprot_species.Title == \"Run1_U1_2000ng.74833.74833.2\"][['Title','Hyperscore', 'Protein']])\n",
    "print(ref_df_spectra_not_in_t2p[['Hyperscore', 'Protein']].tail(5))\n",
    "\n",
    "proteins_that_should_be_contained_in_t2P = {item for sublist in ref_df_spectra_not_in_t2p.Protein for item in sublist}.difference(acc_set_only_in_ref)\n",
    "print(len(proteins_that_should_be_contained_in_t2P))\n",
    "psm_that_should_be_contained_in_t2P = ref_df_spectra_not_in_t2p[get_acc_rows(ref_df_spectra_not_in_t2p.Protein, proteins_that_should_be_contained_in_t2P, True)]\n",
    "psm_that_should_be_contained_in_t2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_set = set()\n",
    "with open('/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/Tax2Proteome_DB/kleiner_species_nr.fasta', 'r') as input:\n",
    "    for line in input:\n",
    "        for pep in ref_identified_peptides_not_in_t2p_uni_spec:\n",
    "            if pep in line:\n",
    "                initial_set.add(pep)\n",
    "print(len(initial_set))\n",
    "#917 der in reference identifizierten Peptide, sind auch in t2p Datenbank enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_spec_db = list(SeqIO.parse(\"/home/jules/Documents/Metaproteomics/Tax2Proteome/benchmarking/Tax2Proteome_DB/kleiner_species_nr_crap.fasta\", \"fasta\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_db_for_peptide(db, peptide_set):\n",
    "    new_dict= defaultdict(set)\n",
    "    for entry in db:\n",
    "        for peptide in peptide_set:\n",
    "            if peptide in entry.seq:\n",
    "                new_dict[peptide].add(entry.id)\n",
    "    return new_dict\n",
    "pep_to_acc_set_dict = search_db_for_peptide(uniprot_spec_db, set(psm_that_should_be_contained_in_t2P.Peptide))\n",
    "print(len(pep_to_acc_set_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(psm_that_should_be_contained_in_t2P.Peptide)))\n",
    "list(pep_to_acc_set_dict.values())[0:2]\n",
    "small_psm_uni = set(df_uni_spec_ref_th[df_uni_spec_ref_th.Hyperscore < 23.7].Title)\n",
    "small_psm_ref = (set(psm_that_should_be_contained_in_t2P[psm_that_should_be_contained_in_t2P.Hyperscore < 23.7].Title))\n",
    "print(len(small_psm_uni), len(small_psm_ref), len(small_psm_uni.intersection(small_psm_ref)))\n",
    "all_spectra_in_ref_above_23_7 = set(df_in_fdr_ref[df_in_fdr_ref.Hyperscore > 23.7].Title)\n",
    "print('in beiden identifizierte Spectra: ', len(set(df_in_fdr_uniprot_species.Title).intersection(all_spectra_in_ref_above_23_7)))\n",
    "print('in ref identifizierte Spectra same th: ', len(all_spectra_in_ref_above_23_7))\n",
    "print(36687-36119)\n",
    "#568 spectren sind in ref über 23.7 aber nicht in t2p species\n",
    "ref_identifiziert_nicht_in_t2p_df = df_in_fdr_ref[(df_in_fdr_ref.Hyperscore > 23.7) & \\\n",
    "                                                  (~ df_in_fdr_ref.Title.isin(set(df_in_fdr_uniprot_species.Title))) &\\\n",
    "                                                 (get_not_acc_rows(df_in_fdr_ref.Protein, acc_set_only_in_ref, False))]\n",
    "proteins_not_identified = {item for sublist in ref_identifiziert_nicht_in_t2p_df.Protein for item in sublist}\n",
    "peptides_not_identified = ref_identifiziert_nicht_in_t2p_df.Peptide\n",
    "#pep_to_acc_set_dict = search_db_for_peptide(uniprot_spec_db, set(peptides_not_identified))\n",
    "print(len(peptides_not_identified))\n",
    "print(\"pep_to_acc_set_dict\", len(pep_to_acc_set_dict))\n",
    "print(len(proteins_not_identified))\n",
    "print(len(set(ref_identifiziert_nicht_in_t2p_df.Title)))\n",
    "from statistics import mean, median\n",
    "evalues = {float(item[1:-1])  for item in ref_identifiziert_nicht_in_t2p_df.EValue}\n",
    "print(median(evalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0afb696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36687-36119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f032bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = search_db_for_peptide(uniprot_spec_db, {\"PGEAPTTATSASPR\"})\n",
    "print(d['tr|Q1LRQ8|Q1LRQ8_CUPMC'])\n",
    "# einige getestet, deren peptide sind wirklich in sequenz DB drin, wurden aber nicht identifiziert, keine Ahnung warum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anzahl der T2P unbekannten Peptide bei der Ref Identifizierung\n",
    "ref_identifiziert_nicht_in_t2p_df = df_in_fdr_ref[(df_in_fdr_ref.Hyperscore > 23.7) & \\\n",
    "                                                  (~ df_in_fdr_ref.Title.isin(set(df_in_fdr_uniprot_species.Title))) &\\\n",
    "                                                 (get_acc_rows(df_in_fdr_ref.Protein, acc_set_only_in_ref, True))]\n",
    "print(len(set(ref_identifiziert_nicht_in_t2p_df.Title)))\n",
    "print(len(set(df_in_fdr_ref[(df_in_fdr_ref.Hyperscore < 23.7)].Title)))\n",
    "print(len(set(df_in_fdr_ref[(df_in_fdr_ref.Hyperscore > 23.7) & \\\n",
    "                            (~ df_in_fdr_ref.Title.isin(set(df_in_fdr_uniprot_species.Title)))].Title)))\n",
    "print(len(set(ref_identifiziert_nicht_in_t2p_df[ref_identifiziert_nicht_in_t2p_df.Peptide.isin(list(pep_to_acc_set_dict.keys()))].Title)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unterschiede ref identification vs. uniprot_species T2P identifications:\n",
    "# #spectra in ref < 23.7 = 4542\n",
    "# # spectra in ref identifiziert mittels t2p unbekannter seq: 392\n",
    "# insgesamt # spectra nicht in t2b identifiziert: 4830, davon mit Hyperscore >23.7: 568\n",
    "# bleiben 152 spectra, deren peptide auch in T2P drin waren, die haben einen mean Hyperscore von 27.1, Evalue: 0.36\n",
    "# nicht identifizierte Peptide: 169, davon waren 144 in der T2P DB enthalten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33846ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidentified_uniprot = df_spectra_identified_exclusive_in_ref[get_acc_rows(df_spectra_identified_exclusive_in_ref.Protein, uni_accs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174737a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050a247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
